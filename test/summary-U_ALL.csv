method,metric,sample,url
GROB-R1-U_ALL,tp,sample-1.pdf,https://ait.ethz.ch/projects/2020/eth-xgaze
GROB-R1-U_ALL,tp,sample-1.pdf,https://ait.ethz.ch/projects/2020/eve
GROB-R1-U_ALL,tp,sample-1.pdf,https://cs.columbia.edu/cave/databases/columbia_gaze
GROB-R1-U_ALL,tp,sample-1.pdf,https://gaze360.csail.mit.edu
GROB-R1-U_ALL,tp,sample-1.pdf,https://gazecapture.csail.mit.edu
GROB-R1-U_ALL,tp,sample-1.pdf,https://github.com/cleardusk/3ddfa_v2
GROB-R1-U_ALL,tp,sample-1.pdf,https://github.com/dongzelian/multi-view-gaze
GROB-R1-U_ALL,tp,sample-1.pdf,https://github.com/kpzhang93/mtcnn_face_detection_alignment
GROB-R1-U_ALL,tp,sample-1.pdf,https://github.com/marekkowalski/deepalignmentnetwork
GROB-R1-U_ALL,tp,sample-1.pdf,https://github.com/tadasbaltrusaitis/openface
GROB-R1-U_ALL,tp,sample-1.pdf,https://github.com/tobias-fischer/rt_gene
GROB-R1-U_ALL,tp,sample-1.pdf,https://github.com/yadiraf/prnet
GROB-R1-U_ALL,tp,sample-1.pdf,https://idiap.ch/dataset/eyediap
GROB-R1-U_ALL,tp,sample-1.pdf,https://mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/research/gaze-based-human-computer-interaction/its-written-all-over-your-face-full-face-appearance-based-gaze-estimation
GROB-R1-U_ALL,tp,sample-1.pdf,https://mpi-inf.mpg.de/invisibleeye
GROB-R1-U_ALL,tp,sample-1.pdf,https://mpi-inf.mpg.de/mpiigaze
GROB-R1-U_ALL,tp,sample-1.pdf,https://phi-ai.org/gazehub
GROB-R1-U_ALL,tp,sample-1.pdf,https://pypi.org/project/dlib/19.6.0
GROB-R1-U_ALL,tp,sample-1.pdf,https://sites.google.com/nvidia.com/nvgaze
GROB-R1-U_ALL,tp,sample-1.pdf,https://ut-vision.org/datasets
GROB-R1-U_ALL,tp,sample-1.pdf,https://www.sciencedirect.com/science/article/pii/s0169814115000761
GROB-R1-U_ALL,tp,sample-1.pdf,https://www.sciencedirect.com/science/article/pii/s0262885614000171
GROB-R1-U_ALL,tp,sample-1.pdf,https://www.sciencedirect.com/science/article/pii/s092523121501783x
GROB-R1-U_ALL,tp,sample-1.pdf,https://www.sciencedirect.com/science/article/pii/s1878929316300846
GROB-R1-U_ALL,tp,sample-2.pdf,https://nlp.stanford.edu/projects/glove
GROB-R1-U_ALL,tp,sample-2.pdf,https://www.aaai.org
GROB-R1-U_ALL,tp,sample-3.pdf,https://code.google.com/p/dkpro-similarity-asl
GROB-R1-U_ALL,tp,sample-3.pdf,https://www.gutenberg.org
GROB-R1-U_ALL,tp,sample-3.pdf,https://www.ukp.tu-darmstadt.de/data/text-similarity/text-reuse-annotations
GROB-R1-U_ALL,tp,sample-3.pdf,https://www.wikipedia.org
GROB-R1-U_ALL,tp,sample-3.pdf,https://www.wiktionary.org
GROB-R1-U_ALL,tp,sample-4.pdf,https://aws.amazon.com/kinesis
GROB-R1-U_ALL,tp,sample-4.pdf,https://developers.google.com/protocol-buffers
GROB-R1-U_ALL,tp,sample-4.pdf,https://flink.apache.org
GROB-R1-U_ALL,tp,sample-4.pdf,https://github.com/nirdslab/streaminghub-conduit
GROB-R1-U_ALL,tp,sample-4.pdf,https://github.com/nirdslab/streaminghub-dfs
GROB-R1-U_ALL,tp,sample-4.pdf,https://github.com/sccn/labstreaminglayer
GROB-R1-U_ALL,tp,sample-4.pdf,https://idl.cs.washington.edu/papers/reactive-vega
GROB-R1-U_ALL,tp,sample-4.pdf,https://kepler-project.org
GROB-R1-U_ALL,tp,sample-4.pdf,https://mqtt.org
GROB-R1-U_ALL,tp,sample-4.pdf,https://nodered.org
GROB-R1-U_ALL,tp,sample-4.pdf,https://www.knime.com
GROB-R1-U_ALL,tp,sample-5.pdf,https://cinetics.com/two-axis360
GROB-R1-U_ALL,tp,sample-5.pdf,https://myscript.com/technology
GROB-R1-U_ALL,tp,sample-5.pdf,https://vubiq.com/v60wgd03
GROB-R1-U_ALL,tp,sample-5.pdf,https://warp.rice.edu/trac/wiki
GROB-R1-U_ALL,tp,sample-5.pdf,https://www.dailywireless.org/2014/01/03/60ghz-backhaul-for-small-cells
GROB-R1-U_ALL,tp,sample-5.pdf,https://www.mcelhearn.com/not-a-review-leap-motioncontroller-fails-in-normal-conditions
GROB-R1-U_ALL,tp,sample-5.pdf,https://www.tdk.com
GROB-R1-U_ALL,tp,sample-6.pdf,https://terramood.informatics.indiana.edu/data
GROB-R1-U_ALL,tp,sample-6.pdf,https://www.cs.pitt.edu/mpqa/opinionfinderrelease
GROB-R1-U_ALL,tp,sample-6.pdf,https://www.gallup.com/poll/122840/gallup-daily-economic-indexes.aspx
GROB-R1-U_ALL,tp,sample-6.pdf,https://www.sca.isr.umich.edu
GROB-R1-U_ALL,tp,sample-7.pdf,https://github.com/nirdslab/streaminghub-dfs
GROB-R1-U_ALL,tp,sample-7.pdf,https://www.cs.odu.edu/~sampath
GROB-R1-U_ALL,tp,sample-7.pdf,https://www.cs.odu.edu/~yasith
GROB-R1-U_ALL,tp,sample-8.pdf,https://github.com/nirdslab/streaminghub-conduit
GROB-R1-U_ALL,tp,sample-8.pdf,https://github.com/nirdslab/streaminghub-dfs
GROB-R1-U_ALL,tp,sample-8.pdf,https://www.cs.odu.edu/~sampath
GROB-R1-U_ALL,tp,sample-8.pdf,https://www.cs.odu.edu/~yasith
GROB-R1-U_ALL,fp,sample-1.pdf,https://ability.convolutional
GROB-R1-U_ALL,fp,sample-1.pdf,https://advance.th
GROB-R1-U_ALL,fp,sample-1.pdf,https://al.propose
GROB-R1-U_ALL,fp,sample-1.pdf,https://applications.recently
GROB-R1-U_ALL,fp,sample-1.pdf,https://buaa.edu.cn
GROB-R1-U_ALL,fp,sample-1.pdf,https://calibration.besides
GROB-R1-U_ALL,fp,sample-1.pdf,https://changes.deep
GROB-R1-U_ALL,fp,sample-1.pdf,https://characteristics.fi
GROB-R1-U_ALL,fp,sample-1.pdf,https://cs.cv
GROB-R1-U_ALL,fp,sample-1.pdf,https://datasets.datasetssubjectstotalannotations
GROB-R1-U_ALL,fp,sample-1.pdf,https://directions.table
GROB-R1-U_ALL,fp,sample-1.pdf,https://domain.fi
GROB-R1-U_ALL,fp,sample-1.pdf,https://domains.wang
GROB-R1-U_ALL,fp,sample-1.pdf,https://estimation.fi
GROB-R1-U_ALL,fp,sample-1.pdf,https://estimation.to
GROB-R1-U_ALL,fp,sample-1.pdf,https://evaluation.th
GROB-R1-U_ALL,fp,sample-1.pdf,https://eyeglasses.besides
GROB-R1-U_ALL,fp,sample-1.pdf,https://factor.fi
GROB-R1-U_ALL,fp,sample-1.pdf,https://factors.th
GROB-R1-U_ALL,fp,sample-1.pdf,https://fig.11.tonsen
GROB-R1-U_ALL,fp,sample-1.pdf,https://fig.12.th
GROB-R1-U_ALL,fp,sample-1.pdf,https://gaze.fi
GROB-R1-U_ALL,fp,sample-1.pdf,https://gaze.given
GROB-R1-U_ALL,fp,sample-1.pdf,https://head.table
GROB-R1-U_ALL,fp,sample-1.pdf,https://ii.after
GROB-R1-U_ALL,fp,sample-1.pdf,https://image.fi
GROB-R1-U_ALL,fp,sample-1.pdf,https://images.fi
GROB-R1-U_ALL,fp,sample-1.pdf,https://images.some
GROB-R1-U_ALL,fp,sample-1.pdf,https://images.tw
GROB-R1-U_ALL,fp,sample-1.pdf,https://information.fi
GROB-R1-U_ALL,fp,sample-1.pdf,https://map.th
GROB-R1-U_ALL,fp,sample-1.pdf,https://methods.computer
GROB-R1-U_ALL,fp,sample-1.pdf,https://methods.in
GROB-R1-U_ALL,fp,sample-1.pdf,https://methods.table
GROB-R1-U_ALL,fp,sample-1.pdf,https://methods.th
GROB-R1-U_ALL,fp,sample-1.pdf,https://network.gaze
GROB-R1-U_ALL,fp,sample-1.pdf,https://networks.some
GROB-R1-U_ALL,fp,sample-1.pdf,https://pcl.ac.cn
GROB-R1-U_ALL,fp,sample-1.pdf,https://perspectives.gaze
GROB-R1-U_ALL,fp,sample-1.pdf,https://platforms.besides
GROB-R1-U_ALL,fp,sample-1.pdf,https://pose.edu/cognitive-e
GROB-R1-U_ALL,fp,sample-1.pdf,https://problem.th
GROB-R1-U_ALL,fp,sample-1.pdf,https://progress.methodsdatasetsmpiifacegaze
GROB-R1-U_ALL,fp,sample-1.pdf,https://progress.table
GROB-R1-U_ALL,fp,sample-1.pdf,https://pub.linksdlib
GROB-R1-U_ALL,fp,sample-1.pdf,https://research.here
GROB-R1-U_ALL,fp,sample-1.pdf,https://rg.illumination
GROB-R1-U_ALL,fp,sample-1.pdf,https://samples.lu
GROB-R1-U_ALL,fp,sample-1.pdf,https://samples.th
GROB-R1-U_ALL,fp,sample-1.pdf,https://scs.rectification
GROB-R1-U_ALL,fp,sample-1.pdf,https://size.ch/projects/2
GROB-R1-U_ALL,fp,sample-1.pdf,https://w.r.t.th
GROB-R1-U_ALL,fp,sample-2.pdf,https://agent.next
GROB-R1-U_ALL,fp,sample-2.pdf,https://appendix.in
GROB-R1-U_ALL,fp,sample-2.pdf,https://aspects.approachin
GROB-R1-U_ALL,fp,sample-2.pdf,https://cases.modelacc
GROB-R1-U_ALL,fp,sample-2.pdf,https://cell.training
GROB-R1-U_ALL,fp,sample-2.pdf,https://data.according
GROB-R1-U_ALL,fp,sample-2.pdf,https://dataset.sequence
GROB-R1-U_ALL,fp,sample-2.pdf,https://dependency.figure
GROB-R1-U_ALL,fp,sample-2.pdf,https://fudan.edu.cn
GROB-R1-U_ALL,fp,sample-2.pdf,https://gradients.to
GROB-R1-U_ALL,fp,sample-2.pdf,https://information.fo
GROB-R1-U_ALL,fp,sample-2.pdf,https://legislation.you
GROB-R1-U_ALL,fp,sample-2.pdf,https://lstm.number
GROB-R1-U_ALL,fp,sample-2.pdf,https://modeling.recurrent
GROB-R1-U_ALL,fp,sample-2.pdf,https://problem.th
GROB-R1-U_ALL,fp,sample-2.pdf,https://report.th
GROB-R1-U_ALL,fp,sample-2.pdf,https://reserved.th
GROB-R1-U_ALL,fp,sample-2.pdf,https://respectively.figure
GROB-R1-U_ALL,fp,sample-2.pdf,https://respectively.th
GROB-R1-U_ALL,fp,sample-2.pdf,https://reward.to
GROB-R1-U_ALL,fp,sample-2.pdf,https://sequence.to
GROB-R1-U_ALL,fp,sample-2.pdf,https://sets.ma
GROB-R1-U_ALL,fp,sample-2.pdf,https://skip.related
GROB-R1-U_ALL,fp,sample-2.pdf,https://space.to
GROB-R1-U_ALL,fp,sample-2.pdf,https://table4.chen
GROB-R1-U_ALL,fp,sample-2.pdf,https://task.please
GROB-R1-U_ALL,fp,sample-2.pdf,https://tasks.conclusionsin
GROB-R1-U_ALL,fp,sample-2.pdf,https://tasks.however
GROB-R1-U_ALL,fp,sample-2.pdf,https://tasks.th
GROB-R1-U_ALL,fp,sample-2.pdf,https://testing.name
GROB-R1-U_ALL,fp,sample-3.pdf,https://15.fo
GROB-R1-U_ALL,fp,sample-3.pdf,https://15.in
GROB-R1-U_ALL,fp,sample-3.pdf,https://3.3.in
GROB-R1-U_ALL,fp,sample-3.pdf,https://859.in
GROB-R1-U_ALL,fp,sample-3.pdf,https://account.in
GROB-R1-U_ALL,fp,sample-3.pdf,https://annotator.acknowledgementsthis
GROB-R1-U_ALL,fp,sample-3.pdf,https://bayes.error
GROB-R1-U_ALL,fp,sample-3.pdf,https://best.table
GROB-R1-U_ALL,fp,sample-3.pdf,https://characteristics.introductiontext
GROB-R1-U_ALL,fp,sample-3.pdf,https://class.plagiarism
GROB-R1-U_ALL,fp,sample-3.pdf,https://correlation.stylistic
GROB-R1-U_ALL,fp,sample-3.pdf,https://data.conclusions
GROB-R1-U_ALL,fp,sample-3.pdf,https://data.contentesa
GROB-R1-U_ALL,fp,sample-3.pdf,https://data.fo
GROB-R1-U_ALL,fp,sample-3.pdf,https://datasets.as
GROB-R1-U_ALL,fp,sample-3.pdf,https://decreases.table
GROB-R1-U_ALL,fp,sample-3.pdf,https://extent.according
GROB-R1-U_ALL,fp,sample-3.pdf,https://figure1.resultswe
GROB-R1-U_ALL,fp,sample-3.pdf,https://grading.fo
GROB-R1-U_ALL,fp,sample-3.pdf,https://hand.meter
GROB-R1-U_ALL,fp,sample-3.pdf,https://henceforth.following
GROB-R1-U_ALL,fp,sample-3.pdf,https://imbalance.wikipedia
GROB-R1-U_ALL,fp,sample-3.pdf,https://individually.in
GROB-R1-U_ALL,fp,sample-3.pdf,https://not.in
GROB-R1-U_ALL,fp,sample-3.pdf,https://para.paraphrase
GROB-R1-U_ALL,fp,sample-3.pdf,https://phase.in
GROB-R1-U_ALL,fp,sample-3.pdf,https://plag.majority
GROB-R1-U_ALL,fp,sample-3.pdf,https://respectively.based
GROB-R1-U_ALL,fp,sample-3.pdf,https://respectively.finally
GROB-R1-U_ALL,fp,sample-3.pdf,https://richness.error
GROB-R1-U_ALL,fp,sample-3.pdf,https://samples.resultswe
GROB-R1-U_ALL,fp,sample-3.pdf,https://segments.inspired
GROB-R1-U_ALL,fp,sample-3.pdf,https://similarity.in
GROB-R1-U_ALL,fp,sample-3.pdf,https://studies.detecting
GROB-R1-U_ALL,fp,sample-3.pdf,https://study.resultswe
GROB-R1-U_ALL,fp,sample-3.pdf,https://table10.error
GROB-R1-U_ALL,fp,sample-3.pdf,https://texts.detecting
GROB-R1-U_ALL,fp,sample-3.pdf,https://texts.stopword
GROB-R1-U_ALL,fp,sample-3.pdf,https://used.th
GROB-R1-U_ALL,fp,sample-3.pdf,https://vectors.comparing
GROB-R1-U_ALL,fp,sample-4.pdf,https://applications.streaminghub
GROB-R1-U_ALL,fp,sample-4.pdf,https://back.usage
GROB-R1-U_ALL,fp,sample-4.pdf,https://clemson.edu
GROB-R1-U_ALL,fp,sample-4.pdf,https://cs.odu.edu
GROB-R1-U_ALL,fp,sample-4.pdf,https://data.case
GROB-R1-U_ALL,fp,sample-4.pdf,https://design.in
GROB-R1-U_ALL,fp,sample-4.pdf,https://dfs.data
GROB-R1-U_ALL,fp,sample-4.pdf,https://exhausted.workflow
GROB-R1-U_ALL,fp,sample-4.pdf,https://results.introductionin
GROB-R1-U_ALL,fp,sample-4.pdf,https://sponsors.removing
GROB-R1-U_ALL,fp,sample-4.pdf,https://streaming.figure
GROB-R1-U_ALL,fp,sample-4.pdf,https://streaminghub.using
GROB-R1-U_ALL,fp,sample-4.pdf,https://streams.here
GROB-R1-U_ALL,fp,sample-4.pdf,https://systems.conclusionusing
GROB-R1-U_ALL,fp,sample-4.pdf,https://time.ca
GROB-R1-U_ALL,fp,sample-4.pdf,https://workflows.as
GROB-R1-U_ALL,fp,sample-5.pdf,https://8.gh
GROB-R1-U_ALL,fp,sample-5.pdf,https://a.from
GROB-R1-U_ALL,fp,sample-5.pdf,https://algorithm.figure
GROB-R1-U_ALL,fp,sample-5.pdf,https://angle.phase
GROB-R1-U_ALL,fp,sample-5.pdf,https://angles.figure
GROB-R1-U_ALL,fp,sample-5.pdf,https://apa.recall
GROB-R1-U_ALL,fp,sample-5.pdf,https://applications.figure
GROB-R1-U_ALL,fp,sample-5.pdf,https://assumption.to
GROB-R1-U_ALL,fp,sample-5.pdf,https://background.figure
GROB-R1-U_ALL,fp,sample-5.pdf,https://background.in
GROB-R1-U_ALL,fp,sample-5.pdf,https://bg.figure
GROB-R1-U_ALL,fp,sample-5.pdf,https://case.figure
GROB-R1-U_ALL,fp,sample-5.pdf,https://cns-1404613.appendix
GROB-R1-U_ALL,fp,sample-5.pdf,https://counting.to
GROB-R1-U_ALL,fp,sample-5.pdf,https://default.bot
GROB-R1-U_ALL,fp,sample-5.pdf,https://detected.acknowledgementwe
GROB-R1-U_ALL,fp,sample-5.pdf,https://directions.figure
GROB-R1-U_ALL,fp,sample-5.pdf,https://distance.dealing
GROB-R1-U_ALL,fp,sample-5.pdf,https://distance.th
GROB-R1-U_ALL,fp,sample-5.pdf,https://ece.wisc.edu
GROB-R1-U_ALL,fp,sample-5.pdf,https://etc.phase
GROB-R1-U_ALL,fp,sample-5.pdf,https://fc.from
GROB-R1-U_ALL,fp,sample-5.pdf,https://feasible.these
GROB-R1-U_ALL,fp,sample-5.pdf,https://hypothesis.it
GROB-R1-U_ALL,fp,sample-5.pdf,https://interest.to
GROB-R1-U_ALL,fp,sample-5.pdf,https://known.figure
GROB-R1-U_ALL,fp,sample-5.pdf,https://larger.figure
GROB-R1-U_ALL,fp,sample-5.pdf,https://level.impact
GROB-R1-U_ALL,fp,sample-5.pdf,https://materials.figure
GROB-R1-U_ALL,fp,sample-5.pdf,https://mm.background
GROB-R1-U_ALL,fp,sample-5.pdf,https://movement.joint
GROB-R1-U_ALL,fp,sample-5.pdf,https://mtrack.beam
GROB-R1-U_ALL,fp,sample-5.pdf,https://mtrack.table
GROB-R1-U_ALL,fp,sample-5.pdf,https://mtrack.this
GROB-R1-U_ALL,fp,sample-5.pdf,https://noise.figure
GROB-R1-U_ALL,fp,sample-5.pdf,https://operations.notably
GROB-R1-U_ALL,fp,sample-5.pdf,https://peaks.implementation
GROB-R1-U_ALL,fp,sample-5.pdf,https://period.tracking
GROB-R1-U_ALL,fp,sample-5.pdf,https://phase-tracking.figure
GROB-R1-U_ALL,fp,sample-5.pdf,https://phase-tracking.suppose
GROB-R1-U_ALL,fp,sample-5.pdf,https://phase.target
GROB-R1-U_ALL,fp,sample-5.pdf,https://position.mtrack
GROB-R1-U_ALL,fp,sample-5.pdf,https://radios.second
GROB-R1-U_ALL,fp,sample-5.pdf,https://receiver.in
GROB-R1-U_ALL,fp,sample-5.pdf,https://reflection.combating
GROB-R1-U_ALL,fp,sample-5.pdf,https://region.algorithm
GROB-R1-U_ALL,fp,sample-5.pdf,https://region.figure
GROB-R1-U_ALL,fp,sample-5.pdf,https://region.reflection/diffusion
GROB-R1-U_ALL,fp,sample-5.pdf,https://rx.in
GROB-R1-U_ALL,fp,sample-5.pdf,https://set.application
GROB-R1-U_ALL,fp,sample-5.pdf,https://signals.fo
GROB-R1-U_ALL,fp,sample-5.pdf,https://signals.performance
GROB-R1-U_ALL,fp,sample-5.pdf,https://space.background
GROB-R1-U_ALL,fp,sample-5.pdf,https://space.figure
GROB-R1-U_ALL,fp,sample-5.pdf,https://steering.figure
GROB-R1-U_ALL,fp,sample-5.pdf,https://subtracted.regeneration
GROB-R1-U_ALL,fp,sample-5.pdf,https://target.figure
GROB-R1-U_ALL,fp,sample-5.pdf,https://trajectory.performance
GROB-R1-U_ALL,fp,sample-5.pdf,https://trajectory.th
GROB-R1-U_ALL,fp,sample-5.pdf,https://truth.following
GROB-R1-U_ALL,fp,sample-5.pdf,https://uncertainties.remarkably
GROB-R1-U_ALL,fp,sample-5.pdf,https://users.figure
GROB-R1-U_ALL,fp,sample-5.pdf,https://value.it
GROB-R1-U_ALL,fp,sample-5.pdf,https://word.table
GROB-R1-U_ALL,fp,sample-5.pdf,https://work.conclusionwe
GROB-R1-U_ALL,fp,sample-5.pdf,https://work.tracking
GROB-R1-U_ALL,fp,sample-5.pdf,https://works.table
GROB-R1-U_ALL,fp,sample-5.pdf,https://www.pcmag.com
GROB-R1-U_ALL,fp,sample-5.pdf,https://www.roborealm.com/help/microsoftkinect.php
GROB-R1-U_ALL,fp,sample-6.pdf,https://0.table
GROB-R1-U_ALL,fp,sample-6.pdf,https://1.in
GROB-R1-U_ALL,fp,sample-6.pdf,https://2008.mood
GROB-R1-U_ALL,fp,sample-6.pdf,https://analysis.second
GROB-R1-U_ALL,fp,sample-6.pdf,https://days.acknowledgmentthis
GROB-R1-U_ALL,fp,sample-6.pdf,https://days.th
GROB-R1-U_ALL,fp,sample-6.pdf,https://december2008.table
GROB-R1-U_ALL,fp,sample-6.pdf,https://happy.th
GROB-R1-U_ALL,fp,sample-6.pdf,https://period.in
GROB-R1-U_ALL,fp,sample-6.pdf,https://range.sofnn
GROB-R1-U_ALL,fp,sample-6.pdf,https://receipts.although
GROB-R1-U_ALL,fp,sample-6.pdf,https://research.fi
GROB-R1-U_ALL,fp,sample-6.pdf,https://series.fi
GROB-R1-U_ALL,fp,sample-6.pdf,https://series.to
GROB-R1-U_ALL,fp,sample-6.pdf,https://site6.to
GROB-R1-U_ALL,fp,sample-6.pdf,https://std.er
GROB-R1-U_ALL,fp,sample-6.pdf,https://t.like
GROB-R1-U_ALL,fp,sample-6.pdf,https://thanksgiving.fi
GROB-R1-U_ALL,fp,sample-6.pdf,https://times.in
GROB-R1-U_ALL,fp,sample-6.pdf,https://twitter.com
GROB-R1-U_ALL,fp,sample-6.pdf,https://value.to
GROB-R1-U_ALL,fp,sample-6.pdf,https://values.however
GROB-R1-U_ALL,fp,sample-6.pdf,https://work.eugeneffamaeainternational
GROB-R1-U_ALL,fp,sample-6.pdf,https://x.zeng@manchester.ac.uk
GROB-R1-U_ALL,fp,sample-7.pdf,https://egestas.integer
GROB-R1-U_ALL,fp,sample-7.pdf,https://github.com/nirdslab/streaminghub-conduitintegersemperelitidvelitconsequat
GROB-R1-U_ALL,fp,sample-7.pdf,https://ornare.aenean
GROB-R1-U_ALL,fp,sample-7.pdf,https://quis.nullam
GROB-R1-U_ALL,fn,sample-1.pdf,https://sh.rice.edu/cognitive-engagement/ tabletgaze
GROB-R1-U_ALL,fn,sample-3.pdf,https://www.ukp.tu-darmstadt.de
GROB-R1-U_ALL,fn,sample-5.pdf,"https://www.pcmag.com/article2/0,2817,2454187,00.asp"
GROB-R1-U_ALL,fn,sample-5.pdf,https://www.roborealm.com/help/microsoft kinect.php
GROB-R1-U_ALL,fn,sample-5.pdf,https://www.vicon.com
GROB-R1-U_ALL,fn,sample-6.pdf,https://www.ccs.neu.edu/home/amislove/twittermood
GROB-R1-U_ALL,fn,sample-7.pdf,https://github.com/nirdslab/streaminghub-conduit
GROB-R2-U_ALL,tp,sample-1.pdf,https://ait.ethz.ch/projects/2020/eth-xgaze
GROB-R2-U_ALL,tp,sample-1.pdf,https://ait.ethz.ch/projects/2020/eve
GROB-R2-U_ALL,tp,sample-1.pdf,https://cs.columbia.edu/cave/databases/columbia_gaze
GROB-R2-U_ALL,tp,sample-1.pdf,https://gaze360.csail.mit.edu
GROB-R2-U_ALL,tp,sample-1.pdf,https://gazecapture.csail.mit.edu
GROB-R2-U_ALL,tp,sample-1.pdf,https://github.com/cleardusk/3ddfa_v2
GROB-R2-U_ALL,tp,sample-1.pdf,https://github.com/dongzelian/multi-view-gaze
GROB-R2-U_ALL,tp,sample-1.pdf,https://github.com/kpzhang93/mtcnn_face_detection_alignment
GROB-R2-U_ALL,tp,sample-1.pdf,https://github.com/marekkowalski/deepalignmentnetwork
GROB-R2-U_ALL,tp,sample-1.pdf,https://github.com/tadasbaltrusaitis/openface
GROB-R2-U_ALL,tp,sample-1.pdf,https://github.com/tobias-fischer/rt_gene
GROB-R2-U_ALL,tp,sample-1.pdf,https://github.com/yadiraf/prnet
GROB-R2-U_ALL,tp,sample-1.pdf,https://idiap.ch/dataset/eyediap
GROB-R2-U_ALL,tp,sample-1.pdf,https://mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/research/gaze-based-human-computer-interaction/its-written-all-over-your-face-full-face-appearance-based-gaze-estimation
GROB-R2-U_ALL,tp,sample-1.pdf,https://mpi-inf.mpg.de/invisibleeye
GROB-R2-U_ALL,tp,sample-1.pdf,https://mpi-inf.mpg.de/mpiigaze
GROB-R2-U_ALL,tp,sample-1.pdf,https://phi-ai.org/gazehub
GROB-R2-U_ALL,tp,sample-1.pdf,https://pypi.org/project/dlib/19.6.0
GROB-R2-U_ALL,tp,sample-1.pdf,https://sites.google.com/nvidia.com/nvgaze
GROB-R2-U_ALL,tp,sample-1.pdf,https://ut-vision.org/datasets
GROB-R2-U_ALL,tp,sample-1.pdf,https://www.sciencedirect.com/science/article/pii/s0169814115000761
GROB-R2-U_ALL,tp,sample-1.pdf,https://www.sciencedirect.com/science/article/pii/s0262885614000171
GROB-R2-U_ALL,tp,sample-1.pdf,https://www.sciencedirect.com/science/article/pii/s092523121501783x
GROB-R2-U_ALL,tp,sample-1.pdf,https://www.sciencedirect.com/science/article/pii/s1878929316300846
GROB-R2-U_ALL,tp,sample-2.pdf,https://nlp.stanford.edu/projects/glove
GROB-R2-U_ALL,tp,sample-2.pdf,https://www.aaai.org
GROB-R2-U_ALL,tp,sample-3.pdf,https://www.gutenberg.org
GROB-R2-U_ALL,tp,sample-3.pdf,https://www.ukp.tu-darmstadt.de/data/text-similarity/text-reuse-annotations
GROB-R2-U_ALL,tp,sample-3.pdf,https://www.wikipedia.org
GROB-R2-U_ALL,tp,sample-3.pdf,https://www.wiktionary.org
GROB-R2-U_ALL,tp,sample-4.pdf,https://aws.amazon.com/kinesis
GROB-R2-U_ALL,tp,sample-4.pdf,https://developers.google.com/protocol-buffers
GROB-R2-U_ALL,tp,sample-4.pdf,https://flink.apache.org
GROB-R2-U_ALL,tp,sample-4.pdf,https://github.com/nirdslab/streaminghub-conduit
GROB-R2-U_ALL,tp,sample-4.pdf,https://github.com/nirdslab/streaminghub-dfs
GROB-R2-U_ALL,tp,sample-4.pdf,https://github.com/sccn/labstreaminglayer
GROB-R2-U_ALL,tp,sample-4.pdf,https://idl.cs.washington.edu/papers/reactive-vega
GROB-R2-U_ALL,tp,sample-4.pdf,https://kepler-project.org
GROB-R2-U_ALL,tp,sample-4.pdf,https://mqtt.org
GROB-R2-U_ALL,tp,sample-4.pdf,https://nodered.org
GROB-R2-U_ALL,tp,sample-4.pdf,https://www.knime.com
GROB-R2-U_ALL,tp,sample-5.pdf,https://cinetics.com/two-axis360
GROB-R2-U_ALL,tp,sample-5.pdf,https://myscript.com/technology
GROB-R2-U_ALL,tp,sample-5.pdf,https://vubiq.com/v60wgd03
GROB-R2-U_ALL,tp,sample-5.pdf,https://warp.rice.edu/trac/wiki
GROB-R2-U_ALL,tp,sample-5.pdf,https://www.dailywireless.org/2014/01/03/60ghz-backhaul-for-small-cells
GROB-R2-U_ALL,tp,sample-5.pdf,https://www.mcelhearn.com/not-a-review-leap-motioncontroller-fails-in-normal-conditions
GROB-R2-U_ALL,tp,sample-5.pdf,https://www.tdk.com
GROB-R2-U_ALL,tp,sample-6.pdf,https://terramood.informatics.indiana.edu/data
GROB-R2-U_ALL,tp,sample-6.pdf,https://www.cs.pitt.edu/mpqa/opinionfinderrelease
GROB-R2-U_ALL,tp,sample-6.pdf,https://www.gallup.com/poll/122840/gallup-daily-economic-indexes.aspx
GROB-R2-U_ALL,tp,sample-6.pdf,https://www.sca.isr.umich.edu
GROB-R2-U_ALL,tp,sample-7.pdf,https://github.com/nirdslab/streaminghub-dfs
GROB-R2-U_ALL,tp,sample-7.pdf,https://www.cs.odu.edu/~sampath
GROB-R2-U_ALL,tp,sample-7.pdf,https://www.cs.odu.edu/~yasith
GROB-R2-U_ALL,tp,sample-8.pdf,https://github.com/nirdslab/streaminghub-conduit
GROB-R2-U_ALL,tp,sample-8.pdf,https://github.com/nirdslab/streaminghub-dfs
GROB-R2-U_ALL,tp,sample-8.pdf,https://www.cs.odu.edu/~sampath
GROB-R2-U_ALL,tp,sample-8.pdf,https://www.cs.odu.edu/~yasith
GROB-R2-U_ALL,fp,sample-1.pdf,https://ability.co
GROB-R2-U_ALL,fp,sample-1.pdf,https://advance.th
GROB-R2-U_ALL,fp,sample-1.pdf,https://al.pro
GROB-R2-U_ALL,fp,sample-1.pdf,https://applications.re
GROB-R2-U_ALL,fp,sample-1.pdf,https://buaa.edu.cn
GROB-R2-U_ALL,fp,sample-1.pdf,https://calibration.be
GROB-R2-U_ALL,fp,sample-1.pdf,https://cameras.se
GROB-R2-U_ALL,fp,sample-1.pdf,https://changes.de
GROB-R2-U_ALL,fp,sample-1.pdf,https://characteristics.fi
GROB-R2-U_ALL,fp,sample-1.pdf,https://cs.cv
GROB-R2-U_ALL,fp,sample-1.pdf,https://datasets.data
GROB-R2-U_ALL,fp,sample-1.pdf,https://directions.tab
GROB-R2-U_ALL,fp,sample-1.pdf,https://domain.fi
GROB-R2-U_ALL,fp,sample-1.pdf,https://domains.wang
GROB-R2-U_ALL,fp,sample-1.pdf,https://estimation.fi
GROB-R2-U_ALL,fp,sample-1.pdf,https://estimation.to
GROB-R2-U_ALL,fp,sample-1.pdf,https://evaluation.th
GROB-R2-U_ALL,fp,sample-1.pdf,https://eyeglasses.be
GROB-R2-U_ALL,fp,sample-1.pdf,https://factor.fi
GROB-R2-U_ALL,fp,sample-1.pdf,https://factors.th
GROB-R2-U_ALL,fp,sample-1.pdf,https://fig.11.to
GROB-R2-U_ALL,fp,sample-1.pdf,https://fig.12.th
GROB-R2-U_ALL,fp,sample-1.pdf,https://gaze.fi
GROB-R2-U_ALL,fp,sample-1.pdf,https://gaze.gi
GROB-R2-U_ALL,fp,sample-1.pdf,https://head.tab
GROB-R2-U_ALL,fp,sample-1.pdf,https://ii.af
GROB-R2-U_ALL,fp,sample-1.pdf,https://image.fi
GROB-R2-U_ALL,fp,sample-1.pdf,https://images.fi
GROB-R2-U_ALL,fp,sample-1.pdf,https://images.ga
GROB-R2-U_ALL,fp,sample-1.pdf,https://images.so
GROB-R2-U_ALL,fp,sample-1.pdf,https://images.tw
GROB-R2-U_ALL,fp,sample-1.pdf,https://information.fi
GROB-R2-U_ALL,fp,sample-1.pdf,https://information.int
GROB-R2-U_ALL,fp,sample-1.pdf,https://map.th
GROB-R2-U_ALL,fp,sample-1.pdf,https://methods.computer
GROB-R2-U_ALL,fp,sample-1.pdf,https://methods.in
GROB-R2-U_ALL,fp,sample-1.pdf,https://methods.tab
GROB-R2-U_ALL,fp,sample-1.pdf,https://methods.th
GROB-R2-U_ALL,fp,sample-1.pdf,https://module.se
GROB-R2-U_ALL,fp,sample-1.pdf,https://network.ga
GROB-R2-U_ALL,fp,sample-1.pdf,https://networks.so
GROB-R2-U_ALL,fp,sample-1.pdf,https://pcl.ac.cn
GROB-R2-U_ALL,fp,sample-1.pdf,https://perspectives.ga
GROB-R2-U_ALL,fp,sample-1.pdf,https://platforms.be
GROB-R2-U_ALL,fp,sample-1.pdf,https://pog.app
GROB-R2-U_ALL,fp,sample-1.pdf,https://pose.edu/cognitive-e
GROB-R2-U_ALL,fp,sample-1.pdf,https://problem.th
GROB-R2-U_ALL,fp,sample-1.pdf,https://progress.me
GROB-R2-U_ALL,fp,sample-1.pdf,https://progress.tab
GROB-R2-U_ALL,fp,sample-1.pdf,https://pub.link
GROB-R2-U_ALL,fp,sample-1.pdf,https://research.here
GROB-R2-U_ALL,fp,sample-1.pdf,https://rg.il
GROB-R2-U_ALL,fp,sample-1.pdf,https://samples.lu
GROB-R2-U_ALL,fp,sample-1.pdf,https://samples.th
GROB-R2-U_ALL,fp,sample-1.pdf,https://scs.re
GROB-R2-U_ALL,fp,sample-1.pdf,https://size.ch/projects
GROB-R2-U_ALL,fp,sample-1.pdf,https://subject.app
GROB-R2-U_ALL,fp,sample-1.pdf,https://w.r.t.th
GROB-R2-U_ALL,fp,sample-2.pdf,https://agent.next
GROB-R2-U_ALL,fp,sample-2.pdf,https://appendix.in
GROB-R2-U_ALL,fp,sample-2.pdf,https://appendix.tab
GROB-R2-U_ALL,fp,sample-2.pdf,https://aspects.app
GROB-R2-U_ALL,fp,sample-2.pdf,https://cases.mo
GROB-R2-U_ALL,fp,sample-2.pdf,https://cell.training
GROB-R2-U_ALL,fp,sample-2.pdf,https://data.ac
GROB-R2-U_ALL,fp,sample-2.pdf,https://dataset.se
GROB-R2-U_ALL,fp,sample-2.pdf,https://dependency.fi
GROB-R2-U_ALL,fp,sample-2.pdf,https://fudan.edu.cn
GROB-R2-U_ALL,fp,sample-2.pdf,https://gradients.to
GROB-R2-U_ALL,fp,sample-2.pdf,https://hours.tab
GROB-R2-U_ALL,fp,sample-2.pdf,https://information.fo
GROB-R2-U_ALL,fp,sample-2.pdf,https://inside.fi
GROB-R2-U_ALL,fp,sample-2.pdf,https://legislation.you
GROB-R2-U_ALL,fp,sample-2.pdf,https://lstm.nu
GROB-R2-U_ALL,fp,sample-2.pdf,https://modeling.re
GROB-R2-U_ALL,fp,sample-2.pdf,https://problem.th
GROB-R2-U_ALL,fp,sample-2.pdf,https://report.th
GROB-R2-U_ALL,fp,sample-2.pdf,https://reserved.th
GROB-R2-U_ALL,fp,sample-2.pdf,https://respectively.fi
GROB-R2-U_ALL,fp,sample-2.pdf,https://respectively.th
GROB-R2-U_ALL,fp,sample-2.pdf,https://reward.to
GROB-R2-U_ALL,fp,sample-2.pdf,https://sequence.to
GROB-R2-U_ALL,fp,sample-2.pdf,https://sets.ma
GROB-R2-U_ALL,fp,sample-2.pdf,https://skip.re
GROB-R2-U_ALL,fp,sample-2.pdf,https://space.to
GROB-R2-U_ALL,fp,sample-2.pdf,https://table4.ch
GROB-R2-U_ALL,fp,sample-2.pdf,https://tasks.co
GROB-R2-U_ALL,fp,sample-2.pdf,https://tasks.how
GROB-R2-U_ALL,fp,sample-2.pdf,https://tasks.th
GROB-R2-U_ALL,fp,sample-2.pdf,https://testing.name
GROB-R2-U_ALL,fp,sample-3.pdf,https://15.fo
GROB-R2-U_ALL,fp,sample-3.pdf,https://15.in
GROB-R2-U_ALL,fp,sample-3.pdf,https://1exp.class.cu
GROB-R2-U_ALL,fp,sample-3.pdf,https://3.3.in
GROB-R2-U_ALL,fp,sample-3.pdf,https://3.3.sy
GROB-R2-U_ALL,fp,sample-3.pdf,https://859.in
GROB-R2-U_ALL,fp,sample-3.pdf,https://account.in
GROB-R2-U_ALL,fp,sample-3.pdf,https://annotator.ac
GROB-R2-U_ALL,fp,sample-3.pdf,https://bayes.er
GROB-R2-U_ALL,fp,sample-3.pdf,https://best.tab
GROB-R2-U_ALL,fp,sample-3.pdf,https://characteristics.int
GROB-R2-U_ALL,fp,sample-3.pdf,https://class.pl
GROB-R2-U_ALL,fp,sample-3.pdf,https://code.google.com
GROB-R2-U_ALL,fp,sample-3.pdf,https://correlation.st
GROB-R2-U_ALL,fp,sample-3.pdf,https://data.co
GROB-R2-U_ALL,fp,sample-3.pdf,https://data.fo
GROB-R2-U_ALL,fp,sample-3.pdf,https://datasets.as
GROB-R2-U_ALL,fp,sample-3.pdf,https://decreases.tab
GROB-R2-U_ALL,fp,sample-3.pdf,https://extent.ac
GROB-R2-U_ALL,fp,sample-3.pdf,https://figure1.re
GROB-R2-U_ALL,fp,sample-3.pdf,https://grading.fo
GROB-R2-U_ALL,fp,sample-3.pdf,https://hand.me
GROB-R2-U_ALL,fp,sample-3.pdf,https://henceforth.fo
GROB-R2-U_ALL,fp,sample-3.pdf,https://imbalance.wiki
GROB-R2-U_ALL,fp,sample-3.pdf,https://individually.in
GROB-R2-U_ALL,fp,sample-3.pdf,https://not.in
GROB-R2-U_ALL,fp,sample-3.pdf,https://para.pa
GROB-R2-U_ALL,fp,sample-3.pdf,https://phase.in
GROB-R2-U_ALL,fp,sample-3.pdf,https://plag.ma
GROB-R2-U_ALL,fp,sample-3.pdf,https://respectively.ba
GROB-R2-U_ALL,fp,sample-3.pdf,https://respectively.final
GROB-R2-U_ALL,fp,sample-3.pdf,https://richness.er
GROB-R2-U_ALL,fp,sample-3.pdf,https://samples.re
GROB-R2-U_ALL,fp,sample-3.pdf,https://segments.in
GROB-R2-U_ALL,fp,sample-3.pdf,https://similarity.in
GROB-R2-U_ALL,fp,sample-3.pdf,https://studies.de
GROB-R2-U_ALL,fp,sample-3.pdf,https://study.re
GROB-R2-U_ALL,fp,sample-3.pdf,https://table10.er
GROB-R2-U_ALL,fp,sample-3.pdf,https://texts.de
GROB-R2-U_ALL,fp,sample-3.pdf,https://texts.st
GROB-R2-U_ALL,fp,sample-3.pdf,https://used.th
GROB-R2-U_ALL,fp,sample-3.pdf,https://vectors.com
GROB-R2-U_ALL,fp,sample-3.pdf,https://weighting.fi
GROB-R2-U_ALL,fp,sample-4.pdf,https://applications.stream
GROB-R2-U_ALL,fp,sample-4.pdf,https://back.us
GROB-R2-U_ALL,fp,sample-4.pdf,https://clemson.edu
GROB-R2-U_ALL,fp,sample-4.pdf,https://cs.odu.edu
GROB-R2-U_ALL,fp,sample-4.pdf,https://data.case
GROB-R2-U_ALL,fp,sample-4.pdf,https://design.in
GROB-R2-U_ALL,fp,sample-4.pdf,https://dfs.data
GROB-R2-U_ALL,fp,sample-4.pdf,https://exhausted.work
GROB-R2-U_ALL,fp,sample-4.pdf,https://improvement.data
GROB-R2-U_ALL,fp,sample-4.pdf,https://results.int
GROB-R2-U_ALL,fp,sample-4.pdf,https://sponsors.re
GROB-R2-U_ALL,fp,sample-4.pdf,https://streaming.fi
GROB-R2-U_ALL,fp,sample-4.pdf,https://streaminghub.us
GROB-R2-U_ALL,fp,sample-4.pdf,https://streams.here
GROB-R2-U_ALL,fp,sample-4.pdf,https://systems.co
GROB-R2-U_ALL,fp,sample-4.pdf,https://time.ca
GROB-R2-U_ALL,fp,sample-4.pdf,https://workflows.as
GROB-R2-U_ALL,fp,sample-5.pdf,https://a.fr
GROB-R2-U_ALL,fp,sample-5.pdf,https://accuracy.mil
GROB-R2-U_ALL,fp,sample-5.pdf,https://algorithm.fi
GROB-R2-U_ALL,fp,sample-5.pdf,https://angle.ph
GROB-R2-U_ALL,fp,sample-5.pdf,https://angles.fi
GROB-R2-U_ALL,fp,sample-5.pdf,https://antenna.fi
GROB-R2-U_ALL,fp,sample-5.pdf,https://apa.fi
GROB-R2-U_ALL,fp,sample-5.pdf,https://apa.re
GROB-R2-U_ALL,fp,sample-5.pdf,https://applications.fi
GROB-R2-U_ALL,fp,sample-5.pdf,https://assumption.to
GROB-R2-U_ALL,fp,sample-5.pdf,https://background.fi
GROB-R2-U_ALL,fp,sample-5.pdf,https://background.in
GROB-R2-U_ALL,fp,sample-5.pdf,https://bg.fi
GROB-R2-U_ALL,fp,sample-5.pdf,https://case.fi
GROB-R2-U_ALL,fp,sample-5.pdf,https://cns-1404613.app
GROB-R2-U_ALL,fp,sample-5.pdf,https://counting.to
GROB-R2-U_ALL,fp,sample-5.pdf,https://default.bot
GROB-R2-U_ALL,fp,sample-5.pdf,https://detected.ac
GROB-R2-U_ALL,fp,sample-5.pdf,https://detection.fi
GROB-R2-U_ALL,fp,sample-5.pdf,https://directions.fi
GROB-R2-U_ALL,fp,sample-5.pdf,https://distance.deal
GROB-R2-U_ALL,fp,sample-5.pdf,https://distance.th
GROB-R2-U_ALL,fp,sample-5.pdf,https://ece.wisc.edu
GROB-R2-U_ALL,fp,sample-5.pdf,https://etc.ph
GROB-R2-U_ALL,fp,sample-5.pdf,https://fc.fr
GROB-R2-U_ALL,fp,sample-5.pdf,https://feasible.th
GROB-R2-U_ALL,fp,sample-5.pdf,https://hypothesis.it
GROB-R2-U_ALL,fp,sample-5.pdf,https://interest.to
GROB-R2-U_ALL,fp,sample-5.pdf,https://known.fi
GROB-R2-U_ALL,fp,sample-5.pdf,https://larger.fi
GROB-R2-U_ALL,fp,sample-5.pdf,https://level.im
GROB-R2-U_ALL,fp,sample-5.pdf,https://materials.fi
GROB-R2-U_ALL,fp,sample-5.pdf,https://mm.ba
GROB-R2-U_ALL,fp,sample-5.pdf,https://movement.jo
GROB-R2-U_ALL,fp,sample-5.pdf,https://mtrack.be
GROB-R2-U_ALL,fp,sample-5.pdf,https://mtrack.tab
GROB-R2-U_ALL,fp,sample-5.pdf,https://mtrack.th
GROB-R2-U_ALL,fp,sample-5.pdf,https://negligible.fi
GROB-R2-U_ALL,fp,sample-5.pdf,https://noise.fi
GROB-R2-U_ALL,fp,sample-5.pdf,https://operations.no
GROB-R2-U_ALL,fp,sample-5.pdf,https://peaks.ba
GROB-R2-U_ALL,fp,sample-5.pdf,https://period.tr
GROB-R2-U_ALL,fp,sample-5.pdf,https://phase-tracking.fi
GROB-R2-U_ALL,fp,sample-5.pdf,https://phase-tracking.su
GROB-R2-U_ALL,fp,sample-5.pdf,https://phase.target
GROB-R2-U_ALL,fp,sample-5.pdf,https://platform.fi
GROB-R2-U_ALL,fp,sample-5.pdf,https://position.mtr
GROB-R2-U_ALL,fp,sample-5.pdf,https://radios.se
GROB-R2-U_ALL,fp,sample-5.pdf,https://receiver.in
GROB-R2-U_ALL,fp,sample-5.pdf,https://reflection.com
GROB-R2-U_ALL,fp,sample-5.pdf,https://region.al
GROB-R2-U_ALL,fp,sample-5.pdf,https://region.fi
GROB-R2-U_ALL,fp,sample-5.pdf,https://region.re
GROB-R2-U_ALL,fp,sample-5.pdf,https://rx.in
GROB-R2-U_ALL,fp,sample-5.pdf,https://set.app
GROB-R2-U_ALL,fp,sample-5.pdf,https://signals.fo
GROB-R2-U_ALL,fp,sample-5.pdf,https://signals.pe
GROB-R2-U_ALL,fp,sample-5.pdf,https://signals.ph
GROB-R2-U_ALL,fp,sample-5.pdf,https://signals.tab
GROB-R2-U_ALL,fp,sample-5.pdf,https://space.ba
GROB-R2-U_ALL,fp,sample-5.pdf,https://space.fi
GROB-R2-U_ALL,fp,sample-5.pdf,https://steering.fi
GROB-R2-U_ALL,fp,sample-5.pdf,https://subtracted.re
GROB-R2-U_ALL,fp,sample-5.pdf,https://surface.fi
GROB-R2-U_ALL,fp,sample-5.pdf,https://target.fi
GROB-R2-U_ALL,fp,sample-5.pdf,https://trackpad.int
GROB-R2-U_ALL,fp,sample-5.pdf,https://trajectory.pe
GROB-R2-U_ALL,fp,sample-5.pdf,https://trajectory.th
GROB-R2-U_ALL,fp,sample-5.pdf,https://truth.fo
GROB-R2-U_ALL,fp,sample-5.pdf,https://uncertainties.re
GROB-R2-U_ALL,fp,sample-5.pdf,https://users.fi
GROB-R2-U_ALL,fp,sample-5.pdf,https://value.it
GROB-R2-U_ALL,fp,sample-5.pdf,https://word.tab
GROB-R2-U_ALL,fp,sample-5.pdf,https://work.co
GROB-R2-U_ALL,fp,sample-5.pdf,https://work.tr
GROB-R2-U_ALL,fp,sample-5.pdf,https://works.tab
GROB-R2-U_ALL,fp,sample-5.pdf,https://www.pcmag.com
GROB-R2-U_ALL,fp,sample-5.pdf,https://www.roborealm.com/help/microsoftkinect.php
GROB-R2-U_ALL,fp,sample-6.pdf,https://0.tab
GROB-R2-U_ALL,fp,sample-6.pdf,https://1.fi
GROB-R2-U_ALL,fp,sample-6.pdf,https://1.in
GROB-R2-U_ALL,fp,sample-6.pdf,https://2008.la
GROB-R2-U_ALL,fp,sample-6.pdf,https://2008.mo
GROB-R2-U_ALL,fp,sample-6.pdf,https://analysis.se
GROB-R2-U_ALL,fp,sample-6.pdf,https://days.ac
GROB-R2-U_ALL,fp,sample-6.pdf,https://days.th
GROB-R2-U_ALL,fp,sample-6.pdf,https://december2008.tab
GROB-R2-U_ALL,fp,sample-6.pdf,https://happy.th
GROB-R2-U_ALL,fp,sample-6.pdf,https://period.in
GROB-R2-U_ALL,fp,sample-6.pdf,https://range.so
GROB-R2-U_ALL,fp,sample-6.pdf,https://receipts.al
GROB-R2-U_ALL,fp,sample-6.pdf,https://research.fi
GROB-R2-U_ALL,fp,sample-6.pdf,https://series.fi
GROB-R2-U_ALL,fp,sample-6.pdf,https://series.to
GROB-R2-U_ALL,fp,sample-6.pdf,https://site6.to
GROB-R2-U_ALL,fp,sample-6.pdf,https://std.er
GROB-R2-U_ALL,fp,sample-6.pdf,https://t.like
GROB-R2-U_ALL,fp,sample-6.pdf,https://thanksgiving.fi
GROB-R2-U_ALL,fp,sample-6.pdf,https://times.in
GROB-R2-U_ALL,fp,sample-6.pdf,https://twitter.com
GROB-R2-U_ALL,fp,sample-6.pdf,https://value.to
GROB-R2-U_ALL,fp,sample-6.pdf,https://values.how
GROB-R2-U_ALL,fp,sample-6.pdf,https://work.eu
GROB-R2-U_ALL,fp,sample-6.pdf,https://x.zeng@manchester.ac.uk
GROB-R2-U_ALL,fp,sample-7.pdf,https://egestas.int
GROB-R2-U_ALL,fp,sample-7.pdf,https://github.com/nirdslab/streaminghub-conduitintegersemperelitidvelitconsequat
GROB-R2-U_ALL,fp,sample-7.pdf,https://ornare.ae
GROB-R2-U_ALL,fp,sample-7.pdf,https://quis.nu
GROB-R2-U_ALL,fn,sample-1.pdf,https://sh.rice.edu/cognitive-engagement/ tabletgaze
GROB-R2-U_ALL,fn,sample-3.pdf,https://code.google.com/p/dkpro-similarity-asl
GROB-R2-U_ALL,fn,sample-3.pdf,https://www.ukp.tu-darmstadt.de
GROB-R2-U_ALL,fn,sample-5.pdf,"https://www.pcmag.com/article2/0,2817,2454187,00.asp"
GROB-R2-U_ALL,fn,sample-5.pdf,https://www.roborealm.com/help/microsoft kinect.php
GROB-R2-U_ALL,fn,sample-5.pdf,https://www.vicon.com
GROB-R2-U_ALL,fn,sample-6.pdf,https://www.ccs.neu.edu/home/amislove/twittermood
GROB-R2-U_ALL,fn,sample-7.pdf,https://github.com/nirdslab/streaminghub-conduit
GROB-R3-U_ALL,tp,sample-1.pdf,https://ait.ethz.ch/projects/2020/eth-xgaze
GROB-R3-U_ALL,tp,sample-1.pdf,https://ait.ethz.ch/projects/2020/eve
GROB-R3-U_ALL,tp,sample-1.pdf,https://cs.columbia.edu/cave/databases/columbia_gaze
GROB-R3-U_ALL,tp,sample-1.pdf,https://gaze360.csail.mit.edu
GROB-R3-U_ALL,tp,sample-1.pdf,https://gazecapture.csail.mit.edu
GROB-R3-U_ALL,tp,sample-1.pdf,https://github.com/cleardusk/3ddfa_v2
GROB-R3-U_ALL,tp,sample-1.pdf,https://github.com/dongzelian/multi-view-gaze
GROB-R3-U_ALL,tp,sample-1.pdf,https://github.com/kpzhang93/mtcnn_face_detection_alignment
GROB-R3-U_ALL,tp,sample-1.pdf,https://github.com/marekkowalski/deepalignmentnetwork
GROB-R3-U_ALL,tp,sample-1.pdf,https://github.com/tadasbaltrusaitis/openface
GROB-R3-U_ALL,tp,sample-1.pdf,https://github.com/tobias-fischer/rt_gene
GROB-R3-U_ALL,tp,sample-1.pdf,https://github.com/yadiraf/prnet
GROB-R3-U_ALL,tp,sample-1.pdf,https://idiap.ch/dataset/eyediap
GROB-R3-U_ALL,tp,sample-1.pdf,https://mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/research/gaze-based-human-computer-interaction/its-written-all-over-your-face-full-face-appearance-based-gaze-estimation
GROB-R3-U_ALL,tp,sample-1.pdf,https://mpi-inf.mpg.de/invisibleeye
GROB-R3-U_ALL,tp,sample-1.pdf,https://mpi-inf.mpg.de/mpiigaze
GROB-R3-U_ALL,tp,sample-1.pdf,https://phi-ai.org/gazehub
GROB-R3-U_ALL,tp,sample-1.pdf,https://pypi.org/project/dlib/19.6.0
GROB-R3-U_ALL,tp,sample-1.pdf,https://sites.google.com/nvidia.com/nvgaze
GROB-R3-U_ALL,tp,sample-1.pdf,https://ut-vision.org/datasets
GROB-R3-U_ALL,tp,sample-1.pdf,https://www.sciencedirect.com/science/article/pii/s0169814115000761
GROB-R3-U_ALL,tp,sample-1.pdf,https://www.sciencedirect.com/science/article/pii/s0262885614000171
GROB-R3-U_ALL,tp,sample-1.pdf,https://www.sciencedirect.com/science/article/pii/s092523121501783x
GROB-R3-U_ALL,tp,sample-1.pdf,https://www.sciencedirect.com/science/article/pii/s1878929316300846
GROB-R3-U_ALL,tp,sample-2.pdf,https://nlp.stanford.edu/projects/glove
GROB-R3-U_ALL,tp,sample-2.pdf,https://www.aaai.org
GROB-R3-U_ALL,tp,sample-3.pdf,https://code.google.com/p/dkpro-similarity-asl
GROB-R3-U_ALL,tp,sample-3.pdf,https://www.gutenberg.org
GROB-R3-U_ALL,tp,sample-3.pdf,https://www.ukp.tu-darmstadt.de/data/text-similarity/text-reuse-annotations
GROB-R3-U_ALL,tp,sample-3.pdf,https://www.wikipedia.org
GROB-R3-U_ALL,tp,sample-3.pdf,https://www.wiktionary.org
GROB-R3-U_ALL,tp,sample-4.pdf,https://aws.amazon.com/kinesis
GROB-R3-U_ALL,tp,sample-4.pdf,https://developers.google.com/protocol-buffers
GROB-R3-U_ALL,tp,sample-4.pdf,https://flink.apache.org
GROB-R3-U_ALL,tp,sample-4.pdf,https://github.com/nirdslab/streaminghub-conduit
GROB-R3-U_ALL,tp,sample-4.pdf,https://github.com/nirdslab/streaminghub-dfs
GROB-R3-U_ALL,tp,sample-4.pdf,https://github.com/sccn/labstreaminglayer
GROB-R3-U_ALL,tp,sample-4.pdf,https://idl.cs.washington.edu/papers/reactive-vega
GROB-R3-U_ALL,tp,sample-4.pdf,https://kepler-project.org
GROB-R3-U_ALL,tp,sample-4.pdf,https://mqtt.org
GROB-R3-U_ALL,tp,sample-4.pdf,https://nodered.org
GROB-R3-U_ALL,tp,sample-4.pdf,https://www.knime.com
GROB-R3-U_ALL,tp,sample-5.pdf,https://cinetics.com/two-axis360
GROB-R3-U_ALL,tp,sample-5.pdf,https://myscript.com/technology
GROB-R3-U_ALL,tp,sample-5.pdf,https://vubiq.com/v60wgd03
GROB-R3-U_ALL,tp,sample-5.pdf,https://warp.rice.edu/trac/wiki
GROB-R3-U_ALL,tp,sample-5.pdf,https://www.dailywireless.org/2014/01/03/60ghz-backhaul-for-small-cells
GROB-R3-U_ALL,tp,sample-5.pdf,https://www.mcelhearn.com/not-a-review-leap-motioncontroller-fails-in-normal-conditions
GROB-R3-U_ALL,tp,sample-5.pdf,https://www.tdk.com
GROB-R3-U_ALL,tp,sample-6.pdf,https://terramood.informatics.indiana.edu/data
GROB-R3-U_ALL,tp,sample-6.pdf,https://www.cs.pitt.edu/mpqa/opinionfinderrelease
GROB-R3-U_ALL,tp,sample-6.pdf,https://www.gallup.com/poll/122840/gallup-daily-economic-indexes.aspx
GROB-R3-U_ALL,tp,sample-6.pdf,https://www.sca.isr.umich.edu
GROB-R3-U_ALL,tp,sample-7.pdf,https://github.com/nirdslab/streaminghub-dfs
GROB-R3-U_ALL,tp,sample-7.pdf,https://www.cs.odu.edu/~sampath
GROB-R3-U_ALL,tp,sample-7.pdf,https://www.cs.odu.edu/~yasith
GROB-R3-U_ALL,tp,sample-8.pdf,https://github.com/nirdslab/streaminghub-conduit
GROB-R3-U_ALL,tp,sample-8.pdf,https://github.com/nirdslab/streaminghub-dfs
GROB-R3-U_ALL,tp,sample-8.pdf,https://www.cs.odu.edu/~sampath
GROB-R3-U_ALL,tp,sample-8.pdf,https://www.cs.odu.edu/~yasith
GROB-R3-U_ALL,fp,sample-5.pdf,https://www.pcmag.com
GROB-R3-U_ALL,fp,sample-5.pdf,https://www.roborealm.com/help/microsoftkinect.php
GROB-R3-U_ALL,fp,sample-6.pdf,https://x.zeng@manchester.ac.uk
GROB-R3-U_ALL,fp,sample-7.pdf,https://github.com/nirdslab/streaminghub-conduitintegersemperelitidvelitconsequat
GROB-R3-U_ALL,fn,sample-1.pdf,https://sh.rice.edu/cognitive-engagement/ tabletgaze
GROB-R3-U_ALL,fn,sample-3.pdf,https://www.ukp.tu-darmstadt.de
GROB-R3-U_ALL,fn,sample-5.pdf,"https://www.pcmag.com/article2/0,2817,2454187,00.asp"
GROB-R3-U_ALL,fn,sample-5.pdf,https://www.roborealm.com/help/microsoft kinect.php
GROB-R3-U_ALL,fn,sample-5.pdf,https://www.vicon.com
GROB-R3-U_ALL,fn,sample-6.pdf,https://www.ccs.neu.edu/home/amislove/twittermood
GROB-R3-U_ALL,fn,sample-7.pdf,https://github.com/nirdslab/streaminghub-conduit
GROB-R4-U_ALL,tp,sample-1.pdf,https://ait.ethz.ch/projects/2020/eth-xgaze
GROB-R4-U_ALL,tp,sample-1.pdf,https://ait.ethz.ch/projects/2020/eve
GROB-R4-U_ALL,tp,sample-1.pdf,https://cs.columbia.edu/cave/databases/columbia_gaze
GROB-R4-U_ALL,tp,sample-1.pdf,https://gaze360.csail.mit.edu
GROB-R4-U_ALL,tp,sample-1.pdf,https://gazecapture.csail.mit.edu
GROB-R4-U_ALL,tp,sample-1.pdf,https://github.com/cleardusk/3ddfa_v2
GROB-R4-U_ALL,tp,sample-1.pdf,https://github.com/dongzelian/multi-view-gaze
GROB-R4-U_ALL,tp,sample-1.pdf,https://github.com/kpzhang93/mtcnn_face_detection_alignment
GROB-R4-U_ALL,tp,sample-1.pdf,https://github.com/marekkowalski/deepalignmentnetwork
GROB-R4-U_ALL,tp,sample-1.pdf,https://github.com/tadasbaltrusaitis/openface
GROB-R4-U_ALL,tp,sample-1.pdf,https://github.com/tobias-fischer/rt_gene
GROB-R4-U_ALL,tp,sample-1.pdf,https://github.com/yadiraf/prnet
GROB-R4-U_ALL,tp,sample-1.pdf,https://idiap.ch/dataset/eyediap
GROB-R4-U_ALL,tp,sample-1.pdf,https://mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/research/gaze-based-human-computer-interaction/its-written-all-over-your-face-full-face-appearance-based-gaze-estimation
GROB-R4-U_ALL,tp,sample-1.pdf,https://mpi-inf.mpg.de/invisibleeye
GROB-R4-U_ALL,tp,sample-1.pdf,https://mpi-inf.mpg.de/mpiigaze
GROB-R4-U_ALL,tp,sample-1.pdf,https://phi-ai.org/gazehub
GROB-R4-U_ALL,tp,sample-1.pdf,https://pypi.org/project/dlib/19.6.0
GROB-R4-U_ALL,tp,sample-1.pdf,https://sites.google.com/nvidia.com/nvgaze
GROB-R4-U_ALL,tp,sample-1.pdf,https://ut-vision.org/datasets
GROB-R4-U_ALL,tp,sample-1.pdf,https://www.sciencedirect.com/science/article/pii/s0169814115000761
GROB-R4-U_ALL,tp,sample-1.pdf,https://www.sciencedirect.com/science/article/pii/s0262885614000171
GROB-R4-U_ALL,tp,sample-1.pdf,https://www.sciencedirect.com/science/article/pii/s092523121501783x
GROB-R4-U_ALL,tp,sample-1.pdf,https://www.sciencedirect.com/science/article/pii/s1878929316300846
GROB-R4-U_ALL,tp,sample-2.pdf,https://nlp.stanford.edu/projects/glove
GROB-R4-U_ALL,tp,sample-2.pdf,https://www.aaai.org
GROB-R4-U_ALL,tp,sample-3.pdf,https://www.gutenberg.org
GROB-R4-U_ALL,tp,sample-3.pdf,https://www.ukp.tu-darmstadt.de/data/text-similarity/text-reuse-annotations
GROB-R4-U_ALL,tp,sample-3.pdf,https://www.wikipedia.org
GROB-R4-U_ALL,tp,sample-3.pdf,https://www.wiktionary.org
GROB-R4-U_ALL,tp,sample-4.pdf,https://aws.amazon.com/kinesis
GROB-R4-U_ALL,tp,sample-4.pdf,https://developers.google.com/protocol-buffers
GROB-R4-U_ALL,tp,sample-4.pdf,https://flink.apache.org
GROB-R4-U_ALL,tp,sample-4.pdf,https://github.com/nirdslab/streaminghub-conduit
GROB-R4-U_ALL,tp,sample-4.pdf,https://github.com/nirdslab/streaminghub-dfs
GROB-R4-U_ALL,tp,sample-4.pdf,https://github.com/sccn/labstreaminglayer
GROB-R4-U_ALL,tp,sample-4.pdf,https://idl.cs.washington.edu/papers/reactive-vega
GROB-R4-U_ALL,tp,sample-4.pdf,https://kepler-project.org
GROB-R4-U_ALL,tp,sample-4.pdf,https://mqtt.org
GROB-R4-U_ALL,tp,sample-4.pdf,https://nodered.org
GROB-R4-U_ALL,tp,sample-4.pdf,https://www.knime.com
GROB-R4-U_ALL,tp,sample-5.pdf,https://cinetics.com/two-axis360
GROB-R4-U_ALL,tp,sample-5.pdf,https://myscript.com/technology
GROB-R4-U_ALL,tp,sample-5.pdf,https://vubiq.com/v60wgd03
GROB-R4-U_ALL,tp,sample-5.pdf,https://warp.rice.edu/trac/wiki
GROB-R4-U_ALL,tp,sample-5.pdf,https://www.dailywireless.org/2014/01/03/60ghz-backhaul-for-small-cells
GROB-R4-U_ALL,tp,sample-5.pdf,https://www.mcelhearn.com/not-a-review-leap-motioncontroller-fails-in-normal-conditions
GROB-R4-U_ALL,tp,sample-5.pdf,https://www.tdk.com
GROB-R4-U_ALL,tp,sample-6.pdf,https://terramood.informatics.indiana.edu/data
GROB-R4-U_ALL,tp,sample-6.pdf,https://www.cs.pitt.edu/mpqa/opinionfinderrelease
GROB-R4-U_ALL,tp,sample-6.pdf,https://www.gallup.com/poll/122840/gallup-daily-economic-indexes.aspx
GROB-R4-U_ALL,tp,sample-6.pdf,https://www.sca.isr.umich.edu
GROB-R4-U_ALL,tp,sample-7.pdf,https://github.com/nirdslab/streaminghub-dfs
GROB-R4-U_ALL,tp,sample-7.pdf,https://www.cs.odu.edu/~sampath
GROB-R4-U_ALL,tp,sample-7.pdf,https://www.cs.odu.edu/~yasith
GROB-R4-U_ALL,tp,sample-8.pdf,https://github.com/nirdslab/streaminghub-conduit
GROB-R4-U_ALL,tp,sample-8.pdf,https://github.com/nirdslab/streaminghub-dfs
GROB-R4-U_ALL,tp,sample-8.pdf,https://www.cs.odu.edu/~sampath
GROB-R4-U_ALL,tp,sample-8.pdf,https://www.cs.odu.edu/~yasith
GROB-R4-U_ALL,fp,sample-3.pdf,https://code.google.com
GROB-R4-U_ALL,fp,sample-5.pdf,https://www.pcmag.com
GROB-R4-U_ALL,fp,sample-5.pdf,https://www.roborealm.com/help/microsoftkinect.php
GROB-R4-U_ALL,fp,sample-6.pdf,https://x.zeng@manchester.ac.uk
GROB-R4-U_ALL,fp,sample-7.pdf,https://github.com/nirdslab/streaminghub-conduitintegersemperelitidvelitconsequat
GROB-R4-U_ALL,fn,sample-1.pdf,https://sh.rice.edu/cognitive-engagement/ tabletgaze
GROB-R4-U_ALL,fn,sample-3.pdf,https://code.google.com/p/dkpro-similarity-asl
GROB-R4-U_ALL,fn,sample-3.pdf,https://www.ukp.tu-darmstadt.de
GROB-R4-U_ALL,fn,sample-5.pdf,"https://www.pcmag.com/article2/0,2817,2454187,00.asp"
GROB-R4-U_ALL,fn,sample-5.pdf,https://www.roborealm.com/help/microsoft kinect.php
GROB-R4-U_ALL,fn,sample-5.pdf,https://www.vicon.com
GROB-R4-U_ALL,fn,sample-6.pdf,https://www.ccs.neu.edu/home/amislove/twittermood
GROB-R4-U_ALL,fn,sample-7.pdf,https://github.com/nirdslab/streaminghub-conduit
PDFM-R1-U_ALL,tp,sample-1.pdf,https://ait.ethz.ch/projects/2020/eth-xgaze
PDFM-R1-U_ALL,tp,sample-1.pdf,https://ait.ethz.ch/projects/2020/eve
PDFM-R1-U_ALL,tp,sample-1.pdf,https://cs.columbia.edu/cave/databases/columbia_gaze
PDFM-R1-U_ALL,tp,sample-1.pdf,https://gaze360.csail.mit.edu
PDFM-R1-U_ALL,tp,sample-1.pdf,https://gazecapture.csail.mit.edu
PDFM-R1-U_ALL,tp,sample-1.pdf,https://github.com/cleardusk/3ddfa_v2
PDFM-R1-U_ALL,tp,sample-1.pdf,https://github.com/dongzelian/multi-view-gaze
PDFM-R1-U_ALL,tp,sample-1.pdf,https://github.com/kpzhang93/mtcnn_face_detection_alignment
PDFM-R1-U_ALL,tp,sample-1.pdf,https://github.com/marekkowalski/deepalignmentnetwork
PDFM-R1-U_ALL,tp,sample-1.pdf,https://github.com/tadasbaltrusaitis/openface
PDFM-R1-U_ALL,tp,sample-1.pdf,https://github.com/tobias-fischer/rt_gene
PDFM-R1-U_ALL,tp,sample-1.pdf,https://github.com/yadiraf/prnet
PDFM-R1-U_ALL,tp,sample-1.pdf,https://idiap.ch/dataset/eyediap
PDFM-R1-U_ALL,tp,sample-1.pdf,https://mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/research/gaze-based-human-computer-interaction/its-written-all-over-your-face-full-face-appearance-based-gaze-estimation
PDFM-R1-U_ALL,tp,sample-1.pdf,https://mpi-inf.mpg.de/invisibleeye
PDFM-R1-U_ALL,tp,sample-1.pdf,https://mpi-inf.mpg.de/mpiigaze
PDFM-R1-U_ALL,tp,sample-1.pdf,https://phi-ai.org/gazehub
PDFM-R1-U_ALL,tp,sample-1.pdf,https://pypi.org/project/dlib/19.6.0
PDFM-R1-U_ALL,tp,sample-1.pdf,https://sites.google.com/nvidia.com/nvgaze
PDFM-R1-U_ALL,tp,sample-1.pdf,https://ut-vision.org/datasets
PDFM-R1-U_ALL,tp,sample-1.pdf,https://www.sciencedirect.com/science/article/pii/s0169814115000761
PDFM-R1-U_ALL,tp,sample-1.pdf,https://www.sciencedirect.com/science/article/pii/s0262885614000171
PDFM-R1-U_ALL,tp,sample-1.pdf,https://www.sciencedirect.com/science/article/pii/s092523121501783x
PDFM-R1-U_ALL,tp,sample-1.pdf,https://www.sciencedirect.com/science/article/pii/s1878929316300846
PDFM-R1-U_ALL,tp,sample-2.pdf,https://nlp.stanford.edu/projects/glove
PDFM-R1-U_ALL,tp,sample-2.pdf,https://www.aaai.org
PDFM-R1-U_ALL,tp,sample-3.pdf,https://code.google.com/p/dkpro-similarity-asl
PDFM-R1-U_ALL,tp,sample-3.pdf,https://www.wikipedia.org
PDFM-R1-U_ALL,tp,sample-3.pdf,https://www.wiktionary.org
PDFM-R1-U_ALL,tp,sample-4.pdf,https://aws.amazon.com/kinesis
PDFM-R1-U_ALL,tp,sample-4.pdf,https://developers.google.com/protocol-buffers
PDFM-R1-U_ALL,tp,sample-4.pdf,https://flink.apache.org
PDFM-R1-U_ALL,tp,sample-4.pdf,https://github.com/nirdslab/streaminghub-conduit
PDFM-R1-U_ALL,tp,sample-4.pdf,https://github.com/nirdslab/streaminghub-dfs
PDFM-R1-U_ALL,tp,sample-4.pdf,https://github.com/sccn/labstreaminglayer
PDFM-R1-U_ALL,tp,sample-4.pdf,https://idl.cs.washington.edu/papers/reactive-vega
PDFM-R1-U_ALL,tp,sample-4.pdf,https://kepler-project.org
PDFM-R1-U_ALL,tp,sample-4.pdf,https://mqtt.org
PDFM-R1-U_ALL,tp,sample-4.pdf,https://nodered.org
PDFM-R1-U_ALL,tp,sample-4.pdf,https://www.knime.com
PDFM-R1-U_ALL,tp,sample-5.pdf,https://cinetics.com/two-axis360
PDFM-R1-U_ALL,tp,sample-5.pdf,https://myscript.com/technology
PDFM-R1-U_ALL,tp,sample-5.pdf,https://vubiq.com/v60wgd03
PDFM-R1-U_ALL,tp,sample-5.pdf,https://warp.rice.edu/trac/wiki
PDFM-R1-U_ALL,tp,sample-5.pdf,"https://www.pcmag.com/article2/0,2817,2454187,00.asp"
PDFM-R1-U_ALL,tp,sample-5.pdf,https://www.tdk.com
PDFM-R1-U_ALL,tp,sample-5.pdf,https://www.vicon.com
PDFM-R1-U_ALL,tp,sample-6.pdf,https://www.ccs.neu.edu/home/amislove/twittermood
PDFM-R1-U_ALL,tp,sample-6.pdf,https://www.cs.pitt.edu/mpqa/opinionfinderrelease
PDFM-R1-U_ALL,tp,sample-6.pdf,https://www.gallup.com/poll/122840/gallup-daily-economic-indexes.aspx
PDFM-R1-U_ALL,tp,sample-6.pdf,https://www.sca.isr.umich.edu
PDFM-R1-U_ALL,tp,sample-7.pdf,https://github.com/nirdslab/streaminghub-conduit
PDFM-R1-U_ALL,tp,sample-7.pdf,https://github.com/nirdslab/streaminghub-dfs
PDFM-R1-U_ALL,tp,sample-7.pdf,https://www.cs.odu.edu/~sampath
PDFM-R1-U_ALL,tp,sample-7.pdf,https://www.cs.odu.edu/~yasith
PDFM-R1-U_ALL,tp,sample-8.pdf,https://github.com/nirdslab/streaminghub-conduit
PDFM-R1-U_ALL,tp,sample-8.pdf,https://github.com/nirdslab/streaminghub-dfs
PDFM-R1-U_ALL,tp,sample-8.pdf,https://www.cs.odu.edu/~sampath
PDFM-R1-U_ALL,tp,sample-8.pdf,https://www.cs.odu.edu/~yasith
PDFM-R1-U_ALL,fp,sample-1.pdf,https://08.new
PDFM-R1-U_ALL,fp,sample-1.pdf,https://11.tonsen
PDFM-R1-U_ALL,fp,sample-1.pdf,https://12.th
PDFM-R1-U_ALL,fp,sample-1.pdf,https://14.fi
PDFM-R1-U_ALL,fp,sample-1.pdf,https://16.new
PDFM-R1-U_ALL,fp,sample-1.pdf,https://1997.arxiv
PDFM-R1-U_ALL,fp,sample-1.pdf,https://5.ieee
PDFM-R1-U_ALL,fp,sample-1.pdf,https://ability.convolutional
PDFM-R1-U_ALL,fp,sample-1.pdf,https://accuracy.here
PDFM-R1-U_ALL,fp,sample-1.pdf,https://advance.th
PDFM-R1-U_ALL,fp,sample-1.pdf,https://appearance.although
PDFM-R1-U_ALL,fp,sample-1.pdf,https://appearance.to
PDFM-R1-U_ALL,fp,sample-1.pdf,https://applications.recently
PDFM-R1-U_ALL,fp,sample-1.pdf,https://author.fi
PDFM-R1-U_ALL,fp,sample-1.pdf,https://b.th
PDFM-R1-U_ALL,fp,sample-1.pdf,https://buaa.edu.cn
PDFM-R1-U_ALL,fp,sample-1.pdf,https://calibration.besides
PDFM-R1-U_ALL,fp,sample-1.pdf,https://camera.et
PDFM-R1-U_ALL,fp,sample-1.pdf,https://camera.in
PDFM-R1-U_ALL,fp,sample-1.pdf,https://camera.limited
PDFM-R1-U_ALL,fp,sample-1.pdf,https://cameras.collected
PDFM-R1-U_ALL,fp,sample-1.pdf,https://changes.deep
PDFM-R1-U_ALL,fp,sample-1.pdf,https://characteristics.perceptrons
PDFM-R1-U_ALL,fp,sample-1.pdf,https://cnns.in
PDFM-R1-U_ALL,fp,sample-1.pdf,https://corners.th
PDFM-R1-U_ALL,fp,sample-1.pdf,https://data.thus
PDFM-R1-U_ALL,fp,sample-1.pdf,https://dataset.therefore
PDFM-R1-U_ALL,fp,sample-1.pdf,https://direction.this
PDFM-R1-U_ALL,fp,sample-1.pdf,https://directions.th
PDFM-R1-U_ALL,fp,sample-1.pdf,https://domain.meta
PDFM-R1-U_ALL,fp,sample-1.pdf,https://domains.cu
PDFM-R1-U_ALL,fp,sample-1.pdf,https://environments.therefore
PDFM-R1-U_ALL,fp,sample-1.pdf,https://estimation.cheng
PDFM-R1-U_ALL,fp,sample-1.pdf,https://estimation.datasetsmethodstask
PDFM-R1-U_ALL,fp,sample-1.pdf,https://estimation.datasetstask
PDFM-R1-U_ALL,fp,sample-1.pdf,https://estimation.references
PDFM-R1-U_ALL,fp,sample-1.pdf,https://estimation.to
PDFM-R1-U_ALL,fp,sample-1.pdf,https://evaluation.th
PDFM-R1-U_ALL,fp,sample-1.pdf,https://eyeglasses.besides
PDFM-R1-U_ALL,fp,sample-1.pdf,https://eyes.fo
PDFM-R1-U_ALL,fp,sample-1.pdf,https://factors.th
PDFM-R1-U_ALL,fp,sample-1.pdf,https://feature.as
PDFM-R1-U_ALL,fp,sample-1.pdf,https://frame.also
PDFM-R1-U_ALL,fp,sample-1.pdf,https://front.th
PDFM-R1-U_ALL,fp,sample-1.pdf,https://gaze.given
PDFM-R1-U_ALL,fp,sample-1.pdf,https://gaze.more
PDFM-R1-U_ALL,fp,sample-1.pdf,https://gaze.pervised
PDFM-R1-U_ALL,fp,sample-1.pdf,https://ii.after
PDFM-R1-U_ALL,fp,sample-1.pdf,https://illumination.collected
PDFM-R1-U_ALL,fp,sample-1.pdf,https://image.as
PDFM-R1-U_ALL,fp,sample-1.pdf,https://image.fi
PDFM-R1-U_ALL,fp,sample-1.pdf,https://images.fi
PDFM-R1-U_ALL,fp,sample-1.pdf,https://images.however
PDFM-R1-U_ALL,fp,sample-1.pdf,https://images.some
PDFM-R1-U_ALL,fp,sample-1.pdf,https://images.then
PDFM-R1-U_ALL,fp,sample-1.pdf,https://images.therefore
PDFM-R1-U_ALL,fp,sample-1.pdf,https://images.tw
PDFM-R1-U_ALL,fp,sample-1.pdf,https://information.rotation
PDFM-R1-U_ALL,fp,sample-1.pdf,https://landmarks.th
PDFM-R1-U_ALL,fp,sample-1.pdf,https://learning.as
PDFM-R1-U_ALL,fp,sample-1.pdf,https://learning.source
PDFM-R1-U_ALL,fp,sample-1.pdf,https://looking.it
PDFM-R1-U_ALL,fp,sample-1.pdf,https://map.th
PDFM-R1-U_ALL,fp,sample-1.pdf,https://margin.these
PDFM-R1-U_ALL,fp,sample-1.pdf,https://method.they
PDFM-R1-U_ALL,fp,sample-1.pdf,https://methods.computer
PDFM-R1-U_ALL,fp,sample-1.pdf,https://methods.glintneural
PDFM-R1-U_ALL,fp,sample-1.pdf,https://methods.in
PDFM-R1-U_ALL,fp,sample-1.pdf,https://methods.th
PDFM-R1-U_ALL,fp,sample-1.pdf,https://methodsnamesyearspub.linksdlib
PDFM-R1-U_ALL,fp,sample-1.pdf,https://model.cnndecoderlandmarkgazefchead
PDFM-R1-U_ALL,fp,sample-1.pdf,https://movement.tw
PDFM-R1-U_ALL,fp,sample-1.pdf,https://network.gaze
PDFM-R1-U_ALL,fp,sample-1.pdf,https://networks.some
PDFM-R1-U_ALL,fp,sample-1.pdf,https://orientation.deng
PDFM-R1-U_ALL,fp,sample-1.pdf,https://orthogonality.th
PDFM-R1-U_ALL,fp,sample-1.pdf,https://p.cheng
PDFM-R1-U_ALL,fp,sample-1.pdf,https://parameters.th
PDFM-R1-U_ALL,fp,sample-1.pdf,https://pcl.ac.cn
PDFM-R1-U_ALL,fp,sample-1.pdf,https://performance.they
PDFM-R1-U_ALL,fp,sample-1.pdf,https://platform.accuracy
PDFM-R1-U_ALL,fp,sample-1.pdf,https://platforms.besides
PDFM-R1-U_ALL,fp,sample-1.pdf,https://pog.methodsmpiifacegaze
PDFM-R1-U_ALL,fp,sample-1.pdf,https://pose.as
PDFM-R1-U_ALL,fp,sample-1.pdf,https://problem.although
PDFM-R1-U_ALL,fp,sample-1.pdf,https://problem.th
PDFM-R1-U_ALL,fp,sample-1.pdf,https://processing.ieee
PDFM-R1-U_ALL,fp,sample-1.pdf,https://progress.by
PDFM-R1-U_ALL,fp,sample-1.pdf,https://progress.fi
PDFM-R1-U_ALL,fp,sample-1.pdf,https://regression.cheng
PDFM-R1-U_ALL,fp,sample-1.pdf,https://research.here
PDFM-R1-U_ALL,fp,sample-1.pdf,https://research.implemented
PDFM-R1-U_ALL,fp,sample-1.pdf,https://resources.fixed
PDFM-R1-U_ALL,fp,sample-1.pdf,https://resources.free
PDFM-R1-U_ALL,fp,sample-1.pdf,https://samples.th
PDFM-R1-U_ALL,fp,sample-1.pdf,https://screen.note
PDFM-R1-U_ALL,fp,sample-1.pdf,https://scs.rectification
PDFM-R1-U_ALL,fp,sample-1.pdf,https://scs.th
PDFM-R1-U_ALL,fp,sample-1.pdf,https://ser.ch
PDFM-R1-U_ALL,fp,sample-1.pdf,https://setting.etc.ir
PDFM-R1-U_ALL,fp,sample-1.pdf,https://sh.rice.edu/cognitive-engagement/tabletgaze
PDFM-R1-U_ALL,fp,sample-1.pdf,https://subject.their
PDFM-R1-U_ALL,fp,sample-1.pdf,https://variables.given
PDFM-R1-U_ALL,fp,sample-1.pdf,https://vc.sc
PDFM-R1-U_ALL,fp,sample-1.pdf,https://w.r.t.th
PDFM-R1-U_ALL,fp,sample-1.pdf,https://zone.limited
PDFM-R1-U_ALL,fp,sample-1.pdf,https://zone.sufficient
PDFM-R1-U_ALL,fp,sample-2.pdf,https://1.0.th
PDFM-R1-U_ALL,fp,sample-2.pdf,https://1.general
PDFM-R1-U_ALL,fp,sample-2.pdf,https://1064-1074.maas
PDFM-R1-U_ALL,fp,sample-2.pdf,https://1312.6026.santos
PDFM-R1-U_ALL,fp,sample-2.pdf,https://1412.6980.lample
PDFM-R1-U_ALL,fp,sample-2.pdf,https://1602.06023.pascanu
PDFM-R1-U_ALL,fp,sample-2.pdf,https://1609.01704.chung
PDFM-R1-U_ALL,fp,sample-2.pdf,https://1650-1659.chiu
PDFM-R1-U_ALL,fp,sample-2.pdf,https://1708.06834.chang
PDFM-R1-U_ALL,fp,sample-2.pdf,https://1735-1780.huang
PDFM-R1-U_ALL,fp,sample-2.pdf,https://1818-1826.se
PDFM-R1-U_ALL,fp,sample-2.pdf,https://1880-1890.zaremba
PDFM-R1-U_ALL,fp,sample-2.pdf,https://2013.how
PDFM-R1-U_ALL,fp,sample-2.pdf,https://2017.arxiv
PDFM-R1-U_ALL,fp,sample-2.pdf,https://2018.latent
PDFM-R1-U_ALL,fp,sample-2.pdf,https://234-239.mujika
PDFM-R1-U_ALL,fp,sample-2.pdf,https://2670-2680.sutskever
PDFM-R1-U_ALL,fp,sample-2.pdf,https://2741-2749.kingma
PDFM-R1-U_ALL,fp,sample-2.pdf,https://2775-2785.nallapati
PDFM-R1-U_ALL,fp,sample-2.pdf,https://3079-3087.deng
PDFM-R1-U_ALL,fp,sample-2.pdf,https://3104-3112.tjong
PDFM-R1-U_ALL,fp,sample-2.pdf,https://313-330.merity
PDFM-R1-U_ALL,fp,sample-2.pdf,https://3776-3784.strubell
PDFM-R1-U_ALL,fp,sample-2.pdf,https://462-471.ma
PDFM-R1-U_ALL,fp,sample-2.pdf,https://493-499.gal
PDFM-R1-U_ALL,fp,sample-2.pdf,https://5917-5926.nachum
PDFM-R1-U_ALL,fp,sample-2.pdf,https://76-86.chen
PDFM-R1-U_ALL,fp,sample-2.pdf,https://ac-tion.actions
PDFM-R1-U_ALL,fp,sample-2.pdf,https://agent.next
PDFM-R1-U_ALL,fp,sample-2.pdf,https://agent.sequential
PDFM-R1-U_ALL,fp,sample-2.pdf,https://algorithm.also
PDFM-R1-U_ALL,fp,sample-2.pdf,https://as-pects.approachin
PDFM-R1-U_ALL,fp,sample-2.pdf,https://cases.this
PDFM-R1-U_ALL,fp,sample-2.pdf,https://categories.th
PDFM-R1-U_ALL,fp,sample-2.pdf,https://computation.reward
PDFM-R1-U_ALL,fp,sample-2.pdf,https://connections.th
PDFM-R1-U_ALL,fp,sample-2.pdf,https://ct.language
PDFM-R1-U_ALL,fp,sample-2.pdf,https://datasets.because
PDFM-R1-U_ALL,fp,sample-2.pdf,https://dependencies.th
PDFM-R1-U_ALL,fp,sample-2.pdf,https://dependency.ltht
PDFM-R1-U_ALL,fp,sample-2.pdf,https://dependency.some
PDFM-R1-U_ALL,fp,sample-2.pdf,https://e.2015.recognition
PDFM-R1-U_ALL,fp,sample-2.pdf,https://fudan.edu.cn
PDFM-R1-U_ALL,fp,sample-2.pdf,https://gradients.to
PDFM-R1-U_ALL,fp,sample-2.pdf,https://hours.table
PDFM-R1-U_ALL,fp,sample-2.pdf,https://in-formation.fo
PDFM-R1-U_ALL,fp,sample-2.pdf,https://legislation.you
PDFM-R1-U_ALL,fp,sample-2.pdf,https://length.however
PDFM-R1-U_ALL,fp,sample-2.pdf,https://lstm.number
PDFM-R1-U_ALL,fp,sample-2.pdf,https://methods.acknowledgmentsthe
PDFM-R1-U_ALL,fp,sample-2.pdf,https://model.th
PDFM-R1-U_ALL,fp,sample-2.pdf,https://operator.represent
PDFM-R1-U_ALL,fp,sample-2.pdf,https://path.through
PDFM-R1-U_ALL,fp,sample-2.pdf,https://problem.th
PDFM-R1-U_ALL,fp,sample-2.pdf,https://r.arxiv
PDFM-R1-U_ALL,fp,sample-2.pdf,https://report.th
PDFM-R1-U_ALL,fp,sample-2.pdf,https://reserved.figure
PDFM-R1-U_ALL,fp,sample-2.pdf,https://sequence.to
PDFM-R1-U_ALL,fp,sample-2.pdf,https://set.sentiment
PDFM-R1-U_ALL,fp,sample-2.pdf,https://skip.related
PDFM-R1-U_ALL,fp,sample-2.pdf,https://space.to
PDFM-R1-U_ALL,fp,sample-2.pdf,https://task.th
PDFM-R1-U_ALL,fp,sample-2.pdf,https://tasks.conclusionsin
PDFM-R1-U_ALL,fp,sample-2.pdf,https://tasks.th
PDFM-R1-U_ALL,fp,sample-2.pdf,https://testing.name
PDFM-R1-U_ALL,fp,sample-2.pdf,https://text.in
PDFM-R1-U_ALL,fp,sample-2.pdf,https://thl.th
PDFM-R1-U_ALL,fp,sample-2.pdf,https://truth.recurrent
PDFM-R1-U_ALL,fp,sample-2.pdf,https://uncertain.therefore
PDFM-R1-U_ALL,fp,sample-2.pdf,https://words.since
PDFM-R1-U_ALL,fp,sample-2.pdf,https://y.cal
PDFM-R1-U_ALL,fp,sample-3.pdf,https://2.1contentsimilarityprobablytheeasiestwaytoreusetextisverbatimcopying.itcanbedetectedbyusingstringmeasureswhichoperateonsubstringsequences.thelongestcommonsubstringmeasure
PDFM-R1-U_ALL,fp,sample-3.pdf,https://811.itoutperformsthebestreferencesystembycloughandstevenson
PDFM-R1-U_ALL,fp,sample-3.pdf,https://852.theresultsreportedbyburrowsetal
PDFM-R1-U_ALL,fp,sample-3.pdf,https://andcomputesfeaturevectorsoftheirfrequenciesforeachpossiblyreuseddocumentandthesourcetext.thecomparisonofthevectorsisthenperformedusingpearson
PDFM-R1-U_ALL,fp,sample-3.pdf,https://deletions.greedystringtiling
PDFM-R1-U_ALL,fp,sample-3.pdf,https://duplicateswithveryhighsimilarityscoresareinfactnegativesamples.resultswesummarizetheresultsonthisdatasetintable8.eventhoughtheferretbaselineisastrongcompetitor
PDFM-R1-U_ALL,fp,sample-3.pdf,https://expectedclassvs.classificationresult
PDFM-R1-U_ALL,fp,sample-3.pdf,https://forcomparingtexts.theconstructionofthesemanticspacewasdoneusingtheevaluationcorpora
PDFM-R1-U_ALL,fp,sample-3.pdf,https://i.e.paraphrasing
PDFM-R1-U_ALL,fp,sample-3.pdf,https://i.e.thepatexthasbeenusedexclusivelyastextreusesource
PDFM-R1-U_ALL,fp,sample-3.pdf,https://implementedtheremainingsystems.thisappliestoallresulttablesinthispaper
PDFM-R1-U_ALL,fp,sample-3.pdf,https://smechanicalturk.inproceedingsofthenaaclhltworkshoponcreatingspeechandlanguagedatawithamazon
PDFM-R1-U_ALL,fp,sample-3.pdf,https://theirbestscorewasachievedbyusingak-nearestneighborclassifierwithafeaturesetof10similaritymeasures.theyexclusivelyusedsimilaritymeasuresthatoperateonthetexts
PDFM-R1-U_ALL,fp,sample-3.pdf,https://www.ukp.tu-darmstadt.de/data/text-similarity/text-reuse-annotations12strengthofagreementforkvaluesaccordingtolandisandkoch
PDFM-R1-U_ALL,fp,sample-4.pdf,https://applications.streaminghub
PDFM-R1-U_ALL,fp,sample-4.pdf,https://back.usage
PDFM-R1-U_ALL,fp,sample-4.pdf,https://clemson.edu
PDFM-R1-U_ALL,fp,sample-4.pdf,https://cs.odu.edu
PDFM-R1-U_ALL,fp,sample-4.pdf,https://date.figure
PDFM-R1-U_ALL,fp,sample-4.pdf,https://dfs.table
PDFM-R1-U_ALL,fp,sample-4.pdf,https://forstreaming.figure
PDFM-R1-U_ALL,fp,sample-4.pdf,https://github11.acknowledgementsthis
PDFM-R1-U_ALL,fp,sample-4.pdf,https://optimizations.growth
PDFM-R1-U_ALL,fp,sample-4.pdf,https://order.figure
PDFM-R1-U_ALL,fp,sample-4.pdf,https://paradigms.ac
PDFM-R1-U_ALL,fp,sample-4.pdf,https://purposes.in
PDFM-R1-U_ALL,fp,sample-4.pdf,https://recorded.moreover
PDFM-R1-U_ALL,fp,sample-4.pdf,https://results.keywordsmetadata
PDFM-R1-U_ALL,fp,sample-4.pdf,https://sponsors.references
PDFM-R1-U_ALL,fp,sample-4.pdf,https://streaminghub.using
PDFM-R1-U_ALL,fp,sample-4.pdf,https://streams.here
PDFM-R1-U_ALL,fp,sample-4.pdf,https://workflows.as
PDFM-R1-U_ALL,fp,sample-4.pdf,https://workflows.to
PDFM-R1-U_ALL,fp,sample-5.pdf,https://2003.appendixa
PDFM-R1-U_ALL,fp,sample-5.pdf,https://350regen.phasecase
PDFM-R1-U_ALL,fp,sample-5.pdf,https://8.tracking
PDFM-R1-U_ALL,fp,sample-5.pdf,https://a.from
PDFM-R1-U_ALL,fp,sample-5.pdf,https://accuracy.peaks
PDFM-R1-U_ALL,fp,sample-5.pdf,https://acm.ac
PDFM-R1-U_ALL,fp,sample-5.pdf,https://acm.org
PDFM-R1-U_ALL,fp,sample-5.pdf,https://algorithms.since
PDFM-R1-U_ALL,fp,sample-5.pdf,https://angles.figure
PDFM-R1-U_ALL,fp,sample-5.pdf,https://antenna.figure
PDFM-R1-U_ALL,fp,sample-5.pdf,https://antennas.using
PDFM-R1-U_ALL,fp,sample-5.pdf,https://apa.figure
PDFM-R1-U_ALL,fp,sample-5.pdf,https://apa.recall
PDFM-R1-U_ALL,fp,sample-5.pdf,https://as-sumption.to
PDFM-R1-U_ALL,fp,sample-5.pdf,https://back-ground.in
PDFM-R1-U_ALL,fp,sample-5.pdf,https://background.figure
PDFM-R1-U_ALL,fp,sample-5.pdf,https://beam-steering.data
PDFM-R1-U_ALL,fp,sample-5.pdf,https://beam-steering.toemulate
PDFM-R1-U_ALL,fp,sample-5.pdf,https://beamwidth.to
PDFM-R1-U_ALL,fp,sample-5.pdf,https://bg.figure
PDFM-R1-U_ALL,fp,sample-5.pdf,https://blocked.however
PDFM-R1-U_ALL,fp,sample-5.pdf,https://classification.paramscomplexitylatencybg
PDFM-R1-U_ALL,fp,sample-5.pdf,https://counting.to
PDFM-R1-U_ALL,fp,sample-5.pdf,https://default.bot
PDFM-R1-U_ALL,fp,sample-5.pdf,https://desktop.this
PDFM-R1-U_ALL,fp,sample-5.pdf,https://detected.accuracy
PDFM-R1-U_ALL,fp,sample-5.pdf,https://detection.figure
PDFM-R1-U_ALL,fp,sample-5.pdf,https://differentusers.figure
PDFM-R1-U_ALL,fp,sample-5.pdf,https://direction.th
PDFM-R1-U_ALL,fp,sample-5.pdf,https://directions.counters
PDFM-R1-U_ALL,fp,sample-5.pdf,https://distance.th
PDFM-R1-U_ALL,fp,sample-5.pdf,https://drops.nonetheless
PDFM-R1-U_ALL,fp,sample-5.pdf,https://events.phase
PDFM-R1-U_ALL,fp,sample-5.pdf,https://fc.from
PDFM-R1-U_ALL,fp,sample-5.pdf,https://feasible.these
PDFM-R1-U_ALL,fp,sample-5.pdf,https://france.copyright
PDFM-R1-U_ALL,fp,sample-5.pdf,https://gain.th
PDFM-R1-U_ALL,fp,sample-5.pdf,https://hypothesis.it
PDFM-R1-U_ALL,fp,sample-5.pdf,https://interest.to
PDFM-R1-U_ALL,fp,sample-5.pdf,https://kinect.ph
PDFM-R1-U_ALL,fp,sample-5.pdf,https://known.consider
PDFM-R1-U_ALL,fp,sample-5.pdf,https://large.by
PDFM-R1-U_ALL,fp,sample-5.pdf,https://larger.figure
PDFM-R1-U_ALL,fp,sample-5.pdf,https://level.impact
PDFM-R1-U_ALL,fp,sample-5.pdf,https://linearw.r.t.target
PDFM-R1-U_ALL,fp,sample-5.pdf,https://ma-terials.figure
PDFM-R1-U_ALL,fp,sample-5.pdf,https://ma-terials.large
PDFM-R1-U_ALL,fp,sample-5.pdf,https://mm.background
PDFM-R1-U_ALL,fp,sample-5.pdf,https://mmwave.it
PDFM-R1-U_ALL,fp,sample-5.pdf,https://mtrack.first
PDFM-R1-U_ALL,fp,sample-5.pdf,https://negligible.figure
PDFM-R1-U_ALL,fp,sample-5.pdf,https://noise.minimizes
PDFM-R1-U_ALL,fp,sample-5.pdf,https://object.simply
PDFM-R1-U_ALL,fp,sample-5.pdf,https://objects.considering
PDFM-R1-U_ALL,fp,sample-5.pdf,https://obtained.this
PDFM-R1-U_ALL,fp,sample-5.pdf,https://op-erations.notably
PDFM-R1-U_ALL,fp,sample-5.pdf,https://opportunisticcalibration.figure
PDFM-R1-U_ALL,fp,sample-5.pdf,https://peaks.8.implementation
PDFM-R1-U_ALL,fp,sample-5.pdf,https://phase-tracking.figure
PDFM-R1-U_ALL,fp,sample-5.pdf,https://phase-tracking.suppose
PDFM-R1-U_ALL,fp,sample-5.pdf,https://phase.onl
PDFM-R1-U_ALL,fp,sample-5.pdf,https://phase.target
PDFM-R1-U_ALL,fp,sample-5.pdf,https://platform.figure
PDFM-R1-U_ALL,fp,sample-5.pdf,https://position.mtrack
PDFM-R1-U_ALL,fp,sample-5.pdf,https://r.choudhury
PDFM-R1-U_ALL,fp,sample-5.pdf,https://radios.second
PDFM-R1-U_ALL,fp,sample-5.pdf,https://radios.table
PDFM-R1-U_ALL,fp,sample-5.pdf,https://receiver.in
PDFM-R1-U_ALL,fp,sample-5.pdf,https://reflection.combating
PDFM-R1-U_ALL,fp,sample-5.pdf,https://reflection.figure
PDFM-R1-U_ALL,fp,sample-5.pdf,https://reflection.th
PDFM-R1-U_ALL,fp,sample-5.pdf,https://region.figure
PDFM-R1-U_ALL,fp,sample-5.pdf,https://respectively.bot
PDFM-R1-U_ALL,fp,sample-5.pdf,https://response.mtrack
PDFM-R1-U_ALL,fp,sample-5.pdf,https://rx.in
PDFM-R1-U_ALL,fp,sample-5.pdf,https://sensingapplications.acknowledgementwe
PDFM-R1-U_ALL,fp,sample-5.pdf,https://shifting.to
PDFM-R1-U_ALL,fp,sample-5.pdf,https://shortperiod.figure
PDFM-R1-U_ALL,fp,sample-5.pdf,https://signals.table
PDFM-R1-U_ALL,fp,sample-5.pdf,https://space.background
PDFM-R1-U_ALL,fp,sample-5.pdf,https://splineinterpolation.figure
PDFM-R1-U_ALL,fp,sample-5.pdf,https://steering.figure
PDFM-R1-U_ALL,fp,sample-5.pdf,https://strength.figure
PDFM-R1-U_ALL,fp,sample-5.pdf,https://subtracted.regeneration
PDFM-R1-U_ALL,fp,sample-5.pdf,https://surface.figure
PDFM-R1-U_ALL,fp,sample-5.pdf,https://target.fo
PDFM-R1-U_ALL,fp,sample-5.pdf,https://target.however
PDFM-R1-U_ALL,fp,sample-5.pdf,https://target.steers
PDFM-R1-U_ALL,fp,sample-5.pdf,https://target.this
PDFM-R1-U_ALL,fp,sample-5.pdf,https://tracking.in
PDFM-R1-U_ALL,fp,sample-5.pdf,https://tracking.mtrack
PDFM-R1-U_ALL,fp,sample-5.pdf,https://tracking.passive
PDFM-R1-U_ALL,fp,sample-5.pdf,https://trackpad.categories
PDFM-R1-U_ALL,fp,sample-5.pdf,https://trajectory.th
PDFM-R1-U_ALL,fp,sample-5.pdf,https://truth.following
PDFM-R1-U_ALL,fp,sample-5.pdf,https://uncertainties.remarkably
PDFM-R1-U_ALL,fp,sample-5.pdf,https://value.it
PDFM-R1-U_ALL,fp,sample-5.pdf,https://variation.mtrack
PDFM-R1-U_ALL,fp,sample-5.pdf,https://wisc.edu
PDFM-R1-U_ALL,fp,sample-5.pdf,https://word.figure
PDFM-R1-U_ALL,fp,sample-5.pdf,https://work.tracking
PDFM-R1-U_ALL,fp,sample-5.pdf,https://works.men
PDFM-R1-U_ALL,fp,sample-5.pdf,https://www.dailywireless.org/2014/01/03
PDFM-R1-U_ALL,fp,sample-5.pdf,https://www.mcelhearn.com/not-a-review-leap-motioncontroller-fails-
PDFM-R1-U_ALL,fp,sample-5.pdf,https://www.roborealm.com/help/microsoft
PDFM-R1-U_ALL,fp,sample-6.pdf,https://1.fi
PDFM-R1-U_ALL,fp,sample-6.pdf,https://1.in
PDFM-R1-U_ALL,fp,sample-6.pdf,https://1.table
PDFM-R1-U_ALL,fp,sample-6.pdf,https://19.market
PDFM-R1-U_ALL,fp,sample-6.pdf,https://2.tracking
PDFM-R1-U_ALL,fp,sample-6.pdf,https://2008.th
PDFM-R1-U_ALL,fp,sample-6.pdf,https://analysis.second
PDFM-R1-U_ALL,fp,sample-6.pdf,https://areas.th
PDFM-R1-U_ALL,fp,sample-6.pdf,https://changes.most
PDFM-R1-U_ALL,fp,sample-6.pdf,https://characters.after
PDFM-R1-U_ALL,fp,sample-6.pdf,https://content.this
PDFM-R1-U_ALL,fp,sample-6.pdf,https://days.th
PDFM-R1-U_ALL,fp,sample-6.pdf,https://dimensions.parameterscalm
PDFM-R1-U_ALL,fp,sample-6.pdf,https://djia.granger
PDFM-R1-U_ALL,fp,sample-6.pdf,https://ec.sc
PDFM-R1-U_ALL,fp,sample-6.pdf,https://errors.second
PDFM-R1-U_ALL,fp,sample-6.pdf,https://h.cootner
PDFM-R1-U_ALL,fp,sample-6.pdf,https://happy.th
PDFM-R1-U_ALL,fp,sample-6.pdf,https://indiana.edu
PDFM-R1-U_ALL,fp,sample-6.pdf,https://l.retrieval
PDFM-R1-U_ALL,fp,sample-6.pdf,https://later.surprisingly
PDFM-R1-U_ALL,fp,sample-6.pdf,https://manchester.ac.uk
PDFM-R1-U_ALL,fp,sample-6.pdf,https://market.johan
PDFM-R1-U_ALL,fp,sample-6.pdf,https://ourwork.references
PDFM-R1-U_ALL,fp,sample-6.pdf,https://period.in
PDFM-R1-U_ALL,fp,sample-6.pdf,https://periods.fi
PDFM-R1-U_ALL,fp,sample-6.pdf,https://prediction.large
PDFM-R1-U_ALL,fp,sample-6.pdf,https://prices.since
PDFM-R1-U_ALL,fp,sample-6.pdf,https://range.sofnn
PDFM-R1-U_ALL,fp,sample-6.pdf,https://receipts.although
PDFM-R1-U_ALL,fp,sample-6.pdf,https://research.acknowledgmentthis
PDFM-R1-U_ALL,fp,sample-6.pdf,https://series.as
PDFM-R1-U_ALL,fp,sample-6.pdf,https://series.to
PDFM-R1-U_ALL,fp,sample-6.pdf,https://site6.to
PDFM-R1-U_ALL,fp,sample-6.pdf,https://states.bibliography
PDFM-R1-U_ALL,fp,sample-6.pdf,https://std.er
PDFM-R1-U_ALL,fp,sample-6.pdf,https://t.like
PDFM-R1-U_ALL,fp,sample-6.pdf,https://thanksgiving.mood
PDFM-R1-U_ALL,fp,sample-6.pdf,https://times.in
PDFM-R1-U_ALL,fp,sample-6.pdf,https://twitter.com
PDFM-R1-U_ALL,fp,sample-6.pdf,https://value.to
PDFM-R1-U_ALL,fp,sample-6.pdf,https://xt-n.fi
PDFM-R1-U_ALL,fp,sample-7.pdf,https://arcu.se
PDFM-R1-U_ALL,fp,sample-7.pdf,https://cursus.aliquam
PDFM-R1-U_ALL,fp,sample-7.pdf,https://egestas.integer
PDFM-R1-U_ALL,fp,sample-7.pdf,https://faucibus.na
PDFM-R1-U_ALL,fp,sample-7.pdf,https://finibusfinibus.donec
PDFM-R1-U_ALL,fp,sample-7.pdf,https://leo.donec
PDFM-R1-U_ALL,fp,sample-7.pdf,https://magna.suspendisse
PDFM-R1-U_ALL,fp,sample-7.pdf,https://maximusornare.nulla
PDFM-R1-U_ALL,fp,sample-7.pdf,https://ornare.se
PDFM-R1-U_ALL,fp,sample-7.pdf,https://purus.curabitur
PDFM-R1-U_ALL,fp,sample-7.pdf,https://purus.in
PDFM-R1-U_ALL,fp,sample-7.pdf,https://quis.nullam
PDFM-R1-U_ALL,fp,sample-7.pdf,https://tincidunt.se
PDFM-R1-U_ALL,fp,sample-8.pdf,https://arcu.se
PDFM-R1-U_ALL,fp,sample-8.pdf,https://cursus.aliquam
PDFM-R1-U_ALL,fp,sample-8.pdf,https://egestas.integer
PDFM-R1-U_ALL,fp,sample-8.pdf,https://finibusfinibus.donec
PDFM-R1-U_ALL,fp,sample-8.pdf,https://leo.donec
PDFM-R1-U_ALL,fp,sample-8.pdf,https://magna.suspendisse
PDFM-R1-U_ALL,fp,sample-8.pdf,https://ornare.nulla
PDFM-R1-U_ALL,fp,sample-8.pdf,https://purus.curabitur
PDFM-R1-U_ALL,fp,sample-8.pdf,https://purus.in
PDFM-R1-U_ALL,fp,sample-8.pdf,https://quis.nullam
PDFM-R1-U_ALL,fp,sample-8.pdf,https://tincidunt.se
PDFM-R1-U_ALL,fn,sample-1.pdf,https://sh.rice.edu/cognitive-engagement/ tabletgaze
PDFM-R1-U_ALL,fn,sample-3.pdf,https://www.gutenberg.org
PDFM-R1-U_ALL,fn,sample-3.pdf,https://www.ukp.tu-darmstadt.de
PDFM-R1-U_ALL,fn,sample-3.pdf,https://www.ukp.tu-darmstadt.de/data/text-similarity/text-reuse-annotations
PDFM-R1-U_ALL,fn,sample-5.pdf,https://www.dailywireless.org/2014/01/03/60ghz-backhaul-for-small-cells
PDFM-R1-U_ALL,fn,sample-5.pdf,https://www.mcelhearn.com/not-a-review-leap-motioncontroller-fails-in-normal-conditions
PDFM-R1-U_ALL,fn,sample-5.pdf,https://www.roborealm.com/help/microsoft kinect.php
PDFM-R1-U_ALL,fn,sample-6.pdf,https://terramood.informatics.indiana.edu/data
PDFM-R2-U_ALL,tp,sample-1.pdf,https://ait.ethz.ch/projects/2020/eth-xgaze
PDFM-R2-U_ALL,tp,sample-1.pdf,https://ait.ethz.ch/projects/2020/eve
PDFM-R2-U_ALL,tp,sample-1.pdf,https://cs.columbia.edu/cave/databases/columbia_gaze
PDFM-R2-U_ALL,tp,sample-1.pdf,https://gaze360.csail.mit.edu
PDFM-R2-U_ALL,tp,sample-1.pdf,https://gazecapture.csail.mit.edu
PDFM-R2-U_ALL,tp,sample-1.pdf,https://github.com/cleardusk/3ddfa_v2
PDFM-R2-U_ALL,tp,sample-1.pdf,https://github.com/dongzelian/multi-view-gaze
PDFM-R2-U_ALL,tp,sample-1.pdf,https://github.com/kpzhang93/mtcnn_face_detection_alignment
PDFM-R2-U_ALL,tp,sample-1.pdf,https://github.com/marekkowalski/deepalignmentnetwork
PDFM-R2-U_ALL,tp,sample-1.pdf,https://github.com/tadasbaltrusaitis/openface
PDFM-R2-U_ALL,tp,sample-1.pdf,https://github.com/tobias-fischer/rt_gene
PDFM-R2-U_ALL,tp,sample-1.pdf,https://github.com/yadiraf/prnet
PDFM-R2-U_ALL,tp,sample-1.pdf,https://idiap.ch/dataset/eyediap
PDFM-R2-U_ALL,tp,sample-1.pdf,https://mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/research/gaze-based-human-computer-interaction/its-written-all-over-your-face-full-face-appearance-based-gaze-estimation
PDFM-R2-U_ALL,tp,sample-1.pdf,https://mpi-inf.mpg.de/invisibleeye
PDFM-R2-U_ALL,tp,sample-1.pdf,https://mpi-inf.mpg.de/mpiigaze
PDFM-R2-U_ALL,tp,sample-1.pdf,https://phi-ai.org/gazehub
PDFM-R2-U_ALL,tp,sample-1.pdf,https://pypi.org/project/dlib/19.6.0
PDFM-R2-U_ALL,tp,sample-1.pdf,https://sites.google.com/nvidia.com/nvgaze
PDFM-R2-U_ALL,tp,sample-1.pdf,https://ut-vision.org/datasets
PDFM-R2-U_ALL,tp,sample-1.pdf,https://www.sciencedirect.com/science/article/pii/s0169814115000761
PDFM-R2-U_ALL,tp,sample-1.pdf,https://www.sciencedirect.com/science/article/pii/s0262885614000171
PDFM-R2-U_ALL,tp,sample-1.pdf,https://www.sciencedirect.com/science/article/pii/s092523121501783x
PDFM-R2-U_ALL,tp,sample-1.pdf,https://www.sciencedirect.com/science/article/pii/s1878929316300846
PDFM-R2-U_ALL,tp,sample-2.pdf,https://nlp.stanford.edu/projects/glove
PDFM-R2-U_ALL,tp,sample-2.pdf,https://www.aaai.org
PDFM-R2-U_ALL,tp,sample-3.pdf,https://www.gutenberg.org
PDFM-R2-U_ALL,tp,sample-3.pdf,https://www.ukp.tu-darmstadt.de
PDFM-R2-U_ALL,tp,sample-3.pdf,https://www.wikipedia.org
PDFM-R2-U_ALL,tp,sample-3.pdf,https://www.wiktionary.org
PDFM-R2-U_ALL,tp,sample-4.pdf,https://aws.amazon.com/kinesis
PDFM-R2-U_ALL,tp,sample-4.pdf,https://developers.google.com/protocol-buffers
PDFM-R2-U_ALL,tp,sample-4.pdf,https://flink.apache.org
PDFM-R2-U_ALL,tp,sample-4.pdf,https://github.com/nirdslab/streaminghub-conduit
PDFM-R2-U_ALL,tp,sample-4.pdf,https://github.com/nirdslab/streaminghub-dfs
PDFM-R2-U_ALL,tp,sample-4.pdf,https://github.com/sccn/labstreaminglayer
PDFM-R2-U_ALL,tp,sample-4.pdf,https://idl.cs.washington.edu/papers/reactive-vega
PDFM-R2-U_ALL,tp,sample-4.pdf,https://kepler-project.org
PDFM-R2-U_ALL,tp,sample-4.pdf,https://mqtt.org
PDFM-R2-U_ALL,tp,sample-4.pdf,https://nodered.org
PDFM-R2-U_ALL,tp,sample-4.pdf,https://www.knime.com
PDFM-R2-U_ALL,tp,sample-5.pdf,https://cinetics.com/two-axis360
PDFM-R2-U_ALL,tp,sample-5.pdf,https://myscript.com/technology
PDFM-R2-U_ALL,tp,sample-5.pdf,https://vubiq.com/v60wgd03
PDFM-R2-U_ALL,tp,sample-5.pdf,https://warp.rice.edu/trac/wiki
PDFM-R2-U_ALL,tp,sample-5.pdf,"https://www.pcmag.com/article2/0,2817,2454187,00.asp"
PDFM-R2-U_ALL,tp,sample-5.pdf,https://www.tdk.com
PDFM-R2-U_ALL,tp,sample-5.pdf,https://www.vicon.com
PDFM-R2-U_ALL,tp,sample-6.pdf,https://www.ccs.neu.edu/home/amislove/twittermood
PDFM-R2-U_ALL,tp,sample-6.pdf,https://www.cs.pitt.edu/mpqa/opinionfinderrelease
PDFM-R2-U_ALL,tp,sample-6.pdf,https://www.gallup.com/poll/122840/gallup-daily-economic-indexes.aspx
PDFM-R2-U_ALL,tp,sample-6.pdf,https://www.sca.isr.umich.edu
PDFM-R2-U_ALL,tp,sample-7.pdf,https://github.com/nirdslab/streaminghub-conduit
PDFM-R2-U_ALL,tp,sample-7.pdf,https://github.com/nirdslab/streaminghub-dfs
PDFM-R2-U_ALL,tp,sample-7.pdf,https://www.cs.odu.edu/~sampath
PDFM-R2-U_ALL,tp,sample-7.pdf,https://www.cs.odu.edu/~yasith
PDFM-R2-U_ALL,tp,sample-8.pdf,https://github.com/nirdslab/streaminghub-conduit
PDFM-R2-U_ALL,tp,sample-8.pdf,https://github.com/nirdslab/streaminghub-dfs
PDFM-R2-U_ALL,tp,sample-8.pdf,https://www.cs.odu.edu/~sampath
PDFM-R2-U_ALL,tp,sample-8.pdf,https://www.cs.odu.edu/~yasith
PDFM-R2-U_ALL,fp,sample-1.pdf,https://08.new
PDFM-R2-U_ALL,fp,sample-1.pdf,https://11.to
PDFM-R2-U_ALL,fp,sample-1.pdf,https://12.th
PDFM-R2-U_ALL,fp,sample-1.pdf,https://14.fi
PDFM-R2-U_ALL,fp,sample-1.pdf,https://16.new
PDFM-R2-U_ALL,fp,sample-1.pdf,https://1975.eg
PDFM-R2-U_ALL,fp,sample-1.pdf,https://1997.ar
PDFM-R2-U_ALL,fp,sample-1.pdf,https://5.ieee
PDFM-R2-U_ALL,fp,sample-1.pdf,https://ability.co
PDFM-R2-U_ALL,fp,sample-1.pdf,https://accuracy.here
PDFM-R2-U_ALL,fp,sample-1.pdf,https://advance.th
PDFM-R2-U_ALL,fp,sample-1.pdf,https://appearance.al
PDFM-R2-U_ALL,fp,sample-1.pdf,https://appearance.to
PDFM-R2-U_ALL,fp,sample-1.pdf,https://applications.re
PDFM-R2-U_ALL,fp,sample-1.pdf,https://author.fi
PDFM-R2-U_ALL,fp,sample-1.pdf,https://b.th
PDFM-R2-U_ALL,fp,sample-1.pdf,https://buaa.edu.cn
PDFM-R2-U_ALL,fp,sample-1.pdf,https://calibration.be
PDFM-R2-U_ALL,fp,sample-1.pdf,https://camera.et
PDFM-R2-U_ALL,fp,sample-1.pdf,https://camera.in
PDFM-R2-U_ALL,fp,sample-1.pdf,https://camera.limited
PDFM-R2-U_ALL,fp,sample-1.pdf,https://cameras.co
PDFM-R2-U_ALL,fp,sample-1.pdf,https://cameras.se
PDFM-R2-U_ALL,fp,sample-1.pdf,https://changes.de
PDFM-R2-U_ALL,fp,sample-1.pdf,https://characteristics.pe
PDFM-R2-U_ALL,fp,sample-1.pdf,https://cnns.in
PDFM-R2-U_ALL,fp,sample-1.pdf,https://corners.th
PDFM-R2-U_ALL,fp,sample-1.pdf,https://data.th
PDFM-R2-U_ALL,fp,sample-1.pdf,https://dataset.th
PDFM-R2-U_ALL,fp,sample-1.pdf,https://direction.th
PDFM-R2-U_ALL,fp,sample-1.pdf,https://directions.th
PDFM-R2-U_ALL,fp,sample-1.pdf,https://domain.me
PDFM-R2-U_ALL,fp,sample-1.pdf,https://domains.cu
PDFM-R2-U_ALL,fp,sample-1.pdf,https://environments.th
PDFM-R2-U_ALL,fp,sample-1.pdf,https://estimation.ch
PDFM-R2-U_ALL,fp,sample-1.pdf,https://estimation.data
PDFM-R2-U_ALL,fp,sample-1.pdf,https://estimation.re
PDFM-R2-U_ALL,fp,sample-1.pdf,https://estimation.to
PDFM-R2-U_ALL,fp,sample-1.pdf,https://evaluation.th
PDFM-R2-U_ALL,fp,sample-1.pdf,https://eyeglasses.be
PDFM-R2-U_ALL,fp,sample-1.pdf,https://eyes.fo
PDFM-R2-U_ALL,fp,sample-1.pdf,https://factors.th
PDFM-R2-U_ALL,fp,sample-1.pdf,https://feature.as
PDFM-R2-U_ALL,fp,sample-1.pdf,https://frame.al
PDFM-R2-U_ALL,fp,sample-1.pdf,https://front.th
PDFM-R2-U_ALL,fp,sample-1.pdf,https://gaze.gi
PDFM-R2-U_ALL,fp,sample-1.pdf,https://gaze.mo
PDFM-R2-U_ALL,fp,sample-1.pdf,https://gaze.pe
PDFM-R2-U_ALL,fp,sample-1.pdf,https://ii.af
PDFM-R2-U_ALL,fp,sample-1.pdf,https://illumination.co
PDFM-R2-U_ALL,fp,sample-1.pdf,https://illumination.foo
PDFM-R2-U_ALL,fp,sample-1.pdf,https://image.as
PDFM-R2-U_ALL,fp,sample-1.pdf,https://image.fi
PDFM-R2-U_ALL,fp,sample-1.pdf,https://images.fi
PDFM-R2-U_ALL,fp,sample-1.pdf,https://images.how
PDFM-R2-U_ALL,fp,sample-1.pdf,https://images.so
PDFM-R2-U_ALL,fp,sample-1.pdf,https://images.th
PDFM-R2-U_ALL,fp,sample-1.pdf,https://images.tw
PDFM-R2-U_ALL,fp,sample-1.pdf,https://information.int
PDFM-R2-U_ALL,fp,sample-1.pdf,https://information.ro
PDFM-R2-U_ALL,fp,sample-1.pdf,https://landmarks.th
PDFM-R2-U_ALL,fp,sample-1.pdf,https://learning.as
PDFM-R2-U_ALL,fp,sample-1.pdf,https://learning.so
PDFM-R2-U_ALL,fp,sample-1.pdf,https://looking.it
PDFM-R2-U_ALL,fp,sample-1.pdf,https://map.th
PDFM-R2-U_ALL,fp,sample-1.pdf,https://margin.th
PDFM-R2-U_ALL,fp,sample-1.pdf,https://method.th
PDFM-R2-U_ALL,fp,sample-1.pdf,https://methods.computer
PDFM-R2-U_ALL,fp,sample-1.pdf,https://methods.gl
PDFM-R2-U_ALL,fp,sample-1.pdf,https://methods.in
PDFM-R2-U_ALL,fp,sample-1.pdf,https://methods.pe
PDFM-R2-U_ALL,fp,sample-1.pdf,https://methods.th
PDFM-R2-U_ALL,fp,sample-1.pdf,https://methodsnamesyearspub.link
PDFM-R2-U_ALL,fp,sample-1.pdf,https://model.cn
PDFM-R2-U_ALL,fp,sample-1.pdf,https://module.se
PDFM-R2-U_ALL,fp,sample-1.pdf,https://movement.tw
PDFM-R2-U_ALL,fp,sample-1.pdf,https://network.ga
PDFM-R2-U_ALL,fp,sample-1.pdf,https://networks.so
PDFM-R2-U_ALL,fp,sample-1.pdf,https://orientation.de
PDFM-R2-U_ALL,fp,sample-1.pdf,https://orthogonality.th
PDFM-R2-U_ALL,fp,sample-1.pdf,https://parameters.th
PDFM-R2-U_ALL,fp,sample-1.pdf,https://pcl.ac.cn
PDFM-R2-U_ALL,fp,sample-1.pdf,https://performance.th
PDFM-R2-U_ALL,fp,sample-1.pdf,https://platform.ac
PDFM-R2-U_ALL,fp,sample-1.pdf,https://platforms.be
PDFM-R2-U_ALL,fp,sample-1.pdf,https://pog.app
PDFM-R2-U_ALL,fp,sample-1.pdf,https://pog.me
PDFM-R2-U_ALL,fp,sample-1.pdf,https://pose.as
PDFM-R2-U_ALL,fp,sample-1.pdf,https://problem.al
PDFM-R2-U_ALL,fp,sample-1.pdf,https://problem.th
PDFM-R2-U_ALL,fp,sample-1.pdf,https://processing.ieee
PDFM-R2-U_ALL,fp,sample-1.pdf,https://progress.by
PDFM-R2-U_ALL,fp,sample-1.pdf,https://progress.fi
PDFM-R2-U_ALL,fp,sample-1.pdf,https://regression.ch
PDFM-R2-U_ALL,fp,sample-1.pdf,https://research.here
PDFM-R2-U_ALL,fp,sample-1.pdf,https://research.im
PDFM-R2-U_ALL,fp,sample-1.pdf,https://resources.fi
PDFM-R2-U_ALL,fp,sample-1.pdf,https://resources.free
PDFM-R2-U_ALL,fp,sample-1.pdf,https://samples.th
PDFM-R2-U_ALL,fp,sample-1.pdf,https://screen.no
PDFM-R2-U_ALL,fp,sample-1.pdf,https://scs.re
PDFM-R2-U_ALL,fp,sample-1.pdf,https://scs.th
PDFM-R2-U_ALL,fp,sample-1.pdf,https://ser.ch
PDFM-R2-U_ALL,fp,sample-1.pdf,https://setting.etc.ir
PDFM-R2-U_ALL,fp,sample-1.pdf,https://sh.rice.edu/cognitive-engagement/tabletgaze
PDFM-R2-U_ALL,fp,sample-1.pdf,https://subject.app
PDFM-R2-U_ALL,fp,sample-1.pdf,https://subject.th
PDFM-R2-U_ALL,fp,sample-1.pdf,https://variables.gi
PDFM-R2-U_ALL,fp,sample-1.pdf,https://vc.sc
PDFM-R2-U_ALL,fp,sample-1.pdf,https://w.r.t.th
PDFM-R2-U_ALL,fp,sample-1.pdf,https://zone.limited
PDFM-R2-U_ALL,fp,sample-1.pdf,https://zone.su
PDFM-R2-U_ALL,fp,sample-2.pdf,https://1.0.th
PDFM-R2-U_ALL,fp,sample-2.pdf,https://1.ge
PDFM-R2-U_ALL,fp,sample-2.pdf,https://1064-1074.ma
PDFM-R2-U_ALL,fp,sample-2.pdf,https://1312.6026.sa
PDFM-R2-U_ALL,fp,sample-2.pdf,https://1412.6980.la
PDFM-R2-U_ALL,fp,sample-2.pdf,https://1508.01991.kim
PDFM-R2-U_ALL,fp,sample-2.pdf,https://1602.06023.pa
PDFM-R2-U_ALL,fp,sample-2.pdf,https://1609.01704.ch
PDFM-R2-U_ALL,fp,sample-2.pdf,https://1650-1659.ch
PDFM-R2-U_ALL,fp,sample-2.pdf,https://1708.06834.ch
PDFM-R2-U_ALL,fp,sample-2.pdf,https://1711.02085.se
PDFM-R2-U_ALL,fp,sample-2.pdf,https://1735-1780.hu
PDFM-R2-U_ALL,fp,sample-2.pdf,https://1818-1826.se
PDFM-R2-U_ALL,fp,sample-2.pdf,https://1880-1890.za
PDFM-R2-U_ALL,fp,sample-2.pdf,https://2013.how
PDFM-R2-U_ALL,fp,sample-2.pdf,https://2016.ch
PDFM-R2-U_ALL,fp,sample-2.pdf,https://2017.ar
PDFM-R2-U_ALL,fp,sample-2.pdf,https://2018.lat
PDFM-R2-U_ALL,fp,sample-2.pdf,https://234-239.mu
PDFM-R2-U_ALL,fp,sample-2.pdf,https://2670-2680.su
PDFM-R2-U_ALL,fp,sample-2.pdf,https://2741-2749.ki
PDFM-R2-U_ALL,fp,sample-2.pdf,https://2775-2785.na
PDFM-R2-U_ALL,fp,sample-2.pdf,https://3079-3087.de
PDFM-R2-U_ALL,fp,sample-2.pdf,https://3104-3112.tj
PDFM-R2-U_ALL,fp,sample-2.pdf,https://313-330.me
PDFM-R2-U_ALL,fp,sample-2.pdf,https://3776-3784.st
PDFM-R2-U_ALL,fp,sample-2.pdf,https://462-471.ma
PDFM-R2-U_ALL,fp,sample-2.pdf,https://493-499.gal
PDFM-R2-U_ALL,fp,sample-2.pdf,https://5917-5926.na
PDFM-R2-U_ALL,fp,sample-2.pdf,https://76-86.ch
PDFM-R2-U_ALL,fp,sample-2.pdf,https://ac-tion.ac
PDFM-R2-U_ALL,fp,sample-2.pdf,https://agent.next
PDFM-R2-U_ALL,fp,sample-2.pdf,https://agent.se
PDFM-R2-U_ALL,fp,sample-2.pdf,https://algorithm.al
PDFM-R2-U_ALL,fp,sample-2.pdf,https://as-pects.app
PDFM-R2-U_ALL,fp,sample-2.pdf,https://cases.th
PDFM-R2-U_ALL,fp,sample-2.pdf,https://categories.th
PDFM-R2-U_ALL,fp,sample-2.pdf,https://computation.re
PDFM-R2-U_ALL,fp,sample-2.pdf,https://connections.th
PDFM-R2-U_ALL,fp,sample-2.pdf,https://ct.la
PDFM-R2-U_ALL,fp,sample-2.pdf,https://datasets.be
PDFM-R2-U_ALL,fp,sample-2.pdf,https://dependencies.th
PDFM-R2-U_ALL,fp,sample-2.pdf,https://dependency.lt
PDFM-R2-U_ALL,fp,sample-2.pdf,https://dependency.so
PDFM-R2-U_ALL,fp,sample-2.pdf,https://e.2015.re
PDFM-R2-U_ALL,fp,sample-2.pdf,https://fudan.edu.cn
PDFM-R2-U_ALL,fp,sample-2.pdf,https://gradients.to
PDFM-R2-U_ALL,fp,sample-2.pdf,https://hours.tab
PDFM-R2-U_ALL,fp,sample-2.pdf,https://in-formation.fo
PDFM-R2-U_ALL,fp,sample-2.pdf,https://k.ls
PDFM-R2-U_ALL,fp,sample-2.pdf,https://legislation.you
PDFM-R2-U_ALL,fp,sample-2.pdf,https://length.how
PDFM-R2-U_ALL,fp,sample-2.pdf,https://lstm-cnns.ar
PDFM-R2-U_ALL,fp,sample-2.pdf,https://lstm.nu
PDFM-R2-U_ALL,fp,sample-2.pdf,https://methods.ac
PDFM-R2-U_ALL,fp,sample-2.pdf,https://model.th
PDFM-R2-U_ALL,fp,sample-2.pdf,https://models.ar
PDFM-R2-U_ALL,fp,sample-2.pdf,https://operator.re
PDFM-R2-U_ALL,fp,sample-2.pdf,https://path.th
PDFM-R2-U_ALL,fp,sample-2.pdf,https://problem.th
PDFM-R2-U_ALL,fp,sample-2.pdf,https://r.ar
PDFM-R2-U_ALL,fp,sample-2.pdf,https://regularization.ar
PDFM-R2-U_ALL,fp,sample-2.pdf,https://report.th
PDFM-R2-U_ALL,fp,sample-2.pdf,https://reserved.fi
PDFM-R2-U_ALL,fp,sample-2.pdf,https://sequence.to
PDFM-R2-U_ALL,fp,sample-2.pdf,https://set.se
PDFM-R2-U_ALL,fp,sample-2.pdf,https://skim-rnn.ar
PDFM-R2-U_ALL,fp,sample-2.pdf,https://skip.re
PDFM-R2-U_ALL,fp,sample-2.pdf,https://space.to
PDFM-R2-U_ALL,fp,sample-2.pdf,https://tagging.ar
PDFM-R2-U_ALL,fp,sample-2.pdf,https://task.th
PDFM-R2-U_ALL,fp,sample-2.pdf,https://tasks.co
PDFM-R2-U_ALL,fp,sample-2.pdf,https://tasks.how
PDFM-R2-U_ALL,fp,sample-2.pdf,https://tasks.th
PDFM-R2-U_ALL,fp,sample-2.pdf,https://testing.name
PDFM-R2-U_ALL,fp,sample-2.pdf,https://text.in
PDFM-R2-U_ALL,fp,sample-2.pdf,https://thl.th
PDFM-R2-U_ALL,fp,sample-2.pdf,https://truth.re
PDFM-R2-U_ALL,fp,sample-2.pdf,https://uncertain.th
PDFM-R2-U_ALL,fp,sample-2.pdf,https://words.si
PDFM-R2-U_ALL,fp,sample-2.pdf,https://y.cal
PDFM-R2-U_ALL,fp,sample-3.pdf,https://033paraphrasenopara.paraphrasenopara.tab
PDFM-R2-U_ALL,fp,sample-3.pdf,https://1-22.call
PDFM-R2-U_ALL,fp,sample-3.pdf,https://11-21.st
PDFM-R2-U_ALL,fp,sample-3.pdf,https://13.821.788ourapproach.884.859exp.cl
PDFM-R2-U_ALL,fp,sample-3.pdf,https://15.fo
PDFM-R2-U_ALL,fp,sample-3.pdf,https://15.inc
PDFM-R2-U_ALL,fp,sample-3.pdf,https://2.1contentsimilarityprobablytheeasiestwaytoreusetextisverbatimcopying.itcanbedetectedbyusingstringmeasureswhichoperateonsubstringsequences.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://249-254.ch
PDFM-R2-U_ALL,fp,sample-3.pdf,https://259-284.land
PDFM-R2-U_ALL,fp,sample-3.pdf,https://305-310.art
PDFM-R2-U_ALL,fp,sample-3.pdf,https://321-325.sh
PDFM-R2-U_ALL,fp,sample-3.pdf,https://378-382.ga
PDFM-R2-U_ALL,fp,sample-3.pdf,https://47ismoderate12.fo
PDFM-R2-U_ALL,fp,sample-3.pdf,https://50-64.spa
PDFM-R2-U_ALL,fp,sample-3.pdf,https://517.so
PDFM-R2-U_ALL,fp,sample-3.pdf,https://555-596.bar
PDFM-R2-U_ALL,fp,sample-3.pdf,https://698intheiroriginalwork.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://707-710.li
PDFM-R2-U_ALL,fp,sample-3.pdf,https://745.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://768.it
PDFM-R2-U_ALL,fp,sample-3.pdf,https://783.705ourapproach.802.768exp.cl
PDFM-R2-U_ALL,fp,sample-3.pdf,https://811.it
PDFM-R2-U_ALL,fp,sample-3.pdf,https://839.837ourapproach.853.852exp.cl
PDFM-R2-U_ALL,fp,sample-3.pdf,https://852.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://859.in
PDFM-R2-U_ALL,fp,sample-3.pdf,https://abit-stringlongest-common-subsequencealgorithm.info
PDFM-R2-U_ALL,fp,sample-3.pdf,https://acomputationalmodeloftextreuseinancientliterarytexts.in
PDFM-R2-U_ALL,fp,sample-3.pdf,https://acorpusforanalysingjournalistictextreuse.in
PDFM-R2-U_ALL,fp,sample-3.pdf,https://advancesinrecordlinkagemethodologyasappliedtothe1985censusoftampaflorida.jo
PDFM-R2-U_ALL,fp,sample-3.pdf,https://alarge-scaleevaluationofalgorithms.in
PDFM-R2-U_ALL,fp,sample-3.pdf,https://allcombinationsofmeasuresacrossdimensionsinadditiontocontentsimilarityimprovetheresults.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://alleviatestheseshortcomings.ititerativelycomputesattrscoreforadynamicallygrowingtextsegmentuntilapointofsaturation-i.e.af
PDFM-R2-U_ALL,fp,sample-3.pdf,https://and20non-reusedtextshavebeenmistakenlylabeledassuch.how
PDFM-R2-U_ALL,fp,sample-3.pdf,https://and72non-reusedinstancesinordertocarryoutacomparableevaluationstudy.resultswesummarizetheresultsonthisdatasetintable6.int
PDFM-R2-U_ALL,fp,sample-3.pdf,https://andcharacter5-gramprofilesfromthetwodimensionscontentandstructure.thissupportsourhypothesisthatthesimilaritycomputationprocessindeedprofitsfromdimensionsotherthancontent.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://andcomputesfeaturevectorsoftheirfrequenciesforeachpossiblyreuseddocumentandthesourcetext.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://andcomputestextsimilarityasthecosinebetweentwodocumentvectors.com
PDFM-R2-U_ALL,fp,sample-3.pdf,https://andconsequentlythebestperformanceisreachedwhencombiningallthreedimensions.ba
PDFM-R2-U_ALL,fp,sample-3.pdf,https://anditspracticalimplementationintheferretplagiarismandcollusiondetector.in
PDFM-R2-U_ALL,fp,sample-3.pdf,https://andlongestcommonsubsequence.fo
PDFM-R2-U_ALL,fp,sample-3.pdf,https://andnewspaperarticlesfrom9britishnewspapersthatreusedthepasourcetextstogeneratetheirowntexts.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://andreversals.so
PDFM-R2-U_ALL,fp,sample-3.pdf,https://andselectedasubsetoftextswhereonlyasinglesourcestoryispresentinthedataset.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://andsequentialttr.as
PDFM-R2-U_ALL,fp,sample-3.pdf,https://andstyle.fi
PDFM-R2-U_ALL,fp,sample-3.pdf,https://andstyle.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://andtheoverallsimilarityscoredecreases.weconcludethatapplicationswillbenefitfromanimprovedclassifierwhichbetterdealswiththesesinstances.forex
PDFM-R2-U_ALL,fp,sample-3.pdf,https://andwedecidedtogoevenonestepfurtherandfoldallpotentialcasesoftextreuse.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://andwhatisnot.as
PDFM-R2-U_ALL,fp,sample-3.pdf,https://anefficientdomain-independentalgorithmfordetectingapproximatelyduplicatedatabaserecords.in
PDFM-R2-U_ALL,fp,sample-3.pdf,https://anelectroniclexicaldatabase.mit
PDFM-R2-U_ALL,fp,sample-3.pdf,https://anexampleofaheavyrevisionwasgiveninfigure1.re
PDFM-R2-U_ALL,fp,sample-3.pdf,https://aninformation-theoreticdefinitionofsimilarity.in
PDFM-R2-U_ALL,fp,sample-3.pdf,https://aninterestingobservationacrossallthreevariantsofthedatasetisthatthesamethreetextsalwaysconstitutesevereerrorinstanceswheree.g.ac
PDFM-R2-U_ALL,fp,sample-3.pdf,https://anupdate.si
PDFM-R2-U_ALL,fp,sample-3.pdf,https://aourapproach.968.967exp.class.551237plagiarismnoplag.plagiarismnoplag.tab
PDFM-R2-U_ALL,fp,sample-3.pdf,https://aparallelcorpusforstatisticalmachinetranslation.in
PDFM-R2-U_ALL,fp,sample-3.pdf,https://aparticulardimensionmayormaynotcontributetoanoverallimprovementbasedonthenatureofthedata.ac
PDFM-R2-U_ALL,fp,sample-3.pdf,https://arebasedontheideathattextreuseoftenpreservessyntacticsimilaritieswhileexchangingcontentwords.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://areflectiveviewontextsimilarity.in
PDFM-R2-U_ALL,fp,sample-3.pdf,https://astatisticalinterpretationoftermspecificityanditsapplicationinretrieval.jo
PDFM-R2-U_ALL,fp,sample-3.pdf,https://avalidationstudyofsophisticatedapproachestolexicaldiversityassessment.be
PDFM-R2-U_ALL,fp,sample-3.pdf,https://backtoenglish.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://bulgaria.bar
PDFM-R2-U_ALL,fp,sample-3.pdf,https://canada.ch
PDFM-R2-U_ALL,fp,sample-3.pdf,https://canada.mc
PDFM-R2-U_ALL,fp,sample-3.pdf,https://canada.sa
PDFM-R2-U_ALL,fp,sample-3.pdf,https://certainlanguageskillsinchildren.universityofminnesotapress.tv
PDFM-R2-U_ALL,fp,sample-3.pdf,https://cf.tab
PDFM-R2-U_ALL,fp,sample-3.pdf,https://charactern-gramprofileshaveratherbeenshownsuccessfulforauthorshipattribution.how
PDFM-R2-U_ALL,fp,sample-3.pdf,https://china.boo
PDFM-R2-U_ALL,fp,sample-3.pdf,https://code.google.com
PDFM-R2-U_ALL,fp,sample-3.pdf,https://collaborationandsharingontheinternet.ad
PDFM-R2-U_ALL,fp,sample-3.pdf,https://comparesthevocabularyrichnessoftwotexts.how
PDFM-R2-U_ALL,fp,sample-3.pdf,https://computerscienceandcomputationalbiology.cam
PDFM-R2-U_ALL,fp,sample-3.pdf,https://computingn-gramsalongpart-of-speechtagsallowstodetectsyntacticsimilaritiesbetweenthesetexts.ag
PDFM-R2-U_ALL,fp,sample-3.pdf,https://computingsemanticrelatednessusingwikipedia-basedexplicitsemanticanalysis.in
PDFM-R2-U_ALL,fp,sample-3.pdf,https://contentoutperformsstructuralandstylisticsimilarity.how
PDFM-R2-U_ALL,fp,sample-3.pdf,https://corpus-basedandknowledge-basedmeasuresoftextsemanticsimilarity.in
PDFM-R2-U_ALL,fp,sample-3.pdf,https://courtandshowbusiness.al
PDFM-R2-U_ALL,fp,sample-3.pdf,https://czechrepublic.land
PDFM-R2-U_ALL,fp,sample-3.pdf,https://dassjeglicheanderetextcharacteristikavernachlassigbarsind.in
PDFM-R2-U_ALL,fp,sample-3.pdf,https://deletions.gr
PDFM-R2-U_ALL,fp,sample-3.pdf,https://detectingnear-duplicatesforwebcrawling.in
PDFM-R2-U_ALL,fp,sample-3.pdf,https://detectingshortpassagesofsimilartextinlargedocumentcollections.in
PDFM-R2-U_ALL,fp,sample-3.pdf,https://detectingtheoriginoftextsegmentsefficiently.in
PDFM-R2-U_ALL,fp,sample-3.pdf,https://developingacorpusofplagiarisedshortanswers.la
PDFM-R2-U_ALL,fp,sample-3.pdf,https://distanceandawordn-gramsimilaritymeasure.as
PDFM-R2-U_ALL,fp,sample-3.pdf,https://documentswithanumericalweighting.it
PDFM-R2-U_ALL,fp,sample-3.pdf,https://duplicateoranautomatedone-for-onewordsubstitution.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://duplicateswithveryhighsimilarityscoresareinfactnegativesamples.re
PDFM-R2-U_ALL,fp,sample-3.pdf,https://e.g.int
PDFM-R2-U_ALL,fp,sample-3.pdf,https://e.g.paraphraserecognitionorautomaticessaygrading.fo
PDFM-R2-U_ALL,fp,sample-3.pdf,https://e.g.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://e.g.tomergebothtexts.de
PDFM-R2-U_ALL,fp,sample-3.pdf,https://e.g.tomergebothtexts.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://eachofwhichshouldcomplytooneof4rewritelevelsandhencereusethesourcetexttoavaryingextent.ac
PDFM-R2-U_ALL,fp,sample-3.pdf,https://eachsubstringtherebybeingamatchofmaximallength.am
PDFM-R2-U_ALL,fp,sample-3.pdf,https://eachtaskexhibitsparticularcharacteristicswhichinfluencethechoiceofasuitablesetofsimilaritydimensions.as
PDFM-R2-U_ALL,fp,sample-3.pdf,https://enginetoestimatetherelativeimportanceofawebpageaccordingtothisweighting.fi
PDFM-R2-U_ALL,fp,sample-3.pdf,https://etwaimrahmenjournalisti-schertatigkeitoderalsmittelzurplagiatserkennung.textwiederverwendungwirdtraditionellermitteltdurchberechnenvontextahnlichkeitzwischeneinemursprungstextundeinempo-tentiellwiederverwendetentext.best
PDFM-R2-U_ALL,fp,sample-3.pdf,https://eventhoughthedecisiontreeclassifierperformedconsistentlybetterthannaivebayes.erroranalysiswepresenttheconfusionmatrixforourbestconfigurationintable2.int
PDFM-R2-U_ALL,fp,sample-3.pdf,https://expectedclassvs.cl
PDFM-R2-U_ALL,fp,sample-3.pdf,https://exploringlinguisticfeaturecombinationsviamachinelearning.in
PDFM-R2-U_ALL,fp,sample-3.pdf,https://featuresetusedtoachievethebestresultsonthewebiscrowdparaphrasecorpus4conclusionsandfutureworkthemotivationforthisworkstemmedfromthehypothesisthatcontentfeaturesalonearenotareliableindicatorfortextreusedetection.as
PDFM-R2-U_ALL,fp,sample-3.pdf,https://featuresofsimilarity.in
PDFM-R2-U_ALL,fp,sample-3.pdf,https://forcomparingtexts.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://fortextcomparisonratherthanmethodsfromnaturallanguageprocessing.acommonapproachtotextreusedetectionistocomputesimilaritybetweenasourcetextandapossiblyreusedtext.am
PDFM-R2-U_ALL,fp,sample-3.pdf,https://fortextreusedetectionitisimportanttohavealignedpairsofreusedtextsandsourcetexts.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://hasbeenmanuallycreatedbycopyingportionsoftextfromasuitablewikipediaarticle.textreusenowoccursbetweenasourcetextandananswergivenbyoneof19participants.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://henceforth.fo
PDFM-R2-U_ALL,fp,sample-3.pdf,https://i.e.ne
PDFM-R2-U_ALL,fp,sample-3.pdf,https://i.e.pa
PDFM-R2-U_ALL,fp,sample-3.pdf,https://i.e.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://implementedtheremainingsystems.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://improveddetectionofsimilaritiesincomputerprogramandothertexts.in
PDFM-R2-U_ALL,fp,sample-3.pdf,https://india.ga
PDFM-R2-U_ALL,fp,sample-3.pdf,https://inoursystem.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://inter-coderagreementforcomputationallinguistics.com
PDFM-R2-U_ALL,fp,sample-3.pdf,https://introductiontomoderninformationretrieval.mcgraw-hill.sa
PDFM-R2-U_ALL,fp,sample-3.pdf,https://isapopularmeansforcomparinglexicalpatternsbetweentwotexts.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://isoriginallylabeledastextreuse.how
PDFM-R2-U_ALL,fp,sample-3.pdf,https://italy.re
PDFM-R2-U_ALL,fp,sample-3.pdf,https://itisparticularlyinterestingtonotethatmanyerrorsareduetothefactthataloweroveralltextsimilaritybetweenthepossiblyreusedtextandtheoriginalsourcedoesnotnecessarilyentailthelabelnoreuse.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://itsrelativeimportancewithintheset.textreuse.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://measuringnominalscaleagreementamongmanyraters.ps
PDFM-R2-U_ALL,fp,sample-3.pdf,https://measuringtextreuse.in
PDFM-R2-U_ALL,fp,sample-3.pdf,https://methodsforidentifyingversionedandplagiarizeddocuments.jo
PDFM-R2-U_ALL,fp,sample-3.pdf,https://mexico.scot
PDFM-R2-U_ALL,fp,sample-3.pdf,https://n-gram-basedauthorprofilesforauthorshipattribution.in
PDFM-R2-U_ALL,fp,sample-3.pdf,https://negativesamples.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://normalizedbythetextlengths.how
PDFM-R2-U_ALL,fp,sample-3.pdf,https://ofalltextstheannotatorsfullyagree.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://ofthesourcestorieshavebeenusedtogeneratetherewrittenstory.how
PDFM-R2-U_ALL,fp,sample-3.pdf,https://ontheresemblanceandcontainmentofdocuments.pro
PDFM-R2-U_ALL,fp,sample-3.pdf,https://onthewebfrommirroringtextsondifferentsitesorreusingtextsinpublicblogs.in
PDFM-R2-U_ALL,fp,sample-3.pdf,https://opensourcetoolkitforstatisticalmachinetranslation.in
PDFM-R2-U_ALL,fp,sample-3.pdf,https://orcreatenewtextsfromscratch.how
PDFM-R2-U_ALL,fp,sample-3.pdf,https://ordinalmeasuresinauthorshipidentification.in
PDFM-R2-U_ALL,fp,sample-3.pdf,https://ormeasuresassessingtextorganizationwithrespecttothediscourseelements.how
PDFM-R2-U_ALL,fp,sample-3.pdf,https://orpartsofreusedtextappearinadifferentorder.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://orstylisticvariance.wethusdevisedanarchitecturewhichcomposesdiversetextsimilaritymeasuresinasupervisedclassificationmodel.int
PDFM-R2-U_ALL,fp,sample-3.pdf,https://ortextsalikealsobelongtotheclassofnegativesamples.inc
PDFM-R2-U_ALL,fp,sample-3.pdf,https://orusestatisticalpropertiesoftextstocomputetextsimilarity.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://ourclassifierfalselyassignedthelabelnoreuse.it
PDFM-R2-U_ALL,fp,sample-3.pdf,https://ourclassifierisabletodetectsimilarityevenforreusedtextsbyexpertjournalists.thisisduetothefactthatajournalistictextwhichreusestheoriginalpressagencysourcemostlikelyalsoshowsstylisticsimilarityintermsofe.g.vocabularyrichness.erroranalysiswepresenttheconfusionmatrixforourbestconfigurationintable6.int
PDFM-R2-U_ALL,fp,sample-3.pdf,https://overviewofthe2ndinternationalcompetitiononplagiarismdetection.in
PDFM-R2-U_ALL,fp,sample-3.pdf,https://pages118-125.man
PDFM-R2-U_ALL,fp,sample-3.pdf,https://pages21-29.br
PDFM-R2-U_ALL,fp,sample-3.pdf,https://pages214-223.garden
PDFM-R2-U_ALL,fp,sample-3.pdf,https://pages296-304.ly
PDFM-R2-U_ALL,fp,sample-3.pdf,https://pages327-352.win
PDFM-R2-U_ALL,fp,sample-3.pdf,https://pages437-446.bobbs-merrill.gu
PDFM-R2-U_ALL,fp,sample-3.pdf,https://paraphrase.ke
PDFM-R2-U_ALL,fp,sample-3.pdf,https://paraphraseacquisitionviacrowdsourcingandmachinelearning.tr
PDFM-R2-U_ALL,fp,sample-3.pdf,https://paraphraserecognition.in
PDFM-R2-U_ALL,fp,sample-3.pdf,https://pastelightrev.heavyrev.noplag.cu
PDFM-R2-U_ALL,fp,sample-3.pdf,https://pastelightrev.heavyrev.noplag.tab
PDFM-R2-U_ALL,fp,sample-3.pdf,https://pastepotentialnoplag.cu
PDFM-R2-U_ALL,fp,sample-3.pdf,https://pastepotentialnoplag.tab
PDFM-R2-U_ALL,fp,sample-3.pdf,https://plagiarismdetectionacrossdistantlanguagepairs.in
PDFM-R2-U_ALL,fp,sample-3.pdf,https://plagiarismdetectionusingstopwordn-grams.jo
PDFM-R2-U_ALL,fp,sample-3.pdf,https://pointscomparedtoourre-implementationofthissystem7.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://pointsintermsof-f1score.theirsystemusesanaivebayesclassifierwithtwocustomfeatureswhichcomparetextsbasedonthelengthandfrequencyofcommonwordsequencesandtherelevanceofindividualwords.as
PDFM-R2-U_ALL,fp,sample-3.pdf,https://potentiallyreusedtextsarepresentedtousersinaninformativemanner.here
PDFM-R2-U_ALL,fp,sample-3.pdf,https://practiceandpoliciesconference.ly
PDFM-R2-U_ALL,fp,sample-3.pdf,https://predictionandentropyofprintedenglish.be
PDFM-R2-U_ALL,fp,sample-3.pdf,https://problemswithtextreuseparticularlyariseinsettingswheresystemsareextensivelyusedinacollaborativemanner.forex
PDFM-R2-U_ALL,fp,sample-3.pdf,https://rangingfromjournalistictextreusetoplagiarismdetection.textreuseistraditionallydetectedbycomputingsimilaritybetweenasourcetextandapossiblyreusedtext.how
PDFM-R2-U_ALL,fp,sample-3.pdf,https://reflectstheweightedarithmeticmeanoverallfourclassesofthedatasetwhereoneclassistwiceasprominentaseachoftheothers.as
PDFM-R2-U_ALL,fp,sample-3.pdf,https://respectively.ba
PDFM-R2-U_ALL,fp,sample-3.pdf,https://respectively.final
PDFM-R2-U_ALL,fp,sample-3.pdf,https://respectively.fo
PDFM-R2-U_ALL,fp,sample-3.pdf,https://resultsandconfusionmatrixforthebestclassificationonthemetercorpustheresultsandthecorrespondingconfusionmatrixintable5.int
PDFM-R2-U_ALL,fp,sample-3.pdf,https://resultsofthebestcombinationsoftextsimilaritymeasureswithinandacrossdimen-sionsonthemetercorpusintable1.fr
PDFM-R2-U_ALL,fp,sample-3.pdf,https://sdecisiontoconsidertextsasreusedornot.ing
PDFM-R2-U_ALL,fp,sample-3.pdf,https://semanticsimilaritybasedoncorpusstatisticsandlexicaltaxonomy.in
PDFM-R2-U_ALL,fp,sample-3.pdf,https://sevenstricturesonsimilarity.ing
PDFM-R2-U_ALL,fp,sample-3.pdf,https://similaritycomputationworksbestifthesimilaritydimensionsarechosenwellwithrespecttothetypeoftextreuseathand.fo
PDFM-R2-U_ALL,fp,sample-3.pdf,https://similarityestimationtechniquesfromroundingalgorithms.in
PDFM-R2-U_ALL,fp,sample-3.pdf,https://smechanicalturk.in
PDFM-R2-U_ALL,fp,sample-3.pdf,https://sothatawidevarietyoftextfeaturesaretakenintoconsideration.thecompositionconsistentlyoutperformspreviousapproachesacrossalldatasets.as
PDFM-R2-U_ALL,fp,sample-3.pdf,https://sothattextreusedetectionapproachescanbeevaluatedpreciselyagainstparticularcharacteristicsofdifferentkindsofdata.fo
PDFM-R2-U_ALL,fp,sample-3.pdf,https://sourcetext.page
PDFM-R2-U_ALL,fp,sample-3.pdf,https://spain.al
PDFM-R2-U_ALL,fp,sample-3.pdf,https://spain.br
PDFM-R2-U_ALL,fp,sample-3.pdf,https://strainingphase.int
PDFM-R2-U_ALL,fp,sample-3.pdf,https://stringcomparatormetricsandenhanceddecisionrulesinthefellegi-suntermodelofrecordlinkage.in
PDFM-R2-U_ALL,fp,sample-3.pdf,https://syntacticclusteringoftheweb.in
PDFM-R2-U_ALL,fp,sample-3.pdf,https://textsimilaritymeasuresforstructuralsimilarityarenecessary.ad
PDFM-R2-U_ALL,fp,sample-3.pdf,https://thecaseofnominalscalecoding.pub
PDFM-R2-U_ALL,fp,sample-3.pdf,https://thecomplementarywordpairdistancemeasurecountsthenumberofwordswhichliebetweenthoseofagivenpair.fo
PDFM-R2-U_ALL,fp,sample-3.pdf,https://theeditorhasfurthersplitthesourcetextintotwoindividualsentencesandchangedtheorderofthereusedparts.ford
PDFM-R2-U_ALL,fp,sample-3.pdf,https://theeffectsofdimensioncombinationheldtrueregardlessoftheclassifierused.theinfluenceofthestylisticsimilaritymeasuresisparticularlyinterestingtonote.inc
PDFM-R2-U_ALL,fp,sample-3.pdf,https://thefederalist.ad
PDFM-R2-U_ALL,fp,sample-3.pdf,https://thegeometryofthought.mitpress.goo
PDFM-R2-U_ALL,fp,sample-3.pdf,https://thehighertheirdegreeoftextreuse.fo
PDFM-R2-U_ALL,fp,sample-3.pdf,https://theirbestscorewasachievedbyusingak-nearestneighborclassifierwithafeaturesetof10similaritymeasures.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://thekappastatistic.com
PDFM-R2-U_ALL,fp,sample-3.pdf,https://themeasurementofobserveragreementforcategoricaldata.bio
PDFM-R2-U_ALL,fp,sample-3.pdf,https://themeasureremovesallcontentwordswhilepreservingonlystopwords.al
PDFM-R2-U_ALL,fp,sample-3.pdf,https://themorelikelyisitthattextreusehasoccurred.af
PDFM-R2-U_ALL,fp,sample-3.pdf,https://thennormalized.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://thenstartsanewfromthatpositioninthetextforanewsegment.thefinallexicaldiversityscoreiscomputedasthenumberoftokensdividedbythenumberofsegments.in
PDFM-R2-U_ALL,fp,sample-3.pdf,https://theprocessofcreatingreusedtextincludesarevisionstepinwhichtheeditorhasacertaindegreeoffreedomonhowtoreusethesourcetext.thiskindofsimilarityisdetectablebycontent-centrictextsimilaritymeasures.how
PDFM-R2-U_ALL,fp,sample-3.pdf,https://therebyinherentlyimplyingthatanyothertextcharacteristicsarenegligible.int
PDFM-R2-U_ALL,fp,sample-3.pdf,https://theycomputesimilarityonlyonfeatureswhichcanbederivedfromthecontentofthegiventexts.by
PDFM-R2-U_ALL,fp,sample-3.pdf,https://theyinherentlyimplythatthesimilaritycomputationprocessdoesnotneedtotakeanyothertextcharacteristicsintoaccount.inc
PDFM-R2-U_ALL,fp,sample-3.pdf,https://theyneedtoavoidcontentduplication.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://though.to
PDFM-R2-U_ALL,fp,sample-3.pdf,https://thoughnotcarriedoutintheirwork.wereportthecorrespondingresultsandtheconfusionmatrixintable4.as
PDFM-R2-U_ALL,fp,sample-3.pdf,https://towardsdocumentplagiarismdetectionbasedontherelevanceandfragmentationofthereusedtext.in
PDFM-R2-U_ALL,fp,sample-3.pdf,https://uk.cl
PDFM-R2-U_ALL,fp,sample-3.pdf,https://unddassdiebestimmungvontextwiederverwendungstarkvoneinembreitenspektrumantextcharacteristikaprofitiert.ke
PDFM-R2-U_ALL,fp,sample-3.pdf,https://usa.car
PDFM-R2-U_ALL,fp,sample-3.pdf,https://usa.mo
PDFM-R2-U_ALL,fp,sample-3.pdf,https://usinginformationcontenttoevaluatesemanticsimilarityinataxonomy.in
PDFM-R2-U_ALL,fp,sample-3.pdf,https://usingnaturallanguageprocessingforautomaticdetectionofplagiarism.in
PDFM-R2-U_ALL,fp,sample-3.pdf,https://weconductedanannotationstudywiththreeannotatorstogainfurtherinsightsintothedata.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://wedecidedtofoldthelightandheavyrevisionclassesintoasingleclasspotentialplagiarism.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://wepresumethatcontentsimilarityaloneisnotareliableindicatoroftextreuse.twoindependentlywrittentextsaboutthesametopicarelikelytomakeuseofacommonvocabularytoacertainextent.wethusproposetoalsousemeasuresofstructuralsimilaritywhichcomputesimilaritybasedonstructuralaspectsinherenttothecomparedtexts.st
PDFM-R2-U_ALL,fp,sample-3.pdf,https://weproposetofurtherincludemeasuresofstylisticsimilarity.int
PDFM-R2-U_ALL,fp,sample-3.pdf,https://were-implementedtheirsystemandalsoappliedittothetwodatasetsintheremainderofthispaper.wereportourfindingsinsections3.2and3.3.int
PDFM-R2-U_ALL,fp,sample-3.pdf,https://werefertothenumberofcorrectlypredictedtextsdividedbythetotalnumberoftexts.as
PDFM-R2-U_ALL,fp,sample-3.pdf,https://wereportonamultitudeoftextsimilaritymeasuresfromthesedimensionsthatweusedforourexperiments.in
PDFM-R2-U_ALL,fp,sample-3.pdf,https://wereportthebestresultsfromtheliteratureforcomparison.evaluationwascarriedoutintermsofaccuracyand-f1score.by
PDFM-R2-U_ALL,fp,sample-3.pdf,https://wereportthedetailedresultsforaselectedsetofindividualtextsimilaritymeasuresintable1.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://wethusovercomethetraditionallimitationoftextsimilaritymeasurestocontentfeatures.inc
PDFM-R2-U_ALL,fp,sample-3.pdf,https://whenappliedindividually.int
PDFM-R2-U_ALL,fp,sample-3.pdf,https://wheree.g.al
PDFM-R2-U_ALL,fp,sample-3.pdf,https://wherepartsofagivensourcetexthavebeenreusedeitherverbatimorbyusingsimilarwordsorphrases.as
PDFM-R2-U_ALL,fp,sample-3.pdf,https://whichhaveshowntobegoodstyleindicatorsinauthorshipattributionstudies.fo
PDFM-R2-U_ALL,fp,sample-3.pdf,https://whichismoreseverethanmislabelingalightrevisionasaheavyrevision.twoofthethreecasesaccountforthetextswhichdescribethepagerankalgorithm.one
PDFM-R2-U_ALL,fp,sample-3.pdf,https://whichiswhythecompositionofallthreedimensionsperformsslightlyworsethanthanthecombinationofonlycontentandstructuralfeatures.fo
PDFM-R2-U_ALL,fp,sample-3.pdf,https://whichmaybeviolatedbydifferentrhetoricalstrategies.se
PDFM-R2-U_ALL,fp,sample-3.pdf,https://whichmayhaveresultedinsubjectivejudgments.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://whichonlyperformsonthesamelevelasthebestindividualmeasurepart-of-speech3-gramscontainment.com
PDFM-R2-U_ALL,fp,sample-3.pdf,https://whichperformsslightlyworsethancontentmeasuresaloneduetothelowerperformanceofstructuralmeasuresonthisdataset.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://whichwouldallowtoalsoidentifypotentialinstancesoftextreuseforonlypartiallymatchingtexts.th
PDFM-R2-U_ALL,fp,sample-3.pdf,https://while413casesoftrueparaphraseswerenotrecognized.how
PDFM-R2-U_ALL,fp,sample-3.pdf,https://whileitdoesnotnecessarilyentailthatareaderperceiveschangesinthevocabularyusage.se
PDFM-R2-U_ALL,fp,sample-3.pdf,https://whiletheincreaseoftypessteadilyslowsdown.inc
PDFM-R2-U_ALL,fp,sample-3.pdf,https://withapplicationtotwocasesofdisputedauthorship.bio
PDFM-R2-U_ALL,fp,sample-3.pdf,https://withlotsofnewfactsbeingintroducedthere.co
PDFM-R2-U_ALL,fp,sample-3.pdf,https://withtheadditionalconstraintthatthereuseneedstobeunacknowledged.ne
PDFM-R2-U_ALL,fp,sample-3.pdf,https://withthemeasuresgreedystringtilingandword2-gramscontainmentperformingbest.as
PDFM-R2-U_ALL,fp,sample-4.pdf,https://applications.stream
PDFM-R2-U_ALL,fp,sample-4.pdf,https://back.us
PDFM-R2-U_ALL,fp,sample-4.pdf,https://clemson.edu
PDFM-R2-U_ALL,fp,sample-4.pdf,https://cs.odu.edu
PDFM-R2-U_ALL,fp,sample-4.pdf,https://date.fi
PDFM-R2-U_ALL,fp,sample-4.pdf,https://dfs.tab
PDFM-R2-U_ALL,fp,sample-4.pdf,https://forstreaming.fi
PDFM-R2-U_ALL,fp,sample-4.pdf,https://github11.ac
PDFM-R2-U_ALL,fp,sample-4.pdf,https://improvement.data
PDFM-R2-U_ALL,fp,sample-4.pdf,https://optimizations.gr
PDFM-R2-U_ALL,fp,sample-4.pdf,https://order.fi
PDFM-R2-U_ALL,fp,sample-4.pdf,https://paradigms.ac
PDFM-R2-U_ALL,fp,sample-4.pdf,https://programming.computer
PDFM-R2-U_ALL,fp,sample-4.pdf,https://purposes.in
PDFM-R2-U_ALL,fp,sample-4.pdf,https://recorded.mo
PDFM-R2-U_ALL,fp,sample-4.pdf,https://results.ke
PDFM-R2-U_ALL,fp,sample-4.pdf,https://sponsors.re
PDFM-R2-U_ALL,fp,sample-4.pdf,https://streaminghub.us
PDFM-R2-U_ALL,fp,sample-4.pdf,https://streams.fo
PDFM-R2-U_ALL,fp,sample-4.pdf,https://streams.here
PDFM-R2-U_ALL,fp,sample-4.pdf,https://workflows.as
PDFM-R2-U_ALL,fp,sample-4.pdf,https://workflows.to
PDFM-R2-U_ALL,fp,sample-5.pdf,https://2003.app
PDFM-R2-U_ALL,fp,sample-5.pdf,https://350regen.ph
PDFM-R2-U_ALL,fp,sample-5.pdf,https://8.tr
PDFM-R2-U_ALL,fp,sample-5.pdf,https://a.fr
PDFM-R2-U_ALL,fp,sample-5.pdf,https://accuracy.mil
PDFM-R2-U_ALL,fp,sample-5.pdf,https://accuracy.pe
PDFM-R2-U_ALL,fp,sample-5.pdf,https://acm.ac
PDFM-R2-U_ALL,fp,sample-5.pdf,https://acm.org
PDFM-R2-U_ALL,fp,sample-5.pdf,https://algorithms.si
PDFM-R2-U_ALL,fp,sample-5.pdf,https://angles.fi
PDFM-R2-U_ALL,fp,sample-5.pdf,https://antenna.fi
PDFM-R2-U_ALL,fp,sample-5.pdf,https://antennas.us
PDFM-R2-U_ALL,fp,sample-5.pdf,https://apa.fi
PDFM-R2-U_ALL,fp,sample-5.pdf,https://apa.re
PDFM-R2-U_ALL,fp,sample-5.pdf,https://as-sumption.to
PDFM-R2-U_ALL,fp,sample-5.pdf,https://back-ground.in
PDFM-R2-U_ALL,fp,sample-5.pdf,https://background.fi
PDFM-R2-U_ALL,fp,sample-5.pdf,https://beam-steering.data
PDFM-R2-U_ALL,fp,sample-5.pdf,https://beam-steering.to
PDFM-R2-U_ALL,fp,sample-5.pdf,https://beamwidth.to
PDFM-R2-U_ALL,fp,sample-5.pdf,https://bg.fi
PDFM-R2-U_ALL,fp,sample-5.pdf,https://blocked.how
PDFM-R2-U_ALL,fp,sample-5.pdf,https://can-cellation1.int
PDFM-R2-U_ALL,fp,sample-5.pdf,https://classification.pa
PDFM-R2-U_ALL,fp,sample-5.pdf,https://counting.to
PDFM-R2-U_ALL,fp,sample-5.pdf,https://default.bot
PDFM-R2-U_ALL,fp,sample-5.pdf,https://desktop.th
PDFM-R2-U_ALL,fp,sample-5.pdf,https://detected.ac
PDFM-R2-U_ALL,fp,sample-5.pdf,https://detection.fi
PDFM-R2-U_ALL,fp,sample-5.pdf,https://differentusers.fi
PDFM-R2-U_ALL,fp,sample-5.pdf,https://direction.th
PDFM-R2-U_ALL,fp,sample-5.pdf,https://directions.co
PDFM-R2-U_ALL,fp,sample-5.pdf,https://distance.th
PDFM-R2-U_ALL,fp,sample-5.pdf,https://drops.no
PDFM-R2-U_ALL,fp,sample-5.pdf,https://events.ph
PDFM-R2-U_ALL,fp,sample-5.pdf,https://fc.fr
PDFM-R2-U_ALL,fp,sample-5.pdf,https://feasible.th
PDFM-R2-U_ALL,fp,sample-5.pdf,https://france.co
PDFM-R2-U_ALL,fp,sample-5.pdf,https://gain.th
PDFM-R2-U_ALL,fp,sample-5.pdf,https://hypothesis.it
PDFM-R2-U_ALL,fp,sample-5.pdf,https://interest.to
PDFM-R2-U_ALL,fp,sample-5.pdf,https://kinect.ph
PDFM-R2-U_ALL,fp,sample-5.pdf,https://known.co
PDFM-R2-U_ALL,fp,sample-5.pdf,https://large.by
PDFM-R2-U_ALL,fp,sample-5.pdf,https://larger.fi
PDFM-R2-U_ALL,fp,sample-5.pdf,https://level.im
PDFM-R2-U_ALL,fp,sample-5.pdf,https://linearw.r.t.target
PDFM-R2-U_ALL,fp,sample-5.pdf,https://ma-terials.fi
PDFM-R2-U_ALL,fp,sample-5.pdf,https://ma-terials.la
PDFM-R2-U_ALL,fp,sample-5.pdf,https://mm.ba
PDFM-R2-U_ALL,fp,sample-5.pdf,https://mmwave.it
PDFM-R2-U_ALL,fp,sample-5.pdf,https://mtrack.fi
PDFM-R2-U_ALL,fp,sample-5.pdf,https://negligible.fi
PDFM-R2-U_ALL,fp,sample-5.pdf,https://noise.mini
PDFM-R2-U_ALL,fp,sample-5.pdf,https://object.si
PDFM-R2-U_ALL,fp,sample-5.pdf,https://objects.co
PDFM-R2-U_ALL,fp,sample-5.pdf,https://obtained.th
PDFM-R2-U_ALL,fp,sample-5.pdf,https://op-erations.no
PDFM-R2-U_ALL,fp,sample-5.pdf,https://opportunisticcalibration.fi
PDFM-R2-U_ALL,fp,sample-5.pdf,https://peaks.8.im
PDFM-R2-U_ALL,fp,sample-5.pdf,https://phase-tracking.fi
PDFM-R2-U_ALL,fp,sample-5.pdf,https://phase-tracking.su
PDFM-R2-U_ALL,fp,sample-5.pdf,https://phase.onl
PDFM-R2-U_ALL,fp,sample-5.pdf,https://phase.target
PDFM-R2-U_ALL,fp,sample-5.pdf,https://platform.fi
PDFM-R2-U_ALL,fp,sample-5.pdf,https://position.mtr
PDFM-R2-U_ALL,fp,sample-5.pdf,https://r.ch
PDFM-R2-U_ALL,fp,sample-5.pdf,https://radios.se
PDFM-R2-U_ALL,fp,sample-5.pdf,https://radios.tab
PDFM-R2-U_ALL,fp,sample-5.pdf,https://receiver.in
PDFM-R2-U_ALL,fp,sample-5.pdf,https://reflection.com
PDFM-R2-U_ALL,fp,sample-5.pdf,https://reflection.fi
PDFM-R2-U_ALL,fp,sample-5.pdf,https://reflection.th
PDFM-R2-U_ALL,fp,sample-5.pdf,https://region.fi
PDFM-R2-U_ALL,fp,sample-5.pdf,https://respectively.bot
PDFM-R2-U_ALL,fp,sample-5.pdf,https://response.mtr
PDFM-R2-U_ALL,fp,sample-5.pdf,https://rx.in
PDFM-R2-U_ALL,fp,sample-5.pdf,https://sensingapplications.ac
PDFM-R2-U_ALL,fp,sample-5.pdf,https://shifting.to
PDFM-R2-U_ALL,fp,sample-5.pdf,https://shortperiod.fi
PDFM-R2-U_ALL,fp,sample-5.pdf,https://signals.ph
PDFM-R2-U_ALL,fp,sample-5.pdf,https://signals.tab
PDFM-R2-U_ALL,fp,sample-5.pdf,https://space.ba
PDFM-R2-U_ALL,fp,sample-5.pdf,https://splineinterpolation.fi
PDFM-R2-U_ALL,fp,sample-5.pdf,https://steering.fi
PDFM-R2-U_ALL,fp,sample-5.pdf,https://strength.fi
PDFM-R2-U_ALL,fp,sample-5.pdf,https://subtracted.re
PDFM-R2-U_ALL,fp,sample-5.pdf,https://surface.fi
PDFM-R2-U_ALL,fp,sample-5.pdf,https://target.fo
PDFM-R2-U_ALL,fp,sample-5.pdf,https://target.how
PDFM-R2-U_ALL,fp,sample-5.pdf,https://target.st
PDFM-R2-U_ALL,fp,sample-5.pdf,https://target.th
PDFM-R2-U_ALL,fp,sample-5.pdf,https://tracking.in
PDFM-R2-U_ALL,fp,sample-5.pdf,https://tracking.mtr
PDFM-R2-U_ALL,fp,sample-5.pdf,https://tracking.pa
PDFM-R2-U_ALL,fp,sample-5.pdf,https://trackpad.cat
PDFM-R2-U_ALL,fp,sample-5.pdf,https://trajectory.th
PDFM-R2-U_ALL,fp,sample-5.pdf,https://truth.fo
PDFM-R2-U_ALL,fp,sample-5.pdf,https://uncertainties.re
PDFM-R2-U_ALL,fp,sample-5.pdf,https://value.it
PDFM-R2-U_ALL,fp,sample-5.pdf,https://var.to
PDFM-R2-U_ALL,fp,sample-5.pdf,https://variation.mtr
PDFM-R2-U_ALL,fp,sample-5.pdf,https://wisc.edu
PDFM-R2-U_ALL,fp,sample-5.pdf,https://word.fi
PDFM-R2-U_ALL,fp,sample-5.pdf,https://work.tr
PDFM-R2-U_ALL,fp,sample-5.pdf,https://works.men
PDFM-R2-U_ALL,fp,sample-5.pdf,https://www.dailywireless.org/2014/01/03
PDFM-R2-U_ALL,fp,sample-5.pdf,https://www.mcelhearn.com/not-a-review-leap-motioncontroller-fails-
PDFM-R2-U_ALL,fp,sample-5.pdf,https://www.roborealm.com/help/microsoft
PDFM-R2-U_ALL,fp,sample-6.pdf,https://1.fi
PDFM-R2-U_ALL,fp,sample-6.pdf,https://1.in
PDFM-R2-U_ALL,fp,sample-6.pdf,https://1.tab
PDFM-R2-U_ALL,fp,sample-6.pdf,https://19.market
PDFM-R2-U_ALL,fp,sample-6.pdf,https://2.tr
PDFM-R2-U_ALL,fp,sample-6.pdf,https://2008.th
PDFM-R2-U_ALL,fp,sample-6.pdf,https://analysis.se
PDFM-R2-U_ALL,fp,sample-6.pdf,https://areas.th
PDFM-R2-U_ALL,fp,sample-6.pdf,https://changes.mo
PDFM-R2-U_ALL,fp,sample-6.pdf,https://characters.af
PDFM-R2-U_ALL,fp,sample-6.pdf,https://content.th
PDFM-R2-U_ALL,fp,sample-6.pdf,https://days.th
PDFM-R2-U_ALL,fp,sample-6.pdf,https://dimensions.pa
PDFM-R2-U_ALL,fp,sample-6.pdf,https://djia.gr
PDFM-R2-U_ALL,fp,sample-6.pdf,https://ec.sc
PDFM-R2-U_ALL,fp,sample-6.pdf,https://errors.se
PDFM-R2-U_ALL,fp,sample-6.pdf,https://h.co
PDFM-R2-U_ALL,fp,sample-6.pdf,https://happy.th
PDFM-R2-U_ALL,fp,sample-6.pdf,https://indiana.edu
PDFM-R2-U_ALL,fp,sample-6.pdf,https://l.re
PDFM-R2-U_ALL,fp,sample-6.pdf,https://later.su
PDFM-R2-U_ALL,fp,sample-6.pdf,https://manchester.ac.uk
PDFM-R2-U_ALL,fp,sample-6.pdf,https://market.jo
PDFM-R2-U_ALL,fp,sample-6.pdf,https://ourwork.re
PDFM-R2-U_ALL,fp,sample-6.pdf,https://period.in
PDFM-R2-U_ALL,fp,sample-6.pdf,https://periods.fi
PDFM-R2-U_ALL,fp,sample-6.pdf,https://prediction.la
PDFM-R2-U_ALL,fp,sample-6.pdf,https://prices.si
PDFM-R2-U_ALL,fp,sample-6.pdf,https://range.so
PDFM-R2-U_ALL,fp,sample-6.pdf,https://receipts.al
PDFM-R2-U_ALL,fp,sample-6.pdf,https://research.ac
PDFM-R2-U_ALL,fp,sample-6.pdf,https://series.as
PDFM-R2-U_ALL,fp,sample-6.pdf,https://series.to
PDFM-R2-U_ALL,fp,sample-6.pdf,https://site6.to
PDFM-R2-U_ALL,fp,sample-6.pdf,https://states.bi
PDFM-R2-U_ALL,fp,sample-6.pdf,https://std.er
PDFM-R2-U_ALL,fp,sample-6.pdf,https://t.like
PDFM-R2-U_ALL,fp,sample-6.pdf,https://thanksgiving.mo
PDFM-R2-U_ALL,fp,sample-6.pdf,https://times.in
PDFM-R2-U_ALL,fp,sample-6.pdf,https://twitter.com
PDFM-R2-U_ALL,fp,sample-6.pdf,https://value.to
PDFM-R2-U_ALL,fp,sample-6.pdf,https://xt-n.fi
PDFM-R2-U_ALL,fp,sample-7.pdf,https://arcu.se
PDFM-R2-U_ALL,fp,sample-7.pdf,https://cursus.al
PDFM-R2-U_ALL,fp,sample-7.pdf,https://egestas.int
PDFM-R2-U_ALL,fp,sample-7.pdf,https://faucibus.na
PDFM-R2-U_ALL,fp,sample-7.pdf,https://finibusfinibus.do
PDFM-R2-U_ALL,fp,sample-7.pdf,https://leo.do
PDFM-R2-U_ALL,fp,sample-7.pdf,https://magna.su
PDFM-R2-U_ALL,fp,sample-7.pdf,https://maximusornare.nu
PDFM-R2-U_ALL,fp,sample-7.pdf,https://ornare.se
PDFM-R2-U_ALL,fp,sample-7.pdf,https://purus.cu
PDFM-R2-U_ALL,fp,sample-7.pdf,https://purus.in
PDFM-R2-U_ALL,fp,sample-7.pdf,https://quis.nu
PDFM-R2-U_ALL,fp,sample-7.pdf,https://tincidunt.se
PDFM-R2-U_ALL,fp,sample-8.pdf,https://arcu.se
PDFM-R2-U_ALL,fp,sample-8.pdf,https://cursus.al
PDFM-R2-U_ALL,fp,sample-8.pdf,https://egestas.int
PDFM-R2-U_ALL,fp,sample-8.pdf,https://finibusfinibus.do
PDFM-R2-U_ALL,fp,sample-8.pdf,https://leo.do
PDFM-R2-U_ALL,fp,sample-8.pdf,https://magna.su
PDFM-R2-U_ALL,fp,sample-8.pdf,https://ornare.nu
PDFM-R2-U_ALL,fp,sample-8.pdf,https://purus.cu
PDFM-R2-U_ALL,fp,sample-8.pdf,https://purus.in
PDFM-R2-U_ALL,fp,sample-8.pdf,https://quis.nu
PDFM-R2-U_ALL,fp,sample-8.pdf,https://tincidunt.se
PDFM-R2-U_ALL,fn,sample-1.pdf,https://sh.rice.edu/cognitive-engagement/ tabletgaze
PDFM-R2-U_ALL,fn,sample-3.pdf,https://code.google.com/p/dkpro-similarity-asl
PDFM-R2-U_ALL,fn,sample-3.pdf,https://www.ukp.tu-darmstadt.de/data/text-similarity/text-reuse-annotations
PDFM-R2-U_ALL,fn,sample-5.pdf,https://www.dailywireless.org/2014/01/03/60ghz-backhaul-for-small-cells
PDFM-R2-U_ALL,fn,sample-5.pdf,https://www.mcelhearn.com/not-a-review-leap-motioncontroller-fails-in-normal-conditions
PDFM-R2-U_ALL,fn,sample-5.pdf,https://www.roborealm.com/help/microsoft kinect.php
PDFM-R2-U_ALL,fn,sample-6.pdf,https://terramood.informatics.indiana.edu/data
PDFM-R3-U_ALL,tp,sample-1.pdf,https://ait.ethz.ch/projects/2020/eth-xgaze
PDFM-R3-U_ALL,tp,sample-1.pdf,https://ait.ethz.ch/projects/2020/eve
PDFM-R3-U_ALL,tp,sample-1.pdf,https://cs.columbia.edu/cave/databases/columbia_gaze
PDFM-R3-U_ALL,tp,sample-1.pdf,https://gaze360.csail.mit.edu
PDFM-R3-U_ALL,tp,sample-1.pdf,https://gazecapture.csail.mit.edu
PDFM-R3-U_ALL,tp,sample-1.pdf,https://github.com/cleardusk/3ddfa_v2
PDFM-R3-U_ALL,tp,sample-1.pdf,https://github.com/dongzelian/multi-view-gaze
PDFM-R3-U_ALL,tp,sample-1.pdf,https://github.com/kpzhang93/mtcnn_face_detection_alignment
PDFM-R3-U_ALL,tp,sample-1.pdf,https://github.com/marekkowalski/deepalignmentnetwork
PDFM-R3-U_ALL,tp,sample-1.pdf,https://github.com/tadasbaltrusaitis/openface
PDFM-R3-U_ALL,tp,sample-1.pdf,https://github.com/tobias-fischer/rt_gene
PDFM-R3-U_ALL,tp,sample-1.pdf,https://github.com/yadiraf/prnet
PDFM-R3-U_ALL,tp,sample-1.pdf,https://idiap.ch/dataset/eyediap
PDFM-R3-U_ALL,tp,sample-1.pdf,https://mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/research/gaze-based-human-computer-interaction/its-written-all-over-your-face-full-face-appearance-based-gaze-estimation
PDFM-R3-U_ALL,tp,sample-1.pdf,https://mpi-inf.mpg.de/invisibleeye
PDFM-R3-U_ALL,tp,sample-1.pdf,https://mpi-inf.mpg.de/mpiigaze
PDFM-R3-U_ALL,tp,sample-1.pdf,https://phi-ai.org/gazehub
PDFM-R3-U_ALL,tp,sample-1.pdf,https://pypi.org/project/dlib/19.6.0
PDFM-R3-U_ALL,tp,sample-1.pdf,https://sites.google.com/nvidia.com/nvgaze
PDFM-R3-U_ALL,tp,sample-1.pdf,https://ut-vision.org/datasets
PDFM-R3-U_ALL,tp,sample-1.pdf,https://www.sciencedirect.com/science/article/pii/s0169814115000761
PDFM-R3-U_ALL,tp,sample-1.pdf,https://www.sciencedirect.com/science/article/pii/s0262885614000171
PDFM-R3-U_ALL,tp,sample-1.pdf,https://www.sciencedirect.com/science/article/pii/s092523121501783x
PDFM-R3-U_ALL,tp,sample-1.pdf,https://www.sciencedirect.com/science/article/pii/s1878929316300846
PDFM-R3-U_ALL,tp,sample-2.pdf,https://nlp.stanford.edu/projects/glove
PDFM-R3-U_ALL,tp,sample-2.pdf,https://www.aaai.org
PDFM-R3-U_ALL,tp,sample-3.pdf,https://code.google.com/p/dkpro-similarity-asl
PDFM-R3-U_ALL,tp,sample-3.pdf,https://www.wikipedia.org
PDFM-R3-U_ALL,tp,sample-3.pdf,https://www.wiktionary.org
PDFM-R3-U_ALL,tp,sample-4.pdf,https://aws.amazon.com/kinesis
PDFM-R3-U_ALL,tp,sample-4.pdf,https://developers.google.com/protocol-buffers
PDFM-R3-U_ALL,tp,sample-4.pdf,https://flink.apache.org
PDFM-R3-U_ALL,tp,sample-4.pdf,https://github.com/nirdslab/streaminghub-conduit
PDFM-R3-U_ALL,tp,sample-4.pdf,https://github.com/nirdslab/streaminghub-dfs
PDFM-R3-U_ALL,tp,sample-4.pdf,https://github.com/sccn/labstreaminglayer
PDFM-R3-U_ALL,tp,sample-4.pdf,https://idl.cs.washington.edu/papers/reactive-vega
PDFM-R3-U_ALL,tp,sample-4.pdf,https://kepler-project.org
PDFM-R3-U_ALL,tp,sample-4.pdf,https://mqtt.org
PDFM-R3-U_ALL,tp,sample-4.pdf,https://nodered.org
PDFM-R3-U_ALL,tp,sample-4.pdf,https://www.knime.com
PDFM-R3-U_ALL,tp,sample-5.pdf,https://cinetics.com/two-axis360
PDFM-R3-U_ALL,tp,sample-5.pdf,https://myscript.com/technology
PDFM-R3-U_ALL,tp,sample-5.pdf,https://vubiq.com/v60wgd03
PDFM-R3-U_ALL,tp,sample-5.pdf,https://warp.rice.edu/trac/wiki
PDFM-R3-U_ALL,tp,sample-5.pdf,"https://www.pcmag.com/article2/0,2817,2454187,00.asp"
PDFM-R3-U_ALL,tp,sample-5.pdf,https://www.tdk.com
PDFM-R3-U_ALL,tp,sample-5.pdf,https://www.vicon.com
PDFM-R3-U_ALL,tp,sample-6.pdf,https://terramood.informatics.indiana.edu/data
PDFM-R3-U_ALL,tp,sample-6.pdf,https://www.ccs.neu.edu/home/amislove/twittermood
PDFM-R3-U_ALL,tp,sample-6.pdf,https://www.cs.pitt.edu/mpqa/opinionfinderrelease
PDFM-R3-U_ALL,tp,sample-6.pdf,https://www.gallup.com/poll/122840/gallup-daily-economic-indexes.aspx
PDFM-R3-U_ALL,tp,sample-6.pdf,https://www.sca.isr.umich.edu
PDFM-R3-U_ALL,tp,sample-7.pdf,https://github.com/nirdslab/streaminghub-conduit
PDFM-R3-U_ALL,tp,sample-7.pdf,https://github.com/nirdslab/streaminghub-dfs
PDFM-R3-U_ALL,tp,sample-7.pdf,https://www.cs.odu.edu/~sampath
PDFM-R3-U_ALL,tp,sample-7.pdf,https://www.cs.odu.edu/~yasith
PDFM-R3-U_ALL,tp,sample-8.pdf,https://github.com/nirdslab/streaminghub-conduit
PDFM-R3-U_ALL,tp,sample-8.pdf,https://github.com/nirdslab/streaminghub-dfs
PDFM-R3-U_ALL,tp,sample-8.pdf,https://www.cs.odu.edu/~sampath
PDFM-R3-U_ALL,tp,sample-8.pdf,https://www.cs.odu.edu/~yasith
PDFM-R3-U_ALL,fp,sample-1.pdf,https://sh.rice.edu/cognitive-engagement/tabletgaze
PDFM-R3-U_ALL,fp,sample-3.pdf,https://www.ukp.tu-darmstadt.de/data/text-similarity/text-reuse-annotations12strengthofagreementforkvaluesaccordingtolandisandkoch
PDFM-R3-U_ALL,fp,sample-5.pdf,https://www.dailywireless.org/2014/01/03
PDFM-R3-U_ALL,fp,sample-5.pdf,https://www.mcelhearn.com/not-a-review-leap-motioncontroller-fails-
PDFM-R3-U_ALL,fp,sample-5.pdf,https://www.roborealm.com/help/microsoft
PDFM-R3-U_ALL,fn,sample-1.pdf,https://sh.rice.edu/cognitive-engagement/ tabletgaze
PDFM-R3-U_ALL,fn,sample-3.pdf,https://www.gutenberg.org
PDFM-R3-U_ALL,fn,sample-3.pdf,https://www.ukp.tu-darmstadt.de
PDFM-R3-U_ALL,fn,sample-3.pdf,https://www.ukp.tu-darmstadt.de/data/text-similarity/text-reuse-annotations
PDFM-R3-U_ALL,fn,sample-5.pdf,https://www.dailywireless.org/2014/01/03/60ghz-backhaul-for-small-cells
PDFM-R3-U_ALL,fn,sample-5.pdf,https://www.mcelhearn.com/not-a-review-leap-motioncontroller-fails-in-normal-conditions
PDFM-R3-U_ALL,fn,sample-5.pdf,https://www.roborealm.com/help/microsoft kinect.php
PDFM-R4-U_ALL,tp,sample-1.pdf,https://ait.ethz.ch/projects/2020/eth-xgaze
PDFM-R4-U_ALL,tp,sample-1.pdf,https://ait.ethz.ch/projects/2020/eve
PDFM-R4-U_ALL,tp,sample-1.pdf,https://cs.columbia.edu/cave/databases/columbia_gaze
PDFM-R4-U_ALL,tp,sample-1.pdf,https://gaze360.csail.mit.edu
PDFM-R4-U_ALL,tp,sample-1.pdf,https://gazecapture.csail.mit.edu
PDFM-R4-U_ALL,tp,sample-1.pdf,https://github.com/cleardusk/3ddfa_v2
PDFM-R4-U_ALL,tp,sample-1.pdf,https://github.com/dongzelian/multi-view-gaze
PDFM-R4-U_ALL,tp,sample-1.pdf,https://github.com/kpzhang93/mtcnn_face_detection_alignment
PDFM-R4-U_ALL,tp,sample-1.pdf,https://github.com/marekkowalski/deepalignmentnetwork
PDFM-R4-U_ALL,tp,sample-1.pdf,https://github.com/tadasbaltrusaitis/openface
PDFM-R4-U_ALL,tp,sample-1.pdf,https://github.com/tobias-fischer/rt_gene
PDFM-R4-U_ALL,tp,sample-1.pdf,https://github.com/yadiraf/prnet
PDFM-R4-U_ALL,tp,sample-1.pdf,https://idiap.ch/dataset/eyediap
PDFM-R4-U_ALL,tp,sample-1.pdf,https://mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/research/gaze-based-human-computer-interaction/its-written-all-over-your-face-full-face-appearance-based-gaze-estimation
PDFM-R4-U_ALL,tp,sample-1.pdf,https://mpi-inf.mpg.de/invisibleeye
PDFM-R4-U_ALL,tp,sample-1.pdf,https://mpi-inf.mpg.de/mpiigaze
PDFM-R4-U_ALL,tp,sample-1.pdf,https://phi-ai.org/gazehub
PDFM-R4-U_ALL,tp,sample-1.pdf,https://pypi.org/project/dlib/19.6.0
PDFM-R4-U_ALL,tp,sample-1.pdf,https://sites.google.com/nvidia.com/nvgaze
PDFM-R4-U_ALL,tp,sample-1.pdf,https://ut-vision.org/datasets
PDFM-R4-U_ALL,tp,sample-1.pdf,https://www.sciencedirect.com/science/article/pii/s0169814115000761
PDFM-R4-U_ALL,tp,sample-1.pdf,https://www.sciencedirect.com/science/article/pii/s0262885614000171
PDFM-R4-U_ALL,tp,sample-1.pdf,https://www.sciencedirect.com/science/article/pii/s092523121501783x
PDFM-R4-U_ALL,tp,sample-1.pdf,https://www.sciencedirect.com/science/article/pii/s1878929316300846
PDFM-R4-U_ALL,tp,sample-2.pdf,https://nlp.stanford.edu/projects/glove
PDFM-R4-U_ALL,tp,sample-2.pdf,https://www.aaai.org
PDFM-R4-U_ALL,tp,sample-3.pdf,https://www.gutenberg.org
PDFM-R4-U_ALL,tp,sample-3.pdf,https://www.ukp.tu-darmstadt.de
PDFM-R4-U_ALL,tp,sample-3.pdf,https://www.wikipedia.org
PDFM-R4-U_ALL,tp,sample-3.pdf,https://www.wiktionary.org
PDFM-R4-U_ALL,tp,sample-4.pdf,https://aws.amazon.com/kinesis
PDFM-R4-U_ALL,tp,sample-4.pdf,https://developers.google.com/protocol-buffers
PDFM-R4-U_ALL,tp,sample-4.pdf,https://flink.apache.org
PDFM-R4-U_ALL,tp,sample-4.pdf,https://github.com/nirdslab/streaminghub-conduit
PDFM-R4-U_ALL,tp,sample-4.pdf,https://github.com/nirdslab/streaminghub-dfs
PDFM-R4-U_ALL,tp,sample-4.pdf,https://github.com/sccn/labstreaminglayer
PDFM-R4-U_ALL,tp,sample-4.pdf,https://idl.cs.washington.edu/papers/reactive-vega
PDFM-R4-U_ALL,tp,sample-4.pdf,https://kepler-project.org
PDFM-R4-U_ALL,tp,sample-4.pdf,https://mqtt.org
PDFM-R4-U_ALL,tp,sample-4.pdf,https://nodered.org
PDFM-R4-U_ALL,tp,sample-4.pdf,https://www.knime.com
PDFM-R4-U_ALL,tp,sample-5.pdf,https://cinetics.com/two-axis360
PDFM-R4-U_ALL,tp,sample-5.pdf,https://myscript.com/technology
PDFM-R4-U_ALL,tp,sample-5.pdf,https://vubiq.com/v60wgd03
PDFM-R4-U_ALL,tp,sample-5.pdf,https://warp.rice.edu/trac/wiki
PDFM-R4-U_ALL,tp,sample-5.pdf,"https://www.pcmag.com/article2/0,2817,2454187,00.asp"
PDFM-R4-U_ALL,tp,sample-5.pdf,https://www.tdk.com
PDFM-R4-U_ALL,tp,sample-5.pdf,https://www.vicon.com
PDFM-R4-U_ALL,tp,sample-6.pdf,https://terramood.informatics.indiana.edu/data
PDFM-R4-U_ALL,tp,sample-6.pdf,https://www.ccs.neu.edu/home/amislove/twittermood
PDFM-R4-U_ALL,tp,sample-6.pdf,https://www.cs.pitt.edu/mpqa/opinionfinderrelease
PDFM-R4-U_ALL,tp,sample-6.pdf,https://www.gallup.com/poll/122840/gallup-daily-economic-indexes.aspx
PDFM-R4-U_ALL,tp,sample-6.pdf,https://www.sca.isr.umich.edu
PDFM-R4-U_ALL,tp,sample-7.pdf,https://github.com/nirdslab/streaminghub-conduit
PDFM-R4-U_ALL,tp,sample-7.pdf,https://github.com/nirdslab/streaminghub-dfs
PDFM-R4-U_ALL,tp,sample-7.pdf,https://www.cs.odu.edu/~sampath
PDFM-R4-U_ALL,tp,sample-7.pdf,https://www.cs.odu.edu/~yasith
PDFM-R4-U_ALL,tp,sample-8.pdf,https://github.com/nirdslab/streaminghub-conduit
PDFM-R4-U_ALL,tp,sample-8.pdf,https://github.com/nirdslab/streaminghub-dfs
PDFM-R4-U_ALL,tp,sample-8.pdf,https://www.cs.odu.edu/~sampath
PDFM-R4-U_ALL,tp,sample-8.pdf,https://www.cs.odu.edu/~yasith
PDFM-R4-U_ALL,fp,sample-1.pdf,https://sh.rice.edu/cognitive-engagement/tabletgaze
PDFM-R4-U_ALL,fp,sample-3.pdf,https://code.google.com
PDFM-R4-U_ALL,fp,sample-5.pdf,https://www.dailywireless.org/2014/01/03
PDFM-R4-U_ALL,fp,sample-5.pdf,https://www.mcelhearn.com/not-a-review-leap-motioncontroller-fails-
PDFM-R4-U_ALL,fp,sample-5.pdf,https://www.roborealm.com/help/microsoft
PDFM-R4-U_ALL,fn,sample-1.pdf,https://sh.rice.edu/cognitive-engagement/ tabletgaze
PDFM-R4-U_ALL,fn,sample-3.pdf,https://code.google.com/p/dkpro-similarity-asl
PDFM-R4-U_ALL,fn,sample-3.pdf,https://www.ukp.tu-darmstadt.de/data/text-similarity/text-reuse-annotations
PDFM-R4-U_ALL,fn,sample-5.pdf,https://www.dailywireless.org/2014/01/03/60ghz-backhaul-for-small-cells
PDFM-R4-U_ALL,fn,sample-5.pdf,https://www.mcelhearn.com/not-a-review-leap-motioncontroller-fails-in-normal-conditions
PDFM-R4-U_ALL,fn,sample-5.pdf,https://www.roborealm.com/help/microsoft kinect.php
