<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">StreamingHub: A Framework for FAIR Data Stream Processing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yasith</forename><surname>Jayawardana</surname></persName>
							<email>yasith@cs.odu.edu</email>
						</author>
						<author>
							<persName><forename type="first">Andrew</forename><forename type="middle">T</forename><surname>Duchowski</surname></persName>
							<email>duchowski@clemson.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<address>
									<postBox>60 61 62 63 64 65 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111</postBox>
									<postCode>112 113, 115 116</postCode>
									<settlement>114</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science Old Dominion University</orgName>
								<address>
									<settlement>Norfolk</settlement>
									<region>VA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">School of Computing Clemson University Clemson</orgName>
								<orgName type="institution">Sampath Jayarathna</orgName>
								<address>
									<region>SC</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Department of Computer Science Old Dominion University</orgName>
								<address>
									<settlement>Norfolk</settlement>
									<region>VA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">StreamingHub: A Framework for FAIR Data Stream Processing</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-07-14T09:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Metadata</term>
					<term>Data Stream Processing</term>
					<term>Scientific Workflows</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Reusable data and reproducible results are cornerstones of quality research. Ideally, all research assets should be reusable and reproducible. In practice, however, this aspect is easily overlooked. As a solution, we propose a framework to build FAIR-compliant data stream processing workflows that are both reusable and reproducible by design. We evaluate our framework on two real-time applications in the 1) eye movement analysis and 2) weather analysis domains. Results show that our framework generalizes across both domains, and facilitates building real-time applications with reproducible results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>In this era of data-intensive, collaborative research, ensuring that research assets are reusable and reproducible is equally as important as creating them. Having quality, FAIR-compliant <ref type="bibr" target="#b14">[15]</ref> (i.e., findability, accessibility, interoperability, and reusability) metadata is thus of paramount importance. While advancements in data sharing technology have encouraged data reuse, creating reusable, reproducible research assets is a painstaking process that involves creating metadata that is unambiguous to a novice <ref type="bibr" target="#b11">[12]</ref>. These circumstances create a causality where research assets are published with poor metadata, and end-users thereby struggle to reuse them. Hence, the process of generating metadata has potential for improvement.</p><p>Data-intensive research typically involve developing, executing, and validating a series of data manipulation and visualization steps (i.e., a workflow) that lead to a meaningful outcome. A scientific workflow (SWF) system is a form of a workflow management system built for this specific need. SWF systems allow complex data computations and parameter-driven simulations to be fine-tuned at a component-level, and to test out alternative setups with ease <ref type="bibr" target="#b4">[5]</ref>. While a plethora of SWF systems exist <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b10">11]</ref>, SWF systems such as KNIME 1 , Kepler 2 , and Node-RED 3 allow users to build workflows through visual programming <ref type="bibr" target="#b1">[2]</ref>. This appeals to non-programmers, such as scientists with no programming background, as it abstracts away the complexity of underlying programming <ref type="bibr" target="#b0">[1]</ref>. Moreover, SWF systems such as Node-RED and Flink 4 are geared towards stream-processing, but supports batch-processing as a special case of stream-processing. In either case, the optimal execution strategy may differ across workloads as it depends on the nature of the data <ref type="bibr" target="#b5">[6]</ref>. Having FAIR-compliant metadata on both data and workflows https://www.knime.com/ 2 https://kepler-project.org/ 3 https://nodered.org/ 4 https://flink.apache.org/ could be beneficial towards such optimization. We hypothesize that a SWF system driven by FAIR-compliant metadata and visual programming, would simplify the design and execution of data stream processing workflows.</p><p>As a solution, we propose StreamingHub: a framework to simplify data stream processing through reusable data, reproducible workflows, and visual programming. Our contribution is three-fold: <ref type="bibr" target="#b0">(1)</ref> We propose an extensible, FAIR-compliant metadata format to describe data sources, data analytics, and data sets.</p><p>(2) We propose two heuristics to identify bottlenecks and dataintensive operations in workflows. (3) We demonstrate how we built self-describing workflows and data-driven visualizations on StreamingHub.</p><p>Using three datasets, we evaluate StreamingHub on real-time applications in the domains of 1) eye movement analysis and 2) weather analysis. Here, we describe our data source(s) using the proposed metadata format, build stream processing workflows that leverage this metadata, and observe their resource utilization using the proposed heuristics. Based on our observations, we discuss the utility of StreamingHub for data stream processing, and uncover important challenges that inspire future work. StreamingHub consists of four components: 1) Dataset File System, 2) Data Mux, 3) Workflow Designer, and 4) Operations Dashboard (see Figure <ref type="figure" target="#fig_0">1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">STREAMINGHUB ARCHITECTURE</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Dataset File System (DFS)</head><p>DFS <ref type="bibr" target="#b4">5</ref> is a collection of schemas for describing data-sources, dataanalytics, and data-sets <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref>. Data-source metadata provides attributes to describe data streams, such as frequency and channel count. Data-analytic metadata provides attributes to describe analytic data streams and their provenance (i.e., the hierarchy of transformations that lead to it). Data-set metadata provides attributes to describe the ownership, identification, provenance, and "spatial dimensions" of a dataset. Here, spatial dimensions indicate different perspectives that data could be viewed from. For instance, data obtained from multiple subjects engaging in different tasks can be viewed "subject"-wise and "task"-wise. Table <ref type="table" target="#tab_0">1</ref> provides a summary of the metadata attributes used in DFS. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Data Mux</head><p>The data mux operates as a bridge between connected sensors, datasets, and data-streams. It uses DFS metadata to create the datastreams needed for a task, and provides three modes of execution:</p><p>• Live -stream live data from connected sensors • Replay -replay a dataset as a data-stream • Simulate -generate a simulated data-stream from a dataset In live mode, it utilizes only data-source metadata. In replay and simulate modes, it utilizes all DFS metadata. The Data Mux uses LabStreamingLayer <ref type="bibr" target="#b5">6</ref> wrapped within a WebSocket API to stream data into workflows and back.</p><p>Usage: The user initiates the data mux by spawning outlets on the local network, which, depending on the execution mode, may stream either live, replayed, or simulated data. Next, the user discovers data-streams on the network via the resolver, and selects a subset of them for analysis. Note that spawning of outlets and subscribing to outlets are kept independent to improve scalability. Next, the resolver spawns inlets for the selected data-streams, performs time-synchronization, and passes time-synchronized data into the aggregator to merge them together. When merging data-streams, the aggregator adheres to the data frequencies specified in the metadata, to facilitate temporally-consistent replay and simulation. The data mux then transitions into an awaiting state, and remains there until it receives a subscription from a workflow. Once a workflow subscribes, the data mux transitions into a streaming state, and remains there until that subscriber disconnects, or until the data stream itself is exhausted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Workflow Designer</head><p>The workflow designer is the front-end for users to build scientific workflows. Workflows define which operations are performed on the data streamed from the data mux. A workflow comprises of transformation nodes and visualization nodes that are bound into a directed graph using connectors. Transformation nodes define the operations performed on input data, and the output(s) generated from them. Each transformation node may accept multiple data streams as input, and may generate multiple data streams as output. Visualization nodes, on the other hand, may accept multiple data streams as inputs, but instead of generating output streams, they generate visualizations. In this work, we primarily use Vega <ref type="bibr" target="#b13">[14]</ref> to declare visualization nodes in JSON format. Additionally, a node itself can be defined as a workflow, allowing users to form hierarchies of workflows. This allows users to re-use existing workflows to form more complex workflows, which also serves as a form of abstraction (See Figure <ref type="figure" target="#fig_3">2</ref> for an example). We use Node-RED to implement the workflow designer, as it offers a visual programming front-end to build workflows, while allowing users to import/export workflows in JSON format. This facilitates both technical and non-technical users to design workflows and share them among peers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Operations Dashboard</head><p>The operations dashboard allows users to monitor active workflows, generate interactive visualizations, and perform data-stream control actions. When designing a workflow, users may add visualization nodes at any desired point in the workflow. Each visualization node, in turn, would generate a dynamic, reactive visualization on the operations dashboard. In terms of data-stream control, we propose to include five data-stream control actions: start, stop, pause, resume, and seek. These actions would enable users to temporally navigate data streams and perform visual analytics <ref type="bibr" target="#b9">[10]</ref>; a particularly useful method to analyze high-frequency, high-dimensional data. We use Node-RED to implement the operations dashboard (See Figure <ref type="figure" target="#fig_5">4</ref> for a sample dashboard).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">FLUIDITY AND GROWTH FACTOR</head><p>Apart from metrics such as latency, throughput, scalability, and resource utilization, we propose two heuristics: 1) fluidity and 2) growth factor, to characterize the performance of a stream processing workflow. In this study, we use these heuristics to identify bottlenecks (via fluidity) and data-intensive operations (via growth factor) in our workflows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fluidity (F):</head><p>We define F as the ratio between inbound and outbound data frequency of a transformation : → , where is the set of inbound streams, and is the set of outbound streams.</p><p>Here, each ∈ will have an expected outbound frequency , and a mean observed outbound frequency . Formally,</p><formula xml:id="formula_0">( , ) = 1 − 1 − ( / ) 2</formula><p>where ( , ) ∈ [0, 1], and ∈ [0, ]. For any outbound stream , is a constant. However, is affected by runtime parameters such as hardware, concurrency, parallelism, and scheduling, and therefore varies with time.</p><p>can be estimated by dividing the number of samples generated from by the time taken; however, adding a Kalman filter may improve the estimation of . Ideally, = which gives = 1. However, F decreases exponentially with , and reaches 0 as → 0. Heuristically, slow-performing transformations yield a low F, and can be improved through codelevel optimization and runtime/scheduling optimizations. Growth Factor (GF): We define GF as the ratio between inbound and outbound data volume of a transformation : → , where is the set of inbound streams, and is the set of outbound streams. Formally,</p><formula xml:id="formula_1">( , ) = ∈ ( ) ∈ ( ) , ( ) =</formula><p>where ( , ) ∈ [0, ∞), and ( ) ≥ 0. For any stream , the data volume ( ) is calculated using its frequency , and the "word size" of each channel in . Here, the word size represents the number of bits occupied by a sample of data from channel (e.g., a of type int32 has = 32). Furthermore, &lt; 1 indicates a data compression, &gt; 1 indicates a data expansion, and = 1 indicates no change. Heuristically, transformations with &lt; 1 are likely candidates for caching and transmitting over networks, as they generate less data than they receive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EVALUATION</head><p>Next, we evaluate StreamingHub through two case studies in the domains of eye movement analysis <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b8">9]</ref> and weather analysis <ref type="bibr" target="#b3">[4]</ref>. We select these particular domains to find whether StreamingHub generalizes across applications serving different scientific purposes. In both case studies, we evaluate three aspects of StreamingHub.</p><p>• Can we use DFS metadata to replay stored datasets? • Can we build workflows for domain-specific analysis tasks?</p><p>• Can we create domain-specific data visualizations?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Case Study 1: Eye Movement Analysis</head><p>4.1.1 Data Preparation. We use two datasets, ADHD-SIN <ref type="bibr" target="#b8">[9]</ref> and N-BACK <ref type="bibr" target="#b2">[3]</ref>, each providing gaze and pupillary measures of subjects during continuous performance tasks. We first pre-processed these datasets to provide normalized gaze positions (x,y) and pupil diameter (d) over time (t). Any missing values were filled via linear interpolation, backward-fill, and forward-fill, in order. In this experiment, we perform three tasks: 1) replay eye movement data, 2) obtain eye movement analytics in real-time, and 3) observe data/analytics through eye movement visualizations. Task 1: Replay: We first generate DFS metadata for the N-BACK and ADHD-SIN datasets. Then we implement a resolver (using Python) for each dataset, which maps queries into respective data files. Next, we use the DataMux API to accesses the file locations returned by each resolver and instantiate outlets for streaming. Task 2: Analytics: We create an eye movement analysis workflow on Node-RED, using visual programming. We begin by creating empty sub-flows for each transformation, and wiring them together, as shown in Figure <ref type="figure" target="#fig_3">2</ref>. Next, we implement these sub-flows to form the complete workflow. For instance, we implement the I-VT algorithm <ref type="bibr" target="#b12">[13]</ref> in the IVT sub-flow to classify data points as fixations or saccades. Task 3: Visualization: We implement an interactive 2D gaze plot using the Vega JSON specification <ref type="bibr" target="#b13">[14]</ref>. It visualizes gaze points as a scatter plot, connects consecutive gaze points using lines, and overlays a heat map to highlight the distribution of gaze points across the 2D space. It also provides a seek bar to explore gaze data at different points in time. The resulting operations dashboard shows the streams available for selection, the selected streams, and a real-time visualization of data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Case Study 2: Weather Analysis</head><p>4.2.1 Data Preparation. We use a weather dataset from Predic-tionGames <ref type="bibr" target="#b3">[4]</ref>, providing daily min/mean/max statistics of metrics such as temperature, dew point, humidity, and wind speed between 1950-01-01 and 2013-12-31 in 49 US-cities. We first pre-processed this dataset by splitting weather data into seperate files by their city, and ordering records by their date. In this experiment, we perform three tasks: 1) replay weather data from different cities, 2) calculate moving average analytics in real-time, and 3) observe data/analytics through chart-based visualizations. Task 1: Replay: We first create DFS metadata for the weather dataset. Here, we set the replay frequency as 1 Hz to speed up analysis (i.e., 1 day = 1 second). Then we implement a resolver (using Python) for this dataset, which maps queries into respective data files. Next, we use the DataMux API to access the file locations returned by the resolver and instantiate Task 2: Analytics: We create a workflow to perform moving average smoothing on weather data and visualize each metric as shown in Figure <ref type="figure" target="#fig_4">3</ref>. For the scope of this experiment, we only use the temperature, dew point, humidity, and wind speed metrics. outlets for streaming.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Heuristics</head><p>Here, we evaluate the consistency of our heuristics with two performance metrics: 1) latency and 2) data size. We pick four transformations from the case studies, and rank them in their increasing order of compute demand and outbound data size. Next, we send 100, 000 samples into each transformation at 50 , and compare our heuristics (fluidity , growth rate ) with the performance metrics (mean latency¯, inbound data size , outbound data size ) (see Table <ref type="table" target="#tab_1">2</ref>). Here,¯was higher for &lt; 1 than for = 1. Moreover, when ≪ , &lt; 1 and when ≫ , &gt; 1, with an exception in the threshold transformation. In explanation, the threshold transformation filters data below a certain threshold, and the outbound data size is thus data-dependent. Since does not capture this behavior, it may not be suited for operations such as these.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DISCUSSION</head><p>Since is based on observed frequency, it is not impacted by latency unless throughput is affected. Furthermore, varies with time, but is independent of time. Thus, can be used to pre-optimize the workflow execution on constrained resources. Moreover, both and can be applied at transformation-level to determine which outputs to cache or re-generate. However, a comprehensive evaluation is needed to validate their behavior across different applications.</p><p>StreamingHub currently relies on LabStreamingLayer for time synchronization. In the future, we plan to implement a time synchronization sub-flow in Node-RED, which would allow us to experiment with alternative communication methods like MQTT 7 and serialization methods like ProtoBuf 8 . Furthermore, we plan to conduct a user study to improve our design and identify new features. We also plan to support distributed workflow execution in StreamingHub by integrating workflow engines like Flink 9 or Kinesis <ref type="bibr" target="#b9">10</ref> . By doing so, we plan to compare StreamingHub with existing SWF systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>Using two eye-tracking datasets and a weather dataset, we demonstrated how metadata could be used to a) replay datasets as data streams, b) pass data streams into stream processing workflows, and c) perform data stream control and visualization for exploratory data analysis. We built two stream processing workflows using DFS, LabStreamingLayer, WebSockets, and Node-RED for two case studies: 1) eye movement analysis and 2) weather analysis. In the</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: A High-level Overview of StreamingHub</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Framework for FAIR Data Stream Processing</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Eye movement analysis SWF on Node-RED 4.1.2 Experiment Design.In this experiment, we perform three tasks: 1) replay eye movement data, 2) obtain eye movement analytics in real-time, and 3) observe data/analytics through eye movement visualizations. Task 1: Replay: We first generate DFS metadata for the N-BACK and ADHD-SIN datasets. Then we implement a resolver (using Python) for each dataset, which maps queries into respective data files. Next, we use the DataMux API to accesses the file locations returned by each resolver and instantiate outlets for streaming. Task 2: Analytics: We create an eye movement analysis workflow on Node-RED, using visual programming. We begin by creating</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Weather Analysis SWF on Node-RED 4.2.2 Experiment Design.In this experiment, we perform three tasks: 1) replay weather data from different cities, 2) calculate moving average analytics in real-time, and 3) observe data/analytics through chart-based visualizations. Task 1: Replay: We first create DFS metadata for the weather dataset. Here, we set the replay frequency as 1 Hz to speed up analysis (i.e., 1 day = 1 second). Then we implement a resolver (using Python) for this dataset, which maps queries into respective data files. Next, we use the DataMux API to access the file locations returned by the resolver and instantiate Task 2: Analytics: We create a workflow to perform moving average smoothing on weather data and visualize each metric as shown in Figure3. For the scope of this experiment, we only use the temperature, dew point, humidity, and wind speed metrics. outlets for streaming.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Operations Dashboard for Weather AnalysisTask 3: Visualization: Here, we accumulate and visualize the averaged weather data through interactive charts. Figure4shows a snapshot of the operations dashboard while visualizing replayed weather data. It shows the streams available for selection (left), the selected streams (rows), and a real-time visualization of data (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Figure  4shows a snapshot of the operations dashboard while visualizing replayed weather data. It shows the streams available for selection (left), the selected streams (rows), and a real-time visualization of data (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Summary of metadata attributes used in DFS</figDesc><table><row><cell></cell><cell>DATA SOURCE</cell></row><row><cell>info</cell><cell>version, timestamp, and checksum (for identification)</cell></row><row><cell>device</cell><cell>model, manufacturer, and category of data source</cell></row><row><cell>fields</cell><cell>dtype, name, and description of all fields</cell></row><row><cell>streams</cell><cell>information about all streams generated</cell></row><row><cell></cell><cell>DATA ANALYTIC</cell></row><row><cell>info</cell><cell>version, timestamp, and checksum (for identification)</cell></row><row><cell>sources</cell><cell>pointer(s) to the data source metadata</cell></row><row><cell>fields</cell><cell>pointer(s) to the fields used in analysis</cell></row><row><cell>inputs</cell><cell>pointer(s) to the streams used in analysis</cell></row><row><cell>streams</cell><cell>information about all streams generated via analysis</cell></row><row><cell></cell><cell>DATA SET</cell></row><row><cell>info</cell><cell>version, timestamp, and checksum (for identification)</cell></row><row><cell>name</cell><cell>name of the data set</cell></row></table><note>description description of the data set keywords keywords describing the data set (for indexing) authors name, affiliation, and email of data set authors sources pointer(s) to the data source metadata fields pointer(s) to the fields used in analysis groups spatial dimensions of data in the dataset resolver path to an executable invoked to resolve data files</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table><row><cell cols="8">Metrics (¯, , ) vs Heuristics ( , ) of transforma-</cell></row><row><cell cols="8">tions ( ) ranked by compute demand ( ) and outbound data</cell></row><row><cell cols="4">size ( )¯(</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>ms)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Mean</cell><cell>1</cell><cell>1</cell><cell>0.018</cell><cell cols="3">782 MB 15.64 MB 1.000</cell><cell>0.02</cell></row><row><cell>Threshold</cell><cell>2</cell><cell>2</cell><cell>0.097</cell><cell cols="4">782 MB 322.9 MB 0.999 1.00</cell></row><row><cell>Differentiate</cell><cell>3</cell><cell>4</cell><cell>0.243</cell><cell>782 MB</cell><cell>1.54 GB</cell><cell>0.934</cell><cell>2.00</cell></row><row><cell>Smooth</cell><cell>4</cell><cell>3</cell><cell>0.645</cell><cell cols="3">782 MB 781.9 MB 0.742</cell><cell>1.00</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">DFS Version 2.0 (https://github.com/nirdslab/streaminghub-dfs)</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">https://github.com/sccn/labstreaminglayer</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">https://mqtt.org/ 8 https://developers.google.com/protocol-buffers<ref type="bibr" target="#b8">9</ref> https://flink.apache.org/ 10 https://aws.amazon.com/kinesis/ eye movement analysis case study, we developed a workflow to identify fixations and visualize gaze data. In the weather analysis case study, we developed a workflow to visualize weather-related statistics, and replay data at different frequencies than recorded. Moreover, we showed that the proposed heuristics can be used to identify bottlenecks and data-intensive operations in workflows. To promote reuse, this work is publicly available on GitHub 11 .</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>This work was supported in part by NSF CAREER IIS-2045523. Any opinions, findings and conclusions or recommendations expressed in this material are the author(s) and do not necessarily reflect those of the sponsors.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Removing Science Workflow Barriers to Adoption of Digital Geologic Mapping by Using the GeoMapper Universal Program and Visual User Interface</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Brimhall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vanegas</surname></persName>
		</author>
		<idno>01-223</idno>
	</analytic>
	<monogr>
		<title level="m">Digital Mapping Techniques</title>
				<meeting><address><addrLine>Tuscaloosa, AL, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="103" to="115" />
		</imprint>
	</monogr>
	<note type="report_type">U.S. Geological Survey Open-File Report</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Visual programming</title>
		<author>
			<persName><forename type="first">M</forename><surname>Margaret</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">W</forename><surname>Burnett</surname></persName>
		</author>
		<author>
			<persName><surname>Mcintyre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">COMPUTER-LOS ALAMITOS</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="14" to="14" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The Low/High Index of Pupillary Activity</title>
		<author>
			<persName><forename type="first">Krzysztof</forename><surname>Andrew T Duchowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nina</forename><forename type="middle">A</forename><surname>Krejtz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tanya</forename><surname>Gehrer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Per</forename><surname>Bafna</surname></persName>
		</author>
		<author>
			<persName><surname>Baekgaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the 2020 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Keeping People Playing: The Effects of Domain News Presentation on Player Engagement in Educational Prediction Games</title>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Dzodom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akshay</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Catherine</forename><forename type="middle">C</forename><surname>Marshall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><forename type="middle">M</forename><surname>Shipman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st ACM Conference on Hypertext and Social Media</title>
				<meeting>the 31st ACM Conference on Hypertext and Social Media</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="47" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">2020. FAIR computational workflows</title>
		<author>
			<persName><forename type="first">Carole</forename><surname>Goble</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarah</forename><surname>Cohen-Boulakia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stian</forename><surname>Soiland-Reyes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Garijo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yolanda</forename><surname>Gil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristian</forename><surname>Michael R Crusoe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><surname>Schober</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Intelligence</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="108" to="121" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Dharmitha Ajerla, Farhana Zulkernine, and Shahzad Khan. 2019. A survey of distributed data stream processing frameworks</title>
		<author>
			<persName><forename type="first">Haruna</forename><surname>Isah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tariq</forename><surname>Abughofa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sazia</forename><surname>Mahfuz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="154300" to="154316" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">DFS: a dataset file system for data discovering users</title>
		<author>
			<persName><forename type="first">Yasith</forename><surname>Jayawardana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sampath</forename><surname>Jayarathna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 ACM/IEEE Joint Conference on Digital Libraries (JCDL)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="355" to="356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Streaming Analytics and Workflow Automation for DFS</title>
		<author>
			<persName><forename type="first">Yasith</forename><surname>Jayawardana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sampath</forename><surname>Jayarathna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM/IEEE Joint Conference on Digital Libraries in 2020</title>
				<meeting>the ACM/IEEE Joint Conference on Digital Libraries in 2020</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="513" to="514" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Pilot study of audiovisual speech-in-noise (sin) performance of young adults with adhd</title>
		<author>
			<persName><forename type="first">Gavindya</forename><surname>Jayawardena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anne</forename><surname>Michalek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Duchowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sampath</forename><surname>Jayarathna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Symposium on Eye Tracking Research and Applications</title>
				<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Visual analytics: Definition, process, and challenges</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Keim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gennady</forename><surname>Andrienko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-Daniel</forename><surname>Fekete</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carsten</forename><surname>Görg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jörn</forename><surname>Kohlhammer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guy</forename><surname>Melançon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information visualization</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="154" to="175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Scientific workflows: moving across paradigms</title>
		<author>
			<persName><surname>Chee Sun Liew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Malcolm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michelle</forename><surname>Atkinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tan</forename><surname>Galea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Fong Ang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jano I Van</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><surname>Hemert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="1" to="39" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Reproducible research in computational science</title>
		<author>
			<persName><forename type="first">D</forename><surname>Roger</surname></persName>
		</author>
		<author>
			<persName><surname>Peng</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.1213847</idno>
		<ptr target="https://doi.org/10.1126/science.1213847" />
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">334</biblScope>
			<biblScope unit="page" from="1226" to="1227" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Identifying fixations and saccades in eye-tracking protocols</title>
		<author>
			<persName><forename type="first">D</forename><surname>Dario</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph H</forename><surname>Salvucci</surname></persName>
		</author>
		<author>
			<persName><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2000 symposium on Eye tracking research &amp; applications</title>
				<meeting>the 2000 symposium on Eye tracking research &amp; applications</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="71" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Declarative Interaction Design for Data Visualization</title>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Satyanarayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kanit</forename><surname>Wongsuphasawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Heer</surname></persName>
		</author>
		<ptr target="http://idl.cs.washington.edu/papers/reactive-vega" />
	</analytic>
	<monogr>
		<title level="m">ACM User Interface Software &amp; Technology (UIST)</title>
				<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The FAIR Guiding Principles for scientific data management and stewardship</title>
		<author>
			<persName><forename type="first">Michel</forename><surname>Mark D Wilkinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">; -Willem</forename><surname>Dumontier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luiz</forename><surname>Boiten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silva</forename><surname>Bonino Da</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">E</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName><surname>Bourne</surname></persName>
		</author>
		<ptr target="https://github.com/nirdslab/streaminghub-conduit/" />
	</analytic>
	<monogr>
		<title level="m">IJsbrand Jan Aalbersberg, Gabrielle Appleton</title>
				<meeting><address><addrLine>Myles Axton, Arie Baak, Niklas Blomberg</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-01" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">160018</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
