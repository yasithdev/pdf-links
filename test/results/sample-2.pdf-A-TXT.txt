The Thirty-Third AAAI Conference on Artiﬁcial Intelligence (AAAI-19)

Long Short-Term Memory with Dynamic Skip Connections

Tao Gui, Qi Zhang, Lujun Zhao, Yaosong Lin, Minlong Peng, Jingjing Gong, Xuanjing Huang
Shanghai Key Laboratory of Intelligent Information Processing, Fudan University
School of Computer Science, Fudan University
Shanghai Insitute of Intelligent Electroics & Systems
825 Zhangheng Road, Shanghai, China
@fudan.edu.cn
tgui16, qz, ljzhao16, mlpeng16, yslin18, jjgong, xjhuang
}
{

Abstract

In recent years, long short-term memory (LSTM) has been
successfully used to model sequential data of variable length.
However, LSTM can still experience difﬁculty in capturing
long-term dependencies. In this work, we tried to allevi-
ate this problem by introducing a dynamic skip connection,
which can learn to directly connect two dependent words.
Since there is no dependency information in the training data,
we propose a novel reinforcement learning-based method to
model the dependency relationship and connect dependent
words. The proposed model computes the recurrent transi-
tion functions based on the skip connections, which pro-
vides a dynamic skipping advantage over RNNs that always
tackle entire sentences sequentially. Our experimental results
on three natural language processing tasks demonstrate that
the proposed method can achieve better performance than ex-
isting methods. In the number prediction experiment, the pro-
posed model outperformed LSTM with respect to accuracy
by nearly 20%.

Introduction
Recurrent neural networks (RNNs) have achieved signiﬁ-
cant success for many difﬁcult natural language processing
tasks, e.g., neural machine translation (Sutskever, Vinyals,
and Le 2014), conversational/dialogue modeling (Serban et
al. 2016), document summarization (Nallapati et al. 2016),
sequence tagging (Santos and Zadrozny 2014), and docu-
ment classiﬁcation (Dai and Le 2015). Because of the need
to model long sentences, an important challenge encoun-
tered by all these models is the difﬁculty of capturing long-
term dependencies. In addition, training RNNs using the
“Back-Propagation Through Time” (BPTT) method is vul-
nerable to vanishing and exploding gradients.

To tackle the above challenges, several variations of
RNNs have been proposed using new RNN transition func-
tional units and optimization techniques, such as gated re-
current unit (GRU) (Chung et al. 2014) and long short-term
memory (LSTM) (Hochreiter and Schmidhuber 1997). Re-
cently, many of the existing methods have focused on the
connection architecture, including “stacked RNNs” (El Hihi
and Bengio 1996) and “skip RNNs” (Chang et al. 2017).
Zhang et al. (2016) introduced a general formulation

Copyright c(cid:13) 2019, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.

Figure 1: Examples of dependencies with variable length in
the language. The same phrase “depend on” in different sen-
tences would have dependencies with different lengths. The
use of clauses also makes the dependency length uncertain.
Therefore, the models using a plain LSTM or an LSTM with
ﬁxed skip connections would be difﬁcult to capture such in-
formation.

for RNN architectures and proposed three architectural
complexity measures: recurrent skip coefﬁcients, recurrent
depth, and feedforward depth. In addition, the skip coefﬁ-
cient is deﬁned as a function of the “shortest path” from one
time to another. In particular, they found empirical evidence
that increasing the feedforward depth might not help with
long-term dependency tasks, while increasing the recurrent
skip coefﬁcient could signiﬁcantly improve the performance
on long-term dependency tasks.

However,

these works on recurrent skip coefﬁcients
adopted ﬁxed skip lengths (Zhang et al. 2016; Chang et al.
2017). Although quite powerful given their simplicity, the
ﬁxed skip length is constrained by its inability to take ad-
vantage of the dependencies with variable lengths in the
language, as shown in Figure 1. From this ﬁgure, we can
see that the same phrase “depend on” in different sentences
would have dependencies with different lengths. The use of
clauses also makes the dependency length uncertain. In addi-
tion, the meaning of a sentence is often determined by words
that are not very close. For example, consider the sentence
“The man who wore a Stetson on his head went inside.” This
sentence is really about a man going inside, not about the
Stetson. Hence, the models using a plain LSTM or an LSTM
with a ﬁxed skip would be difﬁcult to capture such infor-
mation and insufﬁcient to fully capture the semantics of the
natural language.

6481

The exact amounts spent depend to some extent on appropriations legislation.You may depend on the accuracy of the report.The man who wore a Stetson on his head went inside.Figure 2: Architecture of the proposed model. At time step t, the agent selects one of the past few states based on the current
input xt and the previous hidden state ht
1. The agent’s selections will inﬂuence the log-likelihood of the ground truth, which
will be a reward or penalty to optimize the agent. Take the phrase “depend to some extent on” as an example, the agent should
learn to select the hidden state from “depend” not “extend” to predict “on,” because selecting “depend” receives a larger reward.

−

To overcome this limitation, in this paper, we consider the
sequence modeling problem with dynamic skip connections.
The proposed model allows “LSTM cells” to compute recur-
rent transition functions based on one optimal set of hidden
and cell states from the past few states. However, in gen-
eral, we do not have the labels to guide which two words
should be connected. To overcome this problem, we pro-
pose the use of reinforcement learning to learn the depen-
dent relationship through the exploring process. The main
beneﬁt of this approach is the better modeling of depen-
dencies with variable length in the language. In addition,
this approach also mitigates vanishing and exploding gradi-
ent problems with a shorter gradient backpropagation path.
Through experiments, We ﬁnd the empirical evidences (see
Experiments and Appendix1) that our model is better than
that using attention mechanism to connect two words, as re-
ported in (Deng et al. 2018). Experimental results also show
that the proposed method can achieve competitive perfor-
mance on a series of sequence modeling tasks.

The main contributions of this paper can be summarized
as follows: 1) we study the sequence modeling problem in-
corporating dynamic skip connections, which can effectively
tackle the long-term dependency problems; 2) we propose a
novel reinforcement learning-based LSTM model to achieve
the task, and the proposed model can learn to choose one op-
timal set of hidden and cell states from the past few states;
and 3) several experimental results are given to demonstrate
the effectiveness of the proposed method from different as-
pects.

Approach
In this work, we propose a novel LSTM network, which is a
modiﬁcation to the basic LSTM architectures. By using dy-
namic skip connections, the proposed model can choose an
optimal set of hidden and cell states to compute recurrent
transition functions. For the sake of brevity, we use State to
represent both the hidden state and cell state. Because of the
non-differentiability of discrete selection, we adopted rein-
forcement learning to achieve the task.

1Please refer to https://arxiv.org/abs/1811.03873

(cid:55)→

(cid:55)→

some

Model Overview
Taking language modeling as an example, given an in-
put sequence x1:T with length T , at each time step t,
the model takes a word embedding xt as input, and aims
to output a distribution over the next word, which is de-
noted by yt. However, in the example shown in Figure 2,
in standard RNN settings, memorizing long-term depen-
on) while maintaining short-term mem-
dency (depend ...
(cid:55)→
ory (to
extent) is difﬁcult (Chang et al. 2017).
Hence, we developed a skipping technique that learns to
3 to predict
choose the most relevant State at time step t
the word “on” to tackle the long-term dependency problem.
The architecture of the proposed model is shown in Fig-
ure 2. At time step t, the agent takes previous hidden state
1 as input, and then computes the skip softmax that deter-
ht
mines a distribution over the skip steps between 1 and K. In
our setting, the maximum size of skip K is chosen ahead of
time. The agent thereby samples from this distribution to de-
cide which State is transferred to a standard LSTM cell for
recurrent transition computation. Then, the standard LSTM
cell will encode the newly selected State and xt to the hid-
den state ht. At the end of each time step, each hidden state
ht is further used for predicting the next word based on the
same method as standard RNNs. Especially, such a model
can be fully applied to any sequence modeling problem. In
the following, we will detail the architecture and the training
method of the proposed model.

−

−

Dynamic Skip with REINFORCE
The proposed model consists of two components: (1) a pol-
icy gradient agent that repeatedly selects the optimal State
from the historical State set, and (2) a standard LSTM
cell (Hochreiter and Schmidhuber 1997) using a newly se-
lected State to achieve a task. Our goal for training is to
optimize the parameters of the policy gradient agent θa, to-
gether with the parameters of standard LSTM and possibly
other parameters including word embeddings denoted as θl.
The core of the proposed model is a policy gradient agent.
Sequential words x1:T with length T correspond to the se-
quential inputs of one episode. At each time step t, the
agent interacts with the environment st to decide an action

6482

K=1K=2K=kLSTMLSTMLSTMLSTMAgentAgentAgenth1<latexit sha1_base64="9d9AtoY1+JMq1YbLJyyi5JMUeJg=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEqN4KXjxWMG2hDWWznbRLN5uwuxFK6G/w4kERr/4gb/4bt20O2vpg4PHeDDPzwlRwbVz32yltbG5t75R3K3v7B4dH1eOTtk4yxdBniUhUN6QaBZfoG24EdlOFNA4FdsLJ3dzvPKHSPJGPZppiENOR5BFn1FjJHw9ybzao1ty6uwBZJ15BalCgNah+9YcJy2KUhgmqdc9zUxPkVBnOBM4q/UxjStmEjrBnqaQx6iBfHDsjF1YZkihRtqQhC/X3RE5jradxaDtjasZ61ZuL/3m9zEQ3Qc5lmhmUbLkoygQxCZl/ToZcITNiagllittbCRtTRZmx+VRsCN7qy+ukfVX33Lr3cF1r3hZxlOEMzuESPGhAE+6hBT4w4PAMr/DmSOfFeXc+lq0lp5g5hT9wPn8AtRGOkw==</latexit><latexit sha1_base64="9d9AtoY1+JMq1YbLJyyi5JMUeJg=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEqN4KXjxWMG2hDWWznbRLN5uwuxFK6G/w4kERr/4gb/4bt20O2vpg4PHeDDPzwlRwbVz32yltbG5t75R3K3v7B4dH1eOTtk4yxdBniUhUN6QaBZfoG24EdlOFNA4FdsLJ3dzvPKHSPJGPZppiENOR5BFn1FjJHw9ybzao1ty6uwBZJ15BalCgNah+9YcJy2KUhgmqdc9zUxPkVBnOBM4q/UxjStmEjrBnqaQx6iBfHDsjF1YZkihRtqQhC/X3RE5jradxaDtjasZ61ZuL/3m9zEQ3Qc5lmhmUbLkoygQxCZl/ToZcITNiagllittbCRtTRZmx+VRsCN7qy+ukfVX33Lr3cF1r3hZxlOEMzuESPGhAE+6hBT4w4PAMr/DmSOfFeXc+lq0lp5g5hT9wPn8AtRGOkw==</latexit><latexit sha1_base64="9d9AtoY1+JMq1YbLJyyi5JMUeJg=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEqN4KXjxWMG2hDWWznbRLN5uwuxFK6G/w4kERr/4gb/4bt20O2vpg4PHeDDPzwlRwbVz32yltbG5t75R3K3v7B4dH1eOTtk4yxdBniUhUN6QaBZfoG24EdlOFNA4FdsLJ3dzvPKHSPJGPZppiENOR5BFn1FjJHw9ybzao1ty6uwBZJ15BalCgNah+9YcJy2KUhgmqdc9zUxPkVBnOBM4q/UxjStmEjrBnqaQx6iBfHDsjF1YZkihRtqQhC/X3RE5jradxaDtjasZ61ZuL/3m9zEQ3Qc5lmhmUbLkoygQxCZl/ToZcITNiagllittbCRtTRZmx+VRsCN7qy+ukfVX33Lr3cF1r3hZxlOEMzuESPGhAE+6hBT4w4PAMr/DmSOfFeXc+lq0lp5g5hT9wPn8AtRGOkw==</latexit><latexit sha1_base64="9d9AtoY1+JMq1YbLJyyi5JMUeJg=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEqN4KXjxWMG2hDWWznbRLN5uwuxFK6G/w4kERr/4gb/4bt20O2vpg4PHeDDPzwlRwbVz32yltbG5t75R3K3v7B4dH1eOTtk4yxdBniUhUN6QaBZfoG24EdlOFNA4FdsLJ3dzvPKHSPJGPZppiENOR5BFn1FjJHw9ybzao1ty6uwBZJ15BalCgNah+9YcJy2KUhgmqdc9zUxPkVBnOBM4q/UxjStmEjrBnqaQx6iBfHDsjF1YZkihRtqQhC/X3RE5jradxaDtjasZ61ZuL/3m9zEQ3Qc5lmhmUbLkoygQxCZl/ToZcITNiagllittbCRtTRZmx+VRsCN7qy+ukfVX33Lr3cF1r3hZxlOEMzuESPGhAE+6hBT4w4PAMr/DmSOfFeXc+lq0lp5g5hT9wPn8AtRGOkw==</latexit>h0<latexit sha1_base64="X16T19p8Viasqsmv80z1rcdyigY=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEqN4KXjxWMG2hDWWznbRLN5uwuxFK6G/w4kERr/4gb/4bt20O2vpg4PHeDDPzwlRwbVz32yltbG5t75R3K3v7B4dH1eOTtk4yxdBniUhUN6QaBZfoG24EdlOFNA4FdsLJ3dzvPKHSPJGPZppiENOR5BFn1FjJHw9ydzao1ty6uwBZJ15BalCgNah+9YcJy2KUhgmqdc9zUxPkVBnOBM4q/UxjStmEjrBnqaQx6iBfHDsjF1YZkihRtqQhC/X3RE5jradxaDtjasZ61ZuL/3m9zEQ3Qc5lmhmUbLkoygQxCZl/ToZcITNiagllittbCRtTRZmx+VRsCN7qy+ukfVX33Lr3cF1r3hZxlOEMzuESPGhAE+6hBT4w4PAMr/DmSOfFeXc+lq0lp5g5hT9wPn8As4yOkg==</latexit><latexit sha1_base64="X16T19p8Viasqsmv80z1rcdyigY=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEqN4KXjxWMG2hDWWznbRLN5uwuxFK6G/w4kERr/4gb/4bt20O2vpg4PHeDDPzwlRwbVz32yltbG5t75R3K3v7B4dH1eOTtk4yxdBniUhUN6QaBZfoG24EdlOFNA4FdsLJ3dzvPKHSPJGPZppiENOR5BFn1FjJHw9ydzao1ty6uwBZJ15BalCgNah+9YcJy2KUhgmqdc9zUxPkVBnOBM4q/UxjStmEjrBnqaQx6iBfHDsjF1YZkihRtqQhC/X3RE5jradxaDtjasZ61ZuL/3m9zEQ3Qc5lmhmUbLkoygQxCZl/ToZcITNiagllittbCRtTRZmx+VRsCN7qy+ukfVX33Lr3cF1r3hZxlOEMzuESPGhAE+6hBT4w4PAMr/DmSOfFeXc+lq0lp5g5hT9wPn8As4yOkg==</latexit><latexit sha1_base64="X16T19p8Viasqsmv80z1rcdyigY=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEqN4KXjxWMG2hDWWznbRLN5uwuxFK6G/w4kERr/4gb/4bt20O2vpg4PHeDDPzwlRwbVz32yltbG5t75R3K3v7B4dH1eOTtk4yxdBniUhUN6QaBZfoG24EdlOFNA4FdsLJ3dzvPKHSPJGPZppiENOR5BFn1FjJHw9ydzao1ty6uwBZJ15BalCgNah+9YcJy2KUhgmqdc9zUxPkVBnOBM4q/UxjStmEjrBnqaQx6iBfHDsjF1YZkihRtqQhC/X3RE5jradxaDtjasZ61ZuL/3m9zEQ3Qc5lmhmUbLkoygQxCZl/ToZcITNiagllittbCRtTRZmx+VRsCN7qy+ukfVX33Lr3cF1r3hZxlOEMzuESPGhAE+6hBT4w4PAMr/DmSOfFeXc+lq0lp5g5hT9wPn8As4yOkg==</latexit><latexit sha1_base64="X16T19p8Viasqsmv80z1rcdyigY=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEqN4KXjxWMG2hDWWznbRLN5uwuxFK6G/w4kERr/4gb/4bt20O2vpg4PHeDDPzwlRwbVz32yltbG5t75R3K3v7B4dH1eOTtk4yxdBniUhUN6QaBZfoG24EdlOFNA4FdsLJ3dzvPKHSPJGPZppiENOR5BFn1FjJHw9ydzao1ty6uwBZJ15BalCgNah+9YcJy2KUhgmqdc9zUxPkVBnOBM4q/UxjStmEjrBnqaQx6iBfHDsjF1YZkihRtqQhC/X3RE5jradxaDtjasZ61ZuL/3m9zEQ3Qc5lmhmUbLkoygQxCZl/ToZcITNiagllittbCRtTRZmx+VRsCN7qy+ukfVX33Lr3cF1r3hZxlOEMzuESPGhAE+6hBT4w4PAMr/DmSOfFeXc+lq0lp5g5hT9wPn8As4yOkg==</latexit>h2<latexit sha1_base64="uubW29OB2YVvfx9J0KHde9IHi6Y=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoN4KXjxWMG2hDWWz3bRLN5uwOxFK6G/w4kERr/4gb/4bt20O2vpg4PHeDDPzwlQKg6777ZQ2Nre2d8q7lb39g8Oj6vFJ2ySZZtxniUx0N6SGS6G4jwIl76aa0ziUvBNO7uZ+54lrIxL1iNOUBzEdKREJRtFK/niQN2aDas2tuwuQdeIVpAYFWoPqV3+YsCzmCpmkxvQ8N8UgpxoFk3xW6WeGp5RN6Ij3LFU05ibIF8fOyIVVhiRKtC2FZKH+nshpbMw0Dm1nTHFsVr25+J/XyzC6CXKh0gy5YstFUSYJJmT+ORkKzRnKqSWUaWFvJWxMNWVo86nYELzVl9dJu1H33Lr3cFVr3hZxlOEMzuESPLiGJtxDC3xgIOAZXuHNUc6L8+58LFtLTjFzCn/gfP4AtpaOlA==</latexit><latexit sha1_base64="uubW29OB2YVvfx9J0KHde9IHi6Y=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoN4KXjxWMG2hDWWz3bRLN5uwOxFK6G/w4kERr/4gb/4bt20O2vpg4PHeDDPzwlQKg6777ZQ2Nre2d8q7lb39g8Oj6vFJ2ySZZtxniUx0N6SGS6G4jwIl76aa0ziUvBNO7uZ+54lrIxL1iNOUBzEdKREJRtFK/niQN2aDas2tuwuQdeIVpAYFWoPqV3+YsCzmCpmkxvQ8N8UgpxoFk3xW6WeGp5RN6Ij3LFU05ibIF8fOyIVVhiRKtC2FZKH+nshpbMw0Dm1nTHFsVr25+J/XyzC6CXKh0gy5YstFUSYJJmT+ORkKzRnKqSWUaWFvJWxMNWVo86nYELzVl9dJu1H33Lr3cFVr3hZxlOEMzuESPLiGJtxDC3xgIOAZXuHNUc6L8+58LFtLTjFzCn/gfP4AtpaOlA==</latexit><latexit sha1_base64="uubW29OB2YVvfx9J0KHde9IHi6Y=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoN4KXjxWMG2hDWWz3bRLN5uwOxFK6G/w4kERr/4gb/4bt20O2vpg4PHeDDPzwlQKg6777ZQ2Nre2d8q7lb39g8Oj6vFJ2ySZZtxniUx0N6SGS6G4jwIl76aa0ziUvBNO7uZ+54lrIxL1iNOUBzEdKREJRtFK/niQN2aDas2tuwuQdeIVpAYFWoPqV3+YsCzmCpmkxvQ8N8UgpxoFk3xW6WeGp5RN6Ij3LFU05ibIF8fOyIVVhiRKtC2FZKH+nshpbMw0Dm1nTHFsVr25+J/XyzC6CXKh0gy5YstFUSYJJmT+ORkKzRnKqSWUaWFvJWxMNWVo86nYELzVl9dJu1H33Lr3cFVr3hZxlOEMzuESPLiGJtxDC3xgIOAZXuHNUc6L8+58LFtLTjFzCn/gfP4AtpaOlA==</latexit><latexit sha1_base64="uubW29OB2YVvfx9J0KHde9IHi6Y=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoN4KXjxWMG2hDWWz3bRLN5uwOxFK6G/w4kERr/4gb/4bt20O2vpg4PHeDDPzwlQKg6777ZQ2Nre2d8q7lb39g8Oj6vFJ2ySZZtxniUx0N6SGS6G4jwIl76aa0ziUvBNO7uZ+54lrIxL1iNOUBzEdKREJRtFK/niQN2aDas2tuwuQdeIVpAYFWoPqV3+YsCzmCpmkxvQ8N8UgpxoFk3xW6WeGp5RN6Ij3LFU05ibIF8fOyIVVhiRKtC2FZKH+nshpbMw0Dm1nTHFsVr25+J/XyzC6CXKh0gy5YstFUSYJJmT+ORkKzRnKqSWUaWFvJWxMNWVo86nYELzVl9dJu1H33Lr3cFVr3hZxlOEMzuESPLiGJtxDC3xgIOAZXuHNUc6L8+58LFtLTjFzCn/gfP4AtpaOlA==</latexit>y2<latexit sha1_base64="HrE5VO+SmgHMHdj5qNUNFxIp46s=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoN4KXjxWMG2hDWWz3bRLN5uwOxFK6G/w4kERr/4gb/4bt20O2vpg4PHeDDPzwlQKg6777ZQ2Nre2d8q7lb39g8Oj6vFJ2ySZZtxniUx0N6SGS6G4jwIl76aa0ziUvBNO7uZ+54lrIxL1iNOUBzEdKREJRtFK/nSQN2aDas2tuwuQdeIVpAYFWoPqV3+YsCzmCpmkxvQ8N8UgpxoFk3xW6WeGp5RN6Ij3LFU05ibIF8fOyIVVhiRKtC2FZKH+nshpbMw0Dm1nTHFsVr25+J/XyzC6CXKh0gy5YstFUSYJJmT+ORkKzRnKqSWUaWFvJWxMNWVo86nYELzVl9dJu1H33Lr3cFVr3hZxlOEMzuESPLiGJtxDC3xgIOAZXuHNUc6L8+58LFtLTjFzCn/gfP4A0J6OpQ==</latexit><latexit sha1_base64="HrE5VO+SmgHMHdj5qNUNFxIp46s=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoN4KXjxWMG2hDWWz3bRLN5uwOxFK6G/w4kERr/4gb/4bt20O2vpg4PHeDDPzwlQKg6777ZQ2Nre2d8q7lb39g8Oj6vFJ2ySZZtxniUx0N6SGS6G4jwIl76aa0ziUvBNO7uZ+54lrIxL1iNOUBzEdKREJRtFK/nSQN2aDas2tuwuQdeIVpAYFWoPqV3+YsCzmCpmkxvQ8N8UgpxoFk3xW6WeGp5RN6Ij3LFU05ibIF8fOyIVVhiRKtC2FZKH+nshpbMw0Dm1nTHFsVr25+J/XyzC6CXKh0gy5YstFUSYJJmT+ORkKzRnKqSWUaWFvJWxMNWVo86nYELzVl9dJu1H33Lr3cFVr3hZxlOEMzuESPLiGJtxDC3xgIOAZXuHNUc6L8+58LFtLTjFzCn/gfP4A0J6OpQ==</latexit><latexit sha1_base64="HrE5VO+SmgHMHdj5qNUNFxIp46s=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoN4KXjxWMG2hDWWz3bRLN5uwOxFK6G/w4kERr/4gb/4bt20O2vpg4PHeDDPzwlQKg6777ZQ2Nre2d8q7lb39g8Oj6vFJ2ySZZtxniUx0N6SGS6G4jwIl76aa0ziUvBNO7uZ+54lrIxL1iNOUBzEdKREJRtFK/nSQN2aDas2tuwuQdeIVpAYFWoPqV3+YsCzmCpmkxvQ8N8UgpxoFk3xW6WeGp5RN6Ij3LFU05ibIF8fOyIVVhiRKtC2FZKH+nshpbMw0Dm1nTHFsVr25+J/XyzC6CXKh0gy5YstFUSYJJmT+ORkKzRnKqSWUaWFvJWxMNWVo86nYELzVl9dJu1H33Lr3cFVr3hZxlOEMzuESPLiGJtxDC3xgIOAZXuHNUc6L8+58LFtLTjFzCn/gfP4A0J6OpQ==</latexit><latexit sha1_base64="HrE5VO+SmgHMHdj5qNUNFxIp46s=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoN4KXjxWMG2hDWWz3bRLN5uwOxFK6G/w4kERr/4gb/4bt20O2vpg4PHeDDPzwlQKg6777ZQ2Nre2d8q7lb39g8Oj6vFJ2ySZZtxniUx0N6SGS6G4jwIl76aa0ziUvBNO7uZ+54lrIxL1iNOUBzEdKREJRtFK/nSQN2aDas2tuwuQdeIVpAYFWoPqV3+YsCzmCpmkxvQ8N8UgpxoFk3xW6WeGp5RN6Ij3LFU05ibIF8fOyIVVhiRKtC2FZKH+nshpbMw0Dm1nTHFsVr25+J/XyzC6CXKh0gy5YstFUSYJJmT+ORkKzRnKqSWUaWFvJWxMNWVo86nYELzVl9dJu1H33Lr3cFVr3hZxlOEMzuESPLiGJtxDC3xgIOAZXuHNUc6L8+58LFtLTjFzCn/gfP4A0J6OpQ==</latexit>y1<latexit sha1_base64="7vhfex+qjf/rjdzznPZYm/LBAQQ=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEUG8FLx4rmFpoQ9lsN+3SzSbsToQQ+hu8eFDEqz/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O5W19Y3Nrep2bWd3b/+gfnjUMUmmGfdZIhPdDanhUijuo0DJu6nmNA4lfwwntzP/8YlrIxL1gHnKg5iOlIgEo2glPx8U3nRQb7hNdw6ySrySNKBEe1D/6g8TlsVcIZPUmJ7nphgUVKNgkk9r/czwlLIJHfGepYrG3ATF/NgpObPKkESJtqWQzNXfEwWNjcnj0HbGFMdm2ZuJ/3m9DKProBAqzZArtlgUZZJgQmafk6HQnKHMLaFMC3srYWOqKUObT82G4C2/vEo6F03PbXr3l43WTRlHFU7gFM7BgytowR20wQcGAp7hFd4c5bw4787HorXilDPH8AfO5w/PGY6k</latexit><latexit sha1_base64="7vhfex+qjf/rjdzznPZYm/LBAQQ=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEUG8FLx4rmFpoQ9lsN+3SzSbsToQQ+hu8eFDEqz/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O5W19Y3Nrep2bWd3b/+gfnjUMUmmGfdZIhPdDanhUijuo0DJu6nmNA4lfwwntzP/8YlrIxL1gHnKg5iOlIgEo2glPx8U3nRQb7hNdw6ySrySNKBEe1D/6g8TlsVcIZPUmJ7nphgUVKNgkk9r/czwlLIJHfGepYrG3ATF/NgpObPKkESJtqWQzNXfEwWNjcnj0HbGFMdm2ZuJ/3m9DKProBAqzZArtlgUZZJgQmafk6HQnKHMLaFMC3srYWOqKUObT82G4C2/vEo6F03PbXr3l43WTRlHFU7gFM7BgytowR20wQcGAp7hFd4c5bw4787HorXilDPH8AfO5w/PGY6k</latexit><latexit sha1_base64="7vhfex+qjf/rjdzznPZYm/LBAQQ=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEUG8FLx4rmFpoQ9lsN+3SzSbsToQQ+hu8eFDEqz/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O5W19Y3Nrep2bWd3b/+gfnjUMUmmGfdZIhPdDanhUijuo0DJu6nmNA4lfwwntzP/8YlrIxL1gHnKg5iOlIgEo2glPx8U3nRQb7hNdw6ySrySNKBEe1D/6g8TlsVcIZPUmJ7nphgUVKNgkk9r/czwlLIJHfGepYrG3ATF/NgpObPKkESJtqWQzNXfEwWNjcnj0HbGFMdm2ZuJ/3m9DKProBAqzZArtlgUZZJgQmafk6HQnKHMLaFMC3srYWOqKUObT82G4C2/vEo6F03PbXr3l43WTRlHFU7gFM7BgytowR20wQcGAp7hFd4c5bw4787HorXilDPH8AfO5w/PGY6k</latexit><latexit sha1_base64="7vhfex+qjf/rjdzznPZYm/LBAQQ=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEUG8FLx4rmFpoQ9lsN+3SzSbsToQQ+hu8eFDEqz/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O5W19Y3Nrep2bWd3b/+gfnjUMUmmGfdZIhPdDanhUijuo0DJu6nmNA4lfwwntzP/8YlrIxL1gHnKg5iOlIgEo2glPx8U3nRQb7hNdw6ySrySNKBEe1D/6g8TlsVcIZPUmJ7nphgUVKNgkk9r/czwlLIJHfGepYrG3ATF/NgpObPKkESJtqWQzNXfEwWNjcnj0HbGFMdm2ZuJ/3m9DKProBAqzZArtlgUZZJgQmafk6HQnKHMLaFMC3srYWOqKUObT82G4C2/vEo6F03PbXr3l43WTRlHFU7gFM7BgytowR20wQcGAp7hFd4c5bw4787HorXilDPH8AfO5w/PGY6k</latexit>y0<latexit sha1_base64="pT+SB/JYt4zONwRg7WouQYd8G98=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEUG8FLx4rmFpoQ9lsN+3SzSbsToQQ+hu8eFDEqz/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O5W19Y3Nrep2bWd3b/+gfnjUMUmmGfdZIhPdDanhUijuo0DJu6nmNA4lfwwntzP/8YlrIxL1gHnKg5iOlIgEo2glPx8U7nRQb7hNdw6ySrySNKBEe1D/6g8TlsVcIZPUmJ7nphgUVKNgkk9r/czwlLIJHfGepYrG3ATF/NgpObPKkESJtqWQzNXfEwWNjcnj0HbGFMdm2ZuJ/3m9DKProBAqzZArtlgUZZJgQmafk6HQnKHMLaFMC3srYWOqKUObT82G4C2/vEo6F03PbXr3l43WTRlHFU7gFM7BgytowR20wQcGAp7hFd4c5bw4787HorXilDPH8AfO5w/NlI6j</latexit><latexit sha1_base64="pT+SB/JYt4zONwRg7WouQYd8G98=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEUG8FLx4rmFpoQ9lsN+3SzSbsToQQ+hu8eFDEqz/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O5W19Y3Nrep2bWd3b/+gfnjUMUmmGfdZIhPdDanhUijuo0DJu6nmNA4lfwwntzP/8YlrIxL1gHnKg5iOlIgEo2glPx8U7nRQb7hNdw6ySrySNKBEe1D/6g8TlsVcIZPUmJ7nphgUVKNgkk9r/czwlLIJHfGepYrG3ATF/NgpObPKkESJtqWQzNXfEwWNjcnj0HbGFMdm2ZuJ/3m9DKProBAqzZArtlgUZZJgQmafk6HQnKHMLaFMC3srYWOqKUObT82G4C2/vEo6F03PbXr3l43WTRlHFU7gFM7BgytowR20wQcGAp7hFd4c5bw4787HorXilDPH8AfO5w/NlI6j</latexit><latexit sha1_base64="pT+SB/JYt4zONwRg7WouQYd8G98=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEUG8FLx4rmFpoQ9lsN+3SzSbsToQQ+hu8eFDEqz/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O5W19Y3Nrep2bWd3b/+gfnjUMUmmGfdZIhPdDanhUijuo0DJu6nmNA4lfwwntzP/8YlrIxL1gHnKg5iOlIgEo2glPx8U7nRQb7hNdw6ySrySNKBEe1D/6g8TlsVcIZPUmJ7nphgUVKNgkk9r/czwlLIJHfGepYrG3ATF/NgpObPKkESJtqWQzNXfEwWNjcnj0HbGFMdm2ZuJ/3m9DKProBAqzZArtlgUZZJgQmafk6HQnKHMLaFMC3srYWOqKUObT82G4C2/vEo6F03PbXr3l43WTRlHFU7gFM7BgytowR20wQcGAp7hFd4c5bw4787HorXilDPH8AfO5w/NlI6j</latexit><latexit sha1_base64="pT+SB/JYt4zONwRg7WouQYd8G98=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEUG8FLx4rmFpoQ9lsN+3SzSbsToQQ+hu8eFDEqz/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O5W19Y3Nrep2bWd3b/+gfnjUMUmmGfdZIhPdDanhUijuo0DJu6nmNA4lfwwntzP/8YlrIxL1gHnKg5iOlIgEo2glPx8U7nRQb7hNdw6ySrySNKBEe1D/6g8TlsVcIZPUmJ7nphgUVKNgkk9r/czwlLIJHfGepYrG3ATF/NgpObPKkESJtqWQzNXfEwWNjcnj0HbGFMdm2ZuJ/3m9DKProBAqzZArtlgUZZJgQmafk6HQnKHMLaFMC3srYWOqKUObT82G4C2/vEo6F03PbXr3l43WTRlHFU7gFM7BgytowR20wQcGAp7hFd4c5bw4787HorXilDPH8AfO5w/NlI6j</latexit>x0<latexit sha1_base64="9gMEVXI5nPy8/zVrqdImqNvyYh4=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEUG8FLx4rmLbQhrLZTtqlm03Y3Ygl9Dd48aCIV3+QN/+N2zYHbX0w8Hhvhpl5YSq4Nq777ZTW1jc2t8rblZ3dvf2D6uFRSyeZYuizRCSqE1KNgkv0DTcCO6lCGocC2+H4dua3H1FpnsgHM0kxiOlQ8ogzaqzkP/Vzd9qv1ty6OwdZJV5BalCg2a9+9QYJy2KUhgmqdddzUxPkVBnOBE4rvUxjStmYDrFrqaQx6iCfHzslZ1YZkChRtqQhc/X3RE5jrSdxaDtjakZ62ZuJ/3ndzETXQc5lmhmUbLEoygQxCZl9TgZcITNiYgllittbCRtRRZmx+VRsCN7yy6ukdVH33Lp3f1lr3BRxlOEETuEcPLiCBtxBE3xgwOEZXuHNkc6L8+58LFpLTjFzDH/gfP4AzAyOog==</latexit><latexit sha1_base64="9gMEVXI5nPy8/zVrqdImqNvyYh4=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEUG8FLx4rmLbQhrLZTtqlm03Y3Ygl9Dd48aCIV3+QN/+N2zYHbX0w8Hhvhpl5YSq4Nq777ZTW1jc2t8rblZ3dvf2D6uFRSyeZYuizRCSqE1KNgkv0DTcCO6lCGocC2+H4dua3H1FpnsgHM0kxiOlQ8ogzaqzkP/Vzd9qv1ty6OwdZJV5BalCg2a9+9QYJy2KUhgmqdddzUxPkVBnOBE4rvUxjStmYDrFrqaQx6iCfHzslZ1YZkChRtqQhc/X3RE5jrSdxaDtjakZ62ZuJ/3ndzETXQc5lmhmUbLEoygQxCZl9TgZcITNiYgllittbCRtRRZmx+VRsCN7yy6ukdVH33Lp3f1lr3BRxlOEETuEcPLiCBtxBE3xgwOEZXuHNkc6L8+58LFpLTjFzDH/gfP4AzAyOog==</latexit><latexit sha1_base64="9gMEVXI5nPy8/zVrqdImqNvyYh4=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEUG8FLx4rmLbQhrLZTtqlm03Y3Ygl9Dd48aCIV3+QN/+N2zYHbX0w8Hhvhpl5YSq4Nq777ZTW1jc2t8rblZ3dvf2D6uFRSyeZYuizRCSqE1KNgkv0DTcCO6lCGocC2+H4dua3H1FpnsgHM0kxiOlQ8ogzaqzkP/Vzd9qv1ty6OwdZJV5BalCg2a9+9QYJy2KUhgmqdddzUxPkVBnOBE4rvUxjStmYDrFrqaQx6iCfHzslZ1YZkChRtqQhc/X3RE5jrSdxaDtjakZ62ZuJ/3ndzETXQc5lmhmUbLEoygQxCZl9TgZcITNiYgllittbCRtRRZmx+VRsCN7yy6ukdVH33Lp3f1lr3BRxlOEETuEcPLiCBtxBE3xgwOEZXuHNkc6L8+58LFpLTjFzDH/gfP4AzAyOog==</latexit><latexit sha1_base64="9gMEVXI5nPy8/zVrqdImqNvyYh4=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEUG8FLx4rmLbQhrLZTtqlm03Y3Ygl9Dd48aCIV3+QN/+N2zYHbX0w8Hhvhpl5YSq4Nq777ZTW1jc2t8rblZ3dvf2D6uFRSyeZYuizRCSqE1KNgkv0DTcCO6lCGocC2+H4dua3H1FpnsgHM0kxiOlQ8ogzaqzkP/Vzd9qv1ty6OwdZJV5BalCg2a9+9QYJy2KUhgmqdddzUxPkVBnOBE4rvUxjStmYDrFrqaQx6iCfHzslZ1YZkChRtqQhc/X3RE5jrSdxaDtjakZ62ZuJ/3ndzETXQc5lmhmUbLEoygQxCZl9TgZcITNiYgllittbCRtRRZmx+VRsCN7yy6ukdVH33Lp3f1lr3BRxlOEETuEcPLiCBtxBE3xgwOEZXuHNkc6L8+58LFpLTjFzDH/gfP4AzAyOog==</latexit>x1<latexit sha1_base64="BSo1sbtbY8nJyLPqZlWO7YzZ22g=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEUG8FLx4rmLbQhrLZTtqlm03Y3Ygl9Dd48aCIV3+QN/+N2zYHbX0w8Hhvhpl5YSq4Nq777ZTW1jc2t8rblZ3dvf2D6uFRSyeZYuizRCSqE1KNgkv0DTcCO6lCGocC2+H4dua3H1FpnsgHM0kxiOlQ8ogzaqzkP/Vzb9qv1ty6OwdZJV5BalCg2a9+9QYJy2KUhgmqdddzUxPkVBnOBE4rvUxjStmYDrFrqaQx6iCfHzslZ1YZkChRtqQhc/X3RE5jrSdxaDtjakZ62ZuJ/3ndzETXQc5lmhmUbLEoygQxCZl9TgZcITNiYgllittbCRtRRZmx+VRsCN7yy6ukdVH33Lp3f1lr3BRxlOEETuEcPLiCBtxBE3xgwOEZXuHNkc6L8+58LFpLTjFzDH/gfP4AzZGOow==</latexit><latexit sha1_base64="BSo1sbtbY8nJyLPqZlWO7YzZ22g=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEUG8FLx4rmLbQhrLZTtqlm03Y3Ygl9Dd48aCIV3+QN/+N2zYHbX0w8Hhvhpl5YSq4Nq777ZTW1jc2t8rblZ3dvf2D6uFRSyeZYuizRCSqE1KNgkv0DTcCO6lCGocC2+H4dua3H1FpnsgHM0kxiOlQ8ogzaqzkP/Vzb9qv1ty6OwdZJV5BalCg2a9+9QYJy2KUhgmqdddzUxPkVBnOBE4rvUxjStmYDrFrqaQx6iCfHzslZ1YZkChRtqQhc/X3RE5jrSdxaDtjakZ62ZuJ/3ndzETXQc5lmhmUbLEoygQxCZl9TgZcITNiYgllittbCRtRRZmx+VRsCN7yy6ukdVH33Lp3f1lr3BRxlOEETuEcPLiCBtxBE3xgwOEZXuHNkc6L8+58LFpLTjFzDH/gfP4AzZGOow==</latexit><latexit sha1_base64="BSo1sbtbY8nJyLPqZlWO7YzZ22g=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEUG8FLx4rmLbQhrLZTtqlm03Y3Ygl9Dd48aCIV3+QN/+N2zYHbX0w8Hhvhpl5YSq4Nq777ZTW1jc2t8rblZ3dvf2D6uFRSyeZYuizRCSqE1KNgkv0DTcCO6lCGocC2+H4dua3H1FpnsgHM0kxiOlQ8ogzaqzkP/Vzb9qv1ty6OwdZJV5BalCg2a9+9QYJy2KUhgmqdddzUxPkVBnOBE4rvUxjStmYDrFrqaQx6iCfHzslZ1YZkChRtqQhc/X3RE5jrSdxaDtjakZ62ZuJ/3ndzETXQc5lmhmUbLEoygQxCZl9TgZcITNiYgllittbCRtRRZmx+VRsCN7yy6ukdVH33Lp3f1lr3BRxlOEETuEcPLiCBtxBE3xgwOEZXuHNkc6L8+58LFpLTjFzDH/gfP4AzZGOow==</latexit><latexit sha1_base64="BSo1sbtbY8nJyLPqZlWO7YzZ22g=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEUG8FLx4rmLbQhrLZTtqlm03Y3Ygl9Dd48aCIV3+QN/+N2zYHbX0w8Hhvhpl5YSq4Nq777ZTW1jc2t8rblZ3dvf2D6uFRSyeZYuizRCSqE1KNgkv0DTcCO6lCGocC2+H4dua3H1FpnsgHM0kxiOlQ8ogzaqzkP/Vzb9qv1ty6OwdZJV5BalCg2a9+9QYJy2KUhgmqdddzUxPkVBnOBE4rvUxjStmYDrFrqaQx6iCfHzslZ1YZkChRtqQhc/X3RE5jrSdxaDtjakZ62ZuJ/3ndzETXQc5lmhmUbLEoygQxCZl9TgZcITNiYgllittbCRtRRZmx+VRsCN7yy6ukdVH33Lp3f1lr3BRxlOEETuEcPLiCBtxBE3xgwOEZXuHNkc6L8+58LFpLTjFzDH/gfP4AzZGOow==</latexit>x2<latexit sha1_base64="Jh+d1dqdROS9Xlkvz4Ncl4/mIRI=">AAAB7HicbVBNS8NAEJ34WetX1aOXxSJ4KkkR1FvBi8cKpi20oWy2m3bpZhN2J2IJ/Q1ePCji1R/kzX/jts1BWx8MPN6bYWZemEph0HW/nbX1jc2t7dJOeXdv/+CwcnTcMkmmGfdZIhPdCanhUijuo0DJO6nmNA4lb4fj25nffuTaiEQ94CTlQUyHSkSCUbSS/9TP69N+perW3DnIKvEKUoUCzX7lqzdIWBZzhUxSY7qem2KQU42CST4t9zLDU8rGdMi7lioacxPk82On5NwqAxIl2pZCMld/T+Q0NmYSh7Yzpjgyy95M/M/rZhhdB7lQaYZcscWiKJMEEzL7nAyE5gzlxBLKtLC3EjaimjK0+ZRtCN7yy6ukVa95bs27v6w2boo4SnAKZ3ABHlxBA+6gCT4wEPAMr/DmKOfFeXc+Fq1rTjFzAn/gfP4AzxaOpA==</latexit><latexit sha1_base64="Jh+d1dqdROS9Xlkvz4Ncl4/mIRI=">AAAB7HicbVBNS8NAEJ34WetX1aOXxSJ4KkkR1FvBi8cKpi20oWy2m3bpZhN2J2IJ/Q1ePCji1R/kzX/jts1BWx8MPN6bYWZemEph0HW/nbX1jc2t7dJOeXdv/+CwcnTcMkmmGfdZIhPdCanhUijuo0DJO6nmNA4lb4fj25nffuTaiEQ94CTlQUyHSkSCUbSS/9TP69N+perW3DnIKvEKUoUCzX7lqzdIWBZzhUxSY7qem2KQU42CST4t9zLDU8rGdMi7lioacxPk82On5NwqAxIl2pZCMld/T+Q0NmYSh7Yzpjgyy95M/M/rZhhdB7lQaYZcscWiKJMEEzL7nAyE5gzlxBLKtLC3EjaimjK0+ZRtCN7yy6ukVa95bs27v6w2boo4SnAKZ3ABHlxBA+6gCT4wEPAMr/DmKOfFeXc+Fq1rTjFzAn/gfP4AzxaOpA==</latexit><latexit sha1_base64="Jh+d1dqdROS9Xlkvz4Ncl4/mIRI=">AAAB7HicbVBNS8NAEJ34WetX1aOXxSJ4KkkR1FvBi8cKpi20oWy2m3bpZhN2J2IJ/Q1ePCji1R/kzX/jts1BWx8MPN6bYWZemEph0HW/nbX1jc2t7dJOeXdv/+CwcnTcMkmmGfdZIhPdCanhUijuo0DJO6nmNA4lb4fj25nffuTaiEQ94CTlQUyHSkSCUbSS/9TP69N+perW3DnIKvEKUoUCzX7lqzdIWBZzhUxSY7qem2KQU42CST4t9zLDU8rGdMi7lioacxPk82On5NwqAxIl2pZCMld/T+Q0NmYSh7Yzpjgyy95M/M/rZhhdB7lQaYZcscWiKJMEEzL7nAyE5gzlxBLKtLC3EjaimjK0+ZRtCN7yy6ukVa95bs27v6w2boo4SnAKZ3ABHlxBA+6gCT4wEPAMr/DmKOfFeXc+Fq1rTjFzAn/gfP4AzxaOpA==</latexit><latexit sha1_base64="Jh+d1dqdROS9Xlkvz4Ncl4/mIRI=">AAAB7HicbVBNS8NAEJ34WetX1aOXxSJ4KkkR1FvBi8cKpi20oWy2m3bpZhN2J2IJ/Q1ePCji1R/kzX/jts1BWx8MPN6bYWZemEph0HW/nbX1jc2t7dJOeXdv/+CwcnTcMkmmGfdZIhPdCanhUijuo0DJO6nmNA4lb4fj25nffuTaiEQ94CTlQUyHSkSCUbSS/9TP69N+perW3DnIKvEKUoUCzX7lqzdIWBZzhUxSY7qem2KQU42CST4t9zLDU8rGdMi7lioacxPk82On5NwqAxIl2pZCMld/T+Q0NmYSh7Yzpjgyy95M/M/rZhhdB7lQaYZcscWiKJMEEzL7nAyE5gzlxBLKtLC3EjaimjK0+ZRtCN7yy6ukVa95bs27v6w2boo4SnAKZ3ABHlxBA+6gCT4wEPAMr/DmKOfFeXc+Fq1rTjFzAn/gfP4AzxaOpA==</latexit>xt<latexit sha1_base64="EK+1WjIeMUMnWAEPGD4Z6LfWmvs=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEUG8FLx4rmLbQhrLZbtqlm03YnYgl9Dd48aCIV3+QN/+N2zYHbX0w8Hhvhpl5YSqFQdf9dkpr6xubW+Xtys7u3v5B9fCoZZJMM+6zRCa6E1LDpVDcR4GSd1LNaRxK3g7HtzO//ci1EYl6wEnKg5gOlYgEo2gl/6mf47Rfrbl1dw6ySryC1KBAs1/96g0SlsVcIZPUmK7nphjkVKNgkk8rvczwlLIxHfKupYrG3AT5/NgpObPKgESJtqWQzNXfEzmNjZnEoe2MKY7MsjcT//O6GUbXQS5UmiFXbLEoyiTBhMw+JwOhOUM5sYQyLeythI2opgxtPhUbgrf88ippXdQ9t+7dX9YaN0UcZTiBUzgHD66gAXfQBB8YCHiGV3hzlPPivDsfi9aSU8wcwx84nz8zb47m</latexit><latexit sha1_base64="EK+1WjIeMUMnWAEPGD4Z6LfWmvs=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEUG8FLx4rmLbQhrLZbtqlm03YnYgl9Dd48aCIV3+QN/+N2zYHbX0w8Hhvhpl5YSqFQdf9dkpr6xubW+Xtys7u3v5B9fCoZZJMM+6zRCa6E1LDpVDcR4GSd1LNaRxK3g7HtzO//ci1EYl6wEnKg5gOlYgEo2gl/6mf47Rfrbl1dw6ySryC1KBAs1/96g0SlsVcIZPUmK7nphjkVKNgkk8rvczwlLIxHfKupYrG3AT5/NgpObPKgESJtqWQzNXfEzmNjZnEoe2MKY7MsjcT//O6GUbXQS5UmiFXbLEoyiTBhMw+JwOhOUM5sYQyLeythI2opgxtPhUbgrf88ippXdQ9t+7dX9YaN0UcZTiBUzgHD66gAXfQBB8YCHiGV3hzlPPivDsfi9aSU8wcwx84nz8zb47m</latexit><latexit sha1_base64="EK+1WjIeMUMnWAEPGD4Z6LfWmvs=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEUG8FLx4rmLbQhrLZbtqlm03YnYgl9Dd48aCIV3+QN/+N2zYHbX0w8Hhvhpl5YSqFQdf9dkpr6xubW+Xtys7u3v5B9fCoZZJMM+6zRCa6E1LDpVDcR4GSd1LNaRxK3g7HtzO//ci1EYl6wEnKg5gOlYgEo2gl/6mf47Rfrbl1dw6ySryC1KBAs1/96g0SlsVcIZPUmK7nphjkVKNgkk8rvczwlLIxHfKupYrG3AT5/NgpObPKgESJtqWQzNXfEzmNjZnEoe2MKY7MsjcT//O6GUbXQS5UmiFXbLEoyiTBhMw+JwOhOUM5sYQyLeythI2opgxtPhUbgrf88ippXdQ9t+7dX9YaN0UcZTiBUzgHD66gAXfQBB8YCHiGV3hzlPPivDsfi9aSU8wcwx84nz8zb47m</latexit><latexit sha1_base64="EK+1WjIeMUMnWAEPGD4Z6LfWmvs=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEUG8FLx4rmLbQhrLZbtqlm03YnYgl9Dd48aCIV3+QN/+N2zYHbX0w8Hhvhpl5YSqFQdf9dkpr6xubW+Xtys7u3v5B9fCoZZJMM+6zRCa6E1LDpVDcR4GSd1LNaRxK3g7HtzO//ci1EYl6wEnKg5gOlYgEo2gl/6mf47Rfrbl1dw6ySryC1KBAs1/96g0SlsVcIZPUmK7nphjkVKNgkk8rvczwlLIxHfKupYrG3AT5/NgpObPKgESJtqWQzNXfEzmNjZnEoe2MKY7MsjcT//O6GUbXQS5UmiFXbLEoyiTBhMw+JwOhOUM5sYQyLeythI2opgxtPhUbgrf88ippXdQ9t+7dX9YaN0UcZTiBUzgHD66gAXfQBB8YCHiGV3hzlPPivDsfi9aSU8wcwx84nz8zb47m</latexit>yt<latexit sha1_base64="qGSo7TI0l9EX8Xk/wTOjxFwJUhs=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEUG8FLx4rmFpoQ9lsN+3SzSbsToQQ+hu8eFDEqz/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O5W19Y3Nrep2bWd3b/+gfnjUMUmmGfdZIhPdDanhUijuo0DJu6nmNA4lfwwntzP/8YlrIxL1gHnKg5iOlIgEo2glPx8UOB3UG27TnYOsEq8kDSjRHtS/+sOEZTFXyCQ1pue5KQYF1SiY5NNaPzM8pWxCR7xnqaIxN0ExP3ZKzqwyJFGibSkkc/X3REFjY/I4tJ0xxbFZ9mbif14vw+g6KIRKM+SKLRZFmSSYkNnnZCg0ZyhzSyjTwt5K2JhqytDmU7MheMsvr5LORdNzm979ZaN1U8ZRhRM4hXPw4ApacAdt8IGBgGd4hTdHOS/Ou/OxaK045cwx/IHz+QM0947n</latexit><latexit sha1_base64="qGSo7TI0l9EX8Xk/wTOjxFwJUhs=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEUG8FLx4rmFpoQ9lsN+3SzSbsToQQ+hu8eFDEqz/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O5W19Y3Nrep2bWd3b/+gfnjUMUmmGfdZIhPdDanhUijuo0DJu6nmNA4lfwwntzP/8YlrIxL1gHnKg5iOlIgEo2glPx8UOB3UG27TnYOsEq8kDSjRHtS/+sOEZTFXyCQ1pue5KQYF1SiY5NNaPzM8pWxCR7xnqaIxN0ExP3ZKzqwyJFGibSkkc/X3REFjY/I4tJ0xxbFZ9mbif14vw+g6KIRKM+SKLRZFmSSYkNnnZCg0ZyhzSyjTwt5K2JhqytDmU7MheMsvr5LORdNzm979ZaN1U8ZRhRM4hXPw4ApacAdt8IGBgGd4hTdHOS/Ou/OxaK045cwx/IHz+QM0947n</latexit><latexit sha1_base64="qGSo7TI0l9EX8Xk/wTOjxFwJUhs=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEUG8FLx4rmFpoQ9lsN+3SzSbsToQQ+hu8eFDEqz/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O5W19Y3Nrep2bWd3b/+gfnjUMUmmGfdZIhPdDanhUijuo0DJu6nmNA4lfwwntzP/8YlrIxL1gHnKg5iOlIgEo2glPx8UOB3UG27TnYOsEq8kDSjRHtS/+sOEZTFXyCQ1pue5KQYF1SiY5NNaPzM8pWxCR7xnqaIxN0ExP3ZKzqwyJFGibSkkc/X3REFjY/I4tJ0xxbFZ9mbif14vw+g6KIRKM+SKLRZFmSSYkNnnZCg0ZyhzSyjTwt5K2JhqytDmU7MheMsvr5LORdNzm979ZaN1U8ZRhRM4hXPw4ApacAdt8IGBgGd4hTdHOS/Ou/OxaK045cwx/IHz+QM0947n</latexit><latexit sha1_base64="qGSo7TI0l9EX8Xk/wTOjxFwJUhs=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEUG8FLx4rmFpoQ9lsN+3SzSbsToQQ+hu8eFDEqz/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O5W19Y3Nrep2bWd3b/+gfnjUMUmmGfdZIhPdDanhUijuo0DJu6nmNA4lfwwntzP/8YlrIxL1gHnKg5iOlIgEo2glPx8UOB3UG27TnYOsEq8kDSjRHtS/+sOEZTFXyCQ1pue5KQYF1SiY5NNaPzM8pWxCR7xnqaIxN0ExP3ZKzqwyJFGibSkkc/X3REFjY/I4tJ0xxbFZ9mbif14vw+g6KIRKM+SKLRZFmSSYkNnnZCg0ZyhzSyjTwt5K2JhqytDmU7MheMsvr5LORdNzm979ZaN1U8ZRhRM4hXPw4ApacAdt8IGBgGd4hTdHOS/Ou/OxaK045cwx/IHz+QM0947n</latexit>ht k<latexit sha1_base64="yUVvjjeJSzSuGb7nECUw9IyviWo=">AAAB7nicbVBNS8NAEJ3Ur1q/qh69LBbBiyURQb0VvHisYD+gDWWz3bRLNpuwOxFK6I/w4kERr/4eb/4bt20O2vpg4PHeDDPzglQKg6777ZTW1jc2t8rblZ3dvf2D6uFR2ySZZrzFEpnobkANl0LxFgqUvJtqTuNA8k4Q3c38zhPXRiTqEScp92M6UiIUjKKVOuNBjhfRdFCtuXV3DrJKvILUoEBzUP3qDxOWxVwhk9SYnuem6OdUo2CSTyv9zPCUsoiOeM9SRWNu/Hx+7pScWWVIwkTbUkjm6u+JnMbGTOLAdsYUx2bZm4n/eb0Mwxs/FyrNkCu2WBRmkmBCZr+TodCcoZxYQpkW9lbCxlRThjahig3BW355lbQv655b9x6uao3bIo4ynMApnIMH19CAe2hCCxhE8Ayv8Oakzovz7nwsWktOMXMMf+B8/gBPaY+C</latexit><latexit sha1_base64="yUVvjjeJSzSuGb7nECUw9IyviWo=">AAAB7nicbVBNS8NAEJ3Ur1q/qh69LBbBiyURQb0VvHisYD+gDWWz3bRLNpuwOxFK6I/w4kERr/4eb/4bt20O2vpg4PHeDDPzglQKg6777ZTW1jc2t8rblZ3dvf2D6uFR2ySZZrzFEpnobkANl0LxFgqUvJtqTuNA8k4Q3c38zhPXRiTqEScp92M6UiIUjKKVOuNBjhfRdFCtuXV3DrJKvILUoEBzUP3qDxOWxVwhk9SYnuem6OdUo2CSTyv9zPCUsoiOeM9SRWNu/Hx+7pScWWVIwkTbUkjm6u+JnMbGTOLAdsYUx2bZm4n/eb0Mwxs/FyrNkCu2WBRmkmBCZr+TodCcoZxYQpkW9lbCxlRThjahig3BW355lbQv655b9x6uao3bIo4ynMApnIMH19CAe2hCCxhE8Ayv8Oakzovz7nwsWktOMXMMf+B8/gBPaY+C</latexit><latexit sha1_base64="yUVvjjeJSzSuGb7nECUw9IyviWo=">AAAB7nicbVBNS8NAEJ3Ur1q/qh69LBbBiyURQb0VvHisYD+gDWWz3bRLNpuwOxFK6I/w4kERr/4eb/4bt20O2vpg4PHeDDPzglQKg6777ZTW1jc2t8rblZ3dvf2D6uFR2ySZZrzFEpnobkANl0LxFgqUvJtqTuNA8k4Q3c38zhPXRiTqEScp92M6UiIUjKKVOuNBjhfRdFCtuXV3DrJKvILUoEBzUP3qDxOWxVwhk9SYnuem6OdUo2CSTyv9zPCUsoiOeM9SRWNu/Hx+7pScWWVIwkTbUkjm6u+JnMbGTOLAdsYUx2bZm4n/eb0Mwxs/FyrNkCu2WBRmkmBCZr+TodCcoZxYQpkW9lbCxlRThjahig3BW355lbQv655b9x6uao3bIo4ynMApnIMH19CAe2hCCxhE8Ayv8Oakzovz7nwsWktOMXMMf+B8/gBPaY+C</latexit><latexit sha1_base64="yUVvjjeJSzSuGb7nECUw9IyviWo=">AAAB7nicbVBNS8NAEJ3Ur1q/qh69LBbBiyURQb0VvHisYD+gDWWz3bRLNpuwOxFK6I/w4kERr/4eb/4bt20O2vpg4PHeDDPzglQKg6777ZTW1jc2t8rblZ3dvf2D6uFR2ySZZrzFEpnobkANl0LxFgqUvJtqTuNA8k4Q3c38zhPXRiTqEScp92M6UiIUjKKVOuNBjhfRdFCtuXV3DrJKvILUoEBzUP3qDxOWxVwhk9SYnuem6OdUo2CSTyv9zPCUsoiOeM9SRWNu/Hx+7pScWWVIwkTbUkjm6u+JnMbGTOLAdsYUx2bZm4n/eb0Mwxs/FyrNkCu2WBRmkmBCZr+TodCcoZxYQpkW9lbCxlRThjahig3BW355lbQv655b9x6uao3bIo4ynMApnIMH19CAe2hCCxhE8Ayv8Oakzovz7nwsWktOMXMMf+B8/gBPaY+C</latexit>Agentht 1htxt xtSampleHidden state distributionRewardht 1LSTMht k<latexit sha1_base64="yUVvjjeJSzSuGb7nECUw9IyviWo=">AAAB7nicbVBNS8NAEJ3Ur1q/qh69LBbBiyURQb0VvHisYD+gDWWz3bRLNpuwOxFK6I/w4kERr/4eb/4bt20O2vpg4PHeDDPzglQKg6777ZTW1jc2t8rblZ3dvf2D6uFR2ySZZrzFEpnobkANl0LxFgqUvJtqTuNA8k4Q3c38zhPXRiTqEScp92M6UiIUjKKVOuNBjhfRdFCtuXV3DrJKvILUoEBzUP3qDxOWxVwhk9SYnuem6OdUo2CSTyv9zPCUsoiOeM9SRWNu/Hx+7pScWWVIwkTbUkjm6u+JnMbGTOLAdsYUx2bZm4n/eb0Mwxs/FyrNkCu2WBRmkmBCZr+TodCcoZxYQpkW9lbCxlRThjahig3BW355lbQv655b9x6uao3bIo4ynMApnIMH19CAe2hCCxhE8Ayv8Oakzovz7nwsWktOMXMMf+B8/gBPaY+C</latexit><latexit sha1_base64="yUVvjjeJSzSuGb7nECUw9IyviWo=">AAAB7nicbVBNS8NAEJ3Ur1q/qh69LBbBiyURQb0VvHisYD+gDWWz3bRLNpuwOxFK6I/w4kERr/4eb/4bt20O2vpg4PHeDDPzglQKg6777ZTW1jc2t8rblZ3dvf2D6uFR2ySZZrzFEpnobkANl0LxFgqUvJtqTuNA8k4Q3c38zhPXRiTqEScp92M6UiIUjKKVOuNBjhfRdFCtuXV3DrJKvILUoEBzUP3qDxOWxVwhk9SYnuem6OdUo2CSTyv9zPCUsoiOeM9SRWNu/Hx+7pScWWVIwkTbUkjm6u+JnMbGTOLAdsYUx2bZm4n/eb0Mwxs/FyrNkCu2WBRmkmBCZr+TodCcoZxYQpkW9lbCxlRThjahig3BW355lbQv655b9x6uao3bIo4ynMApnIMH19CAe2hCCxhE8Ayv8Oakzovz7nwsWktOMXMMf+B8/gBPaY+C</latexit><latexit sha1_base64="yUVvjjeJSzSuGb7nECUw9IyviWo=">AAAB7nicbVBNS8NAEJ3Ur1q/qh69LBbBiyURQb0VvHisYD+gDWWz3bRLNpuwOxFK6I/w4kERr/4eb/4bt20O2vpg4PHeDDPzglQKg6777ZTW1jc2t8rblZ3dvf2D6uFR2ySZZrzFEpnobkANl0LxFgqUvJtqTuNA8k4Q3c38zhPXRiTqEScp92M6UiIUjKKVOuNBjhfRdFCtuXV3DrJKvILUoEBzUP3qDxOWxVwhk9SYnuem6OdUo2CSTyv9zPCUsoiOeM9SRWNu/Hx+7pScWWVIwkTbUkjm6u+JnMbGTOLAdsYUx2bZm4n/eb0Mwxs/FyrNkCu2WBRmkmBCZr+TodCcoZxYQpkW9lbCxlRThjahig3BW355lbQv655b9x6uao3bIo4ynMApnIMH19CAe2hCCxhE8Ayv8Oakzovz7nwsWktOMXMMf+B8/gBPaY+C</latexit><latexit sha1_base64="yUVvjjeJSzSuGb7nECUw9IyviWo=">AAAB7nicbVBNS8NAEJ3Ur1q/qh69LBbBiyURQb0VvHisYD+gDWWz3bRLNpuwOxFK6I/w4kERr/4eb/4bt20O2vpg4PHeDDPzglQKg6777ZTW1jc2t8rblZ3dvf2D6uFR2ySZZrzFEpnobkANl0LxFgqUvJtqTuNA8k4Q3c38zhPXRiTqEScp92M6UiIUjKKVOuNBjhfRdFCtuXV3DrJKvILUoEBzUP3qDxOWxVwhk9SYnuem6OdUo2CSTyv9zPCUsoiOeM9SRWNu/Hx+7pScWWVIwkTbUkjm6u+JnMbGTOLAdsYUx2bZm4n/eb0Mwxs/FyrNkCu2WBRmkmBCZr+TodCcoZxYQpkW9lbCxlRThjahig3BW355lbQv655b9x6uao3bIo4ynMApnIMH19CAe2hCCxhE8Ayv8Oakzovz7nwsWktOMXMMf+B8/gBPaY+C</latexit>Word EmbeddingLSTMSoftmaxht<latexit sha1_base64="RTZU/IBBNRdeCulLKNopIkCtPBY=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEqN4KXjxWMG2hDWWz3bRLN5uwOxFK6G/w4kERr/4gb/4bt20O2vpg4PHeDDPzwlQKg6777ZQ2Nre2d8q7lb39g8Oj6vFJ2ySZZtxniUx0N6SGS6G4jwIl76aa0ziUvBNO7uZ+54lrIxL1iNOUBzEdKREJRtFK/niQ42xQrbl1dwGyTryC1KBAa1D96g8TlsVcIZPUmJ7nphjkVKNgks8q/czwlLIJHfGepYrG3AT54tgZubDKkESJtqWQLNTfEzmNjZnGoe2MKY7NqjcX//N6GUY3QS5UmiFXbLkoyiTBhMw/J0OhOUM5tYQyLeythI2ppgxtPhUbgrf68jppX9U9t+49XNeat0UcZTiDc7gEDxrQhHtogQ8MBDzDK7w5ynlx3p2PZWvJKWZO4Q+czx8a747W</latexit><latexit sha1_base64="RTZU/IBBNRdeCulLKNopIkCtPBY=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEqN4KXjxWMG2hDWWz3bRLN5uwOxFK6G/w4kERr/4gb/4bt20O2vpg4PHeDDPzwlQKg6777ZQ2Nre2d8q7lb39g8Oj6vFJ2ySZZtxniUx0N6SGS6G4jwIl76aa0ziUvBNO7uZ+54lrIxL1iNOUBzEdKREJRtFK/niQ42xQrbl1dwGyTryC1KBAa1D96g8TlsVcIZPUmJ7nphjkVKNgks8q/czwlLIJHfGepYrG3AT54tgZubDKkESJtqWQLNTfEzmNjZnGoe2MKY7NqjcX//N6GUY3QS5UmiFXbLkoyiTBhMw/J0OhOUM5tYQyLeythI2ppgxtPhUbgrf68jppX9U9t+49XNeat0UcZTiDc7gEDxrQhHtogQ8MBDzDK7w5ynlx3p2PZWvJKWZO4Q+czx8a747W</latexit><latexit sha1_base64="RTZU/IBBNRdeCulLKNopIkCtPBY=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEqN4KXjxWMG2hDWWz3bRLN5uwOxFK6G/w4kERr/4gb/4bt20O2vpg4PHeDDPzwlQKg6777ZQ2Nre2d8q7lb39g8Oj6vFJ2ySZZtxniUx0N6SGS6G4jwIl76aa0ziUvBNO7uZ+54lrIxL1iNOUBzEdKREJRtFK/niQ42xQrbl1dwGyTryC1KBAa1D96g8TlsVcIZPUmJ7nphjkVKNgks8q/czwlLIJHfGepYrG3AT54tgZubDKkESJtqWQLNTfEzmNjZnGoe2MKY7NqjcX//N6GUY3QS5UmiFXbLkoyiTBhMw/J0OhOUM5tYQyLeythI2ppgxtPhUbgrf68jppX9U9t+49XNeat0UcZTiDc7gEDxrQhHtogQ8MBDzDK7w5ynlx3p2PZWvJKWZO4Q+czx8a747W</latexit><latexit sha1_base64="RTZU/IBBNRdeCulLKNopIkCtPBY=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEqN4KXjxWMG2hDWWz3bRLN5uwOxFK6G/w4kERr/4gb/4bt20O2vpg4PHeDDPzwlQKg6777ZQ2Nre2d8q7lb39g8Oj6vFJ2ySZZtxniUx0N6SGS6G4jwIl76aa0ziUvBNO7uZ+54lrIxL1iNOUBzEdKREJRtFK/niQ42xQrbl1dwGyTryC1KBAa1D96g8TlsVcIZPUmJ7nphjkVKNgks8q/czwlLIJHfGepYrG3AT54tgZubDKkESJtqWQLNTfEzmNjZnGoe2MKY7NqjcX//N6GUY3QS5UmiFXbLkoyiTBhMw/J0OhOUM5tYQyLeythI2ppgxtPhUbgrf68jppX9U9t+49XNeat0UcZTiDc7gEDxrQhHtogQ8MBDzDK7w5ynlx3p2PZWvJKWZO4Q+czx8a747W</latexit>Hidden StateState Setat (transferring a certain State to a standard LSTM cell).
Then, the standard LSTM cell uses the newly selected State
to achieve the task. The model’s performance based on the
current selections will be treated as a reward to update the
parameters of the agent.

Next, we will detail the four key points of the agent, in-
cluding the environment representation st, the action at, the
reward function, and the recurrent transition function.
Environment representation. Our intuition in formulating
an environment representation is that the agent should se-
lect an action based on both the historical and current infor-
mation. We therefore incorporate the previous hidden state
1 and the current input xt to formulate the agent’s envi-
ht
ronment representation as follows:

−

st = ht

xt,

1 ⊕
−

⊕

where
refers to the concatenation operation. At each time
step, the agent observes the environment st to decide an ac-
tion.
Actions. After observing the environment st, the agent
should decide which State is optimal for the downstream
LSTM cell. Formally, we construct a State set SK, which
preserves the K recently obtained State, and the maximum
size K is set ahead of time. The agent takes an action by
sampling an optimal State in SK from a multinomial distri-
bution πK(k

st) as follows:

|

P = sof tmax(M LP (st))

πK(k

st) = P r(K = k

st) =

|

|

K
(cid:89)

i=1

p[k=i]
i

,

(1)

−

where [k = i] evaluates to 1 if k = i, 0 otherwise. M LP
represents a multilayer perceptron to transform st to a vector
with dimensionality K, and the sof tmax function is used to
transform the vector to a probability distribution P . pi is the
i-th element in P . Then, the Statet
k is transferred to the
LSTM cell for further computation.
Reward function. Reward function is an indicator of the
skip utility. A suitable reward function could guide the agent
to select a series of optimal skip actions for training a bet-
ter predictor. We capture this intuition by setting the reward
to be the predicted log-likelihood of the ground truth, i.e.,
hT ). Therefore, by interacting with the en-
R = log P r(ˆyT |
vironment through the rewards, the agent is incentivized to
select the optimal skips to promote the probability of the
ground truth.
Recurrent transition function. Based on the previously
mentioned technique, we use a standard LSTM cell to en-
. In
code the selected Statet
}
the text classiﬁcation experiments, we found that adding
the additional immediate previous state Statet
1 usually
−
led better results, although Statet
1 is a particular case
−
k. However, in our sequence labeling tasks, we
of Statet
k is almost the optimal solu-
found that just using Statet
−
tion. Therefore, In our model, we use a hyperparameter λ to
incorporate these two situations, as shown in Figure 3. For-

k, where k

1, 2, ..., K

∈ {

−

−

Figure 3: Schematic of the recurrent transition function en-
coding both the selected hidden/cell states and the previous
hidden/cell states. λ refers to the function λa + (1
λ)b. σ
and φ refer to the sigmoid and tanh functions, respectively.

−

mally, we give the LSTM function as follows:

1

−
1

−

(cid:101)ht
1 = λht
k + (1
λ)ht
−
−
−
k + (1
1 = λct
(cid:101)ct
λ)ct
−
−
−



x, Wg


Wg
gt
h
x, Wi
Wi
it
h
x, Wf
ft
Wf
h
ot
x, Wo
Wo
h
σ(it) + (cid:101)ct
φ (ct) ,

ct = φ(gt)
ht = σ(ot)



 •


 =












(cid:21)

(cid:20) xt
(cid:101)ht

1

−

+

















bg
bi
bf
bo

(2)

σ(ft)

1 (cid:12)
−

1, 2, ..., K

(cid:12)
(cid:12)
. φ is the tanh operator, and σ is the
where k
}
∈ {
sigmoid operator.
represent the Hadamard prod-
and
(cid:12)
uct and the matrix product, respectively. We assume that y
. The LSTM has Nh hidden units and
is one of
g, i, f, o
{
}
Nx is the dimensionality of word representation xi. Then,
Nx , Wy
RNh are the
RNh
Wy
parameters of the standard LSTM cell.

Nh , and by

x ∈

h ∈

RNh

∈

•

×

×

Training Methods

Our goal for training is optimizing the parameters of the pol-
icy gradient agent θa, together with the parameters of stan-
dard LSTM and possibly other parameters denoted as θl.
Optimizing θl is straightforward and can be treated as a clas-
siﬁcation problem. Because the cross entropy loss J1(θl) is
differentiable, we can apply backpropagation to minimize it
as follows:

J1(θl) =

[yi log ˆyi + (1

−
−
where ˆyi is the output of the model.

yi) log(1

ˆyi)],

(3)

−

The objective of training the agent is to maximize the ex-
pected reward under the skip policy distribution plus an en-
tropy regularization (Nachum et al. 2017).

J2(θa) = E

π(a1:T )[R] + H(π(a1:T )),

(4)

hT ). H(π(a1:T )) =

t=1 P r(at|
E
−

where π(a1:T ) = (cid:81)T
st; θa), and R =
π(a1:T )[log π(a1:T )] is
log P r(ˆyT |
an entropy term, which can prevent premature entropy col-
lapse and encourage the policy to explore more diverse
space. We provide evidence that using the reinforcement
learning with an entropy term can model sentence better than
attention-based connections, as shown in Appendix.

6483

 ⌦⌦⌦       ht 1ht kct kct 1xthtctForget GateInput GateOutput GateTask
Named Entity Recognition
Language Modeling
Sentiment Analysis
Number Prediction

Dataset
CoNLL2003
Penn Treebank
IMDB
synthetic

Level
word
word
sentence
word

Vocab
30,290
10K
112,540
10

#Train
204,567
929,590
21,250
100,000

#Dev
51,578
73,761
3,750
10,000

#Test
46,666
82,431
25,000
10,000

#class
17
10K
2
10

Table 1: Statistics of the CoNLL2003, Penn Treebank, IMDB, and synthetic datasets.

Because of the non-differentiable nature of discrete skips,
we adopt a policy gradient formulation referred to as REIN-
FORCE method (Williams 1992) to optimize θa:

∇θa J2(θa) =E

π(a1:T )[

∇θa log P r(at|

st; θa)
∗

(5)

(R

−

log P r(at|

st; θa)

1)].

−

T
(cid:88)

t=1

T
(cid:88)

t=1

By applying the above algorithm, the loss J2(θa) can be
computed by standard backpropagation. Then, we can get
the ﬁnal objective by minimizing the following function:

J(θa, θl) =

(J1(θl)

J2(θa))],

(6)

1
M

M
(cid:88)

[
m=1

−

where M denotes the quantity of the minibatch, and the ob-
jective function is fully differentiable.

Experiments and Results
In this section, we present the experimental results of the
proposed model for a variety of sequence modeling tasks,
such as named entity recognition, language modeling, and
sentiment analysis. In addition to the evaluation matrices
for each task, in order to better understand the advantages
of our model, we visualize the behavior of skip actions and
make a comparison about how the gradients get changed be-
tween the LSTM and the proposed model. In addition, we
also evaluate the model on the synthetic number prediction
tasks, and verify the proﬁciency in long-term dependencies.
The datasets used in the experiments are listed in Table 1.
General experiment settings. For the fair comparison, we
use the same hyperparameters and optimizer with each base-
line model of different tasks, which will be detailed in each
experiment. As for the policy gradient agent, we use single
layer MLPs with 50 hidden units. The maximum size of skip
K and the hyperparameter λ are ﬁxed during both training
and testing.

Named Entity Recognition
We now present the results for a sequence modeling task,
Named Entity Recognition (NER). We performed exper-
iments on the English data from CoNLL 2003 shared
task (Tjong Kim Sang and De Meulder 2003). This data
set contains four different types of named entities: loca-
tions, persons, organizations, and miscellaneous entities that
do not belong in any of the three previous categories.
The corpora statistics are shown in Table 1. We used the

Model
Huang, Xu, and Yu (2015)
Chiu and Nichols (2015)
Lample et al. (2016)
Ma and Hovy (2016)
Strubell et al. (2017)
†
Strubell et al. (2017)
LSTM, ﬁxed skip = 3 (Zhang et al. 2016)
LSTM, ﬁxed skip = 5 (Zhang et al. 2016)
LSTM with attention
LSTM with dynamic skip

90.91

0.20

90.54
90.85

0.18
0.29

F1
90.10

±
90.94
91.21

±
±
91.14
91.16
91.23
91.56

Table 2: F1-measure of different methods applied to the
CoNLL 2003 dataset. The model that does not use character
embeddings is marked with
. “LSTM with attention” refers
to the LSTM model using attention mechanism to connect
two words.

†

BIOES tagging scheme instead of standard BIO2, as previ-
ous studies have reported meaningful improvement with this
scheme (Lample et al. 2016; Ma and Hovy 2016).

Following (Ma and Hovy 2016), we use 100-dimension
GloVe word embeddings2 and unpretrained character em-
beddings as initialization. We use a forward and backward
new LSTM layer with λ = 1, K = 5 and a CRF layer to
achieve this task. The reward is probability of true label se-
quence in CRF. We use early stopping based on performance
on validation sets. Ma and Hovy (2016) reported the “best”
result appeared at 50 epochs and the model training required
8 hours. In our experiment, because of more exploration, the
“best” result appeared at 65 epochs, the proposed method
training required 9.98 hours.

Table 2 shows the F1 scores of previous models and our
model for NER on the test dataset from the CoNLL 2003
shared task. To our knowledge, the previous best F1 score
(91.21) was achieved by using a combination of bidirec-
tional LSTM, CNN, and CRF to obtain both word- and
character-level representations automatically (Ma and Hovy
2016). By adding a bidirectional LSTM with a ﬁxed skip,
the model’s performance would not improve. By contrast,
the model using dynamic skipping technique improves the
performance by average of 0.35%, and error reduction rate
is more than 4%. Our model also outperforms the attention
model, because the attention model employs a determinis-
tic network to compute an expectation over the alignment
variable, i.e., log f (H, Ek[k]), not the expectation over the
features, i.e., log Ek(H, k). However, the gap between the
above two expectations may be large (Deng et al. 2018). Our

2http://nlp.stanford.edu/projects/glove/

6484

Dev.(PPL) Test(PPL)

Model
RNN (Mikolov and Zweig 2012)
RNN-LDA (Mikolov and Zweig 2012)
Deep RNN (Pascanu et al. 2013)
Zoneout + Variational LSTM (medium) (Merity et al. 2016)
†
Variational LSTM (medium) (Gal and Ghahramani 2016)
†
Variational LSTM (medium, MC) (Gal and Ghahramani 2016)
†
Regularized LSTM (Zaremba, Sutskever, and Vinyals 2014)
Regularized LSTM, ﬁxed skip = 3 (Zhang et al. 2016)
†
Regularized LSTM, ﬁxed skip = 5 (Zhang et al. 2016)
†
Regularized LSTM with attention
†
Regularized LSTM with dynamic skip, λ=1, K=5
CharLM (Kim et al. 2016)
CharLM, ﬁxed skip = 3 (Zhang et al. 2016)
†
CharLM, ﬁxed skip = 5 (Zhang et al. 2016)
†
CharLM with attention
†
CharLM with dynamic skip, λ=1, K=5

†‡

†‡

†

†

-
-
-
84.4
81.9
-
86.2
85.3
86.2
85.1
82.5
82.0
83.6
84.9
82.2
79.9

124.7
113.7
107.5
80.6
79.7
78.6
82.7
81.5
82.0
81.4
78.5
78.9
80.2
80.9
79.0
76.5

Size
6 m
7 m
6 m
20 m
20 m
20 m
20 m
20 m
20 m
20 m
20 m
19 m
19 m
19 m
19 m
19 m

Table 3: Perplexity on validation and test sets for the Penn Treebank language modeling task. PPL refers to the average per-
plexity (lower is better) in ten runs. Size refers to the approximate number of parameters in the model. The models marked
are
have the same conﬁguration which features a hidden size of 650 and a two layer LSTM. The models marked with
with
equivalent to the proposed model with hyperparameters λ = 0, and K = 1.

†

‡

hundreds of times larger than that in the standard LSTM, in-
dicating that the proposed model captures long-term depen-
dencies, whereas the standard LSTM basically stores short-
term information (Mujika, Meier, and Steger 2017). The
same effect was observed for cell states ct.

Language Modeling

We also evaluate the proposed model on the Penn Treebank
language model corpus (Marcus, Marcinkiewicz, and San-
torini 1993). The corpora statistics are shown in Table 1. The
model is trained to predict the next word (evaluated on per-
plexity) in a sequence.

To exclude the potential impact of advanced models, we
restrict our comparison among the RNNs models. We repli-
cate settings from Regularized LSTM (Zaremba, Sutskever,
and Vinyals 2014) and CharLM (Kim et al. 2016). The above
networks both have two layers of LSTM with 650 units,
and the weights are initialized uniformly [-0.05, +0.05]. The
gradients backpropagate for 35 time steps using stochastic
gradient descent, with a learning rate initially set to 1.0.
The norm of the gradients is constrained to be below ﬁve.
Dropout with a probability of 0.5 on the LSTM input-to-
hidden layers and the hidden-to-output softmax layer is ap-
plied. The main difference between the two models is that
the former model uses word embeddings as inputs, while
the latter relies only on character-level inputs.

We replace the second layer of LSTM in the above base-
line models with a ﬁxed skip LSTM or our proposed model.
The testing results are listed in Table 3. We can see that
the performance of the LSTM with a ﬁxed skip may be
even worse than that of the standard LSTM in some cases.
This veriﬁes that in some simple tasks such as the adding
problem, copying memory problem, and sequential MNIST
problem, the LSTM with a ﬁxed skip length may be quite

(cid:13)
(cid:13)
Figure 4: Normalized long-term gradient values
(cid:13)
tested on CoNLL 2003 dataset. At the initial time steps, the
proposed model still preserves effective gradients, which is
hundreds of times larger than those in the standard LSTM,
indicating that the proposed model have stronger ability to
capture long-term dependency.

∂LT
∂ht

(cid:13)
(cid:13)
(cid:13)

model is equivalent to the “Categorical Alignments” model
in (Deng et al. 2018), which can effectively tackle the above
deﬁciency. The detailed proof is given in Appendix.

(cid:13)
(cid:13)
(cid:13)

∂LT
∂ht

In Figure 4, we investigate the problem of vanishing gra-
dient by comparing the long-term gradient values between
standard LSTM and the proposed model. Following (Mu-
jika, Meier, and Steger 2017), we compute the average gra-
(cid:13)
(cid:13)
dient norms
(cid:13) of the loss at time T with respect to
hidden state ht at each time step t. We visualize the gradient
norms in the ﬁrst 20 time steps by normalizing the average
gradient norms by the sum of average gradient norms for
all time steps. Evidently, at the initial time steps, the pro-
posed model still preserves effective gradient backpropaga-
tion. The average gradient norm in the proposed model is

6485

LSTMLSTM with dynamic skipAverage Gradient Norm00.0020.0040.0060.0080.0100.0120.0140.0160.0180.020Time Step01234567891011121314151617181920Model
LSTM
LSTM + LA (Chen et al. 2016)
LSTM + CBAG (Long et al. 2017)
LSTM + CBA + LAG
LSTM + CBA + LAG
Skip LSTM (Campos et al. 2017)
Jump LSTM (Yu, Lee, and Le 2017)
LSTM, ﬁxed skip = 3 (Zhang et al. 2016)
LSTM, ﬁxed skip = 5 (Zhang et al. 2016)
LSTM with attention
LSTM with dynamic skip, λ=0.5, K=3

s (Long et al. 2017)
p (Long et al. 2017)

Acc.
89.1
89.3
89.4
89.8
90.1
86.6
89.4
89.6
89.3
89.4
90.1

Table 4: Accuracy on the IMDB test set.

Sentiment Analysis on IMDB
Two similar works to ours are Jump LSTM (Yu, Lee, and
Le 2017) and Skip LSTM (Campos et al. 2017), which are
excellent modiﬁcations to the LSTM and achieve great per-
formance on text classiﬁcation. However, the above model
cannot be applied to some sequence modeling tasks, such as
language modeling and named entity recognition, because
the jumping characteristics and the nature of skipping state
updates make the models cannot produce LSTM outputs for
skipped tokens and cannot update the hidden state, respec-
tively. For better comparison with the above two models, we
apply the proposed model to a sentiment analysis task.

The IMDB dataset (Maas et al. 2011) contains 25,000
training and 25,000 testing movie reviews annotated into
positive or negative sentiments, where the average length
of text is 240 words. We randomly set aside about 15% of
the training data for validation. The proposed model, Jump
LSTM, Skip LSTM, and LSTM all have one layer and 128
hidden units, and the batch size is 50. We use pretrained
word2vec embeddings as initialization when available, or
0.25, +0.25). Dropout with
(
random vectors drawn from
−
a rate of 0.2 is applied between the last LSTM state and the
classiﬁcation layer. We either pad a short sequence or crop a
long sequence to 400 words. We set λ and K to 0.5 and 3,
respectively.

U

The result is reported in Table 4. Chen et al. (2016) em-
ployed the idea of local semantic attention to achieve the
task. Long et al. (2017) proposed a cognition based attention
model, which needed additional eye-tracking data. From this
result, we can see that our model also exhibits a strong per-
formance on the text classiﬁcation task. The proposed model
is 1% better than the standard LSTM model. In addition,
our model outperforms Skip LSTM and Jump LSTM mod-
els with accuracy at 90.1%. Therefore, the proposed model
not only can achieve sequence modeling tasks such as lan-
guage modeling and named entity recognition, but it also
has a stronger ability for text classiﬁcation tasks than Jump
LSTM and Skip LSTM.

Number Prediction with Skips
For further veriﬁcation that the LSTM with dynamic skip
connections is indeed able to learn how to skip if a clear
skipping signal is given in the text, similar to (Yu, Lee, and

Figure 5: Test set perplexities (lower is better) on Penn Tree-
bank language model corpus with standard deviation for K
from 2 to 10 with λ = 0.5 (left), and λ from 0.1 to 1.0 with
K = 5 (right).

Figure 6: Examples of the proposed model applied to lan-
guage modeling.

powerful (Zhang et al. 2016), whereas in a complex lan-
guage environment, the ﬁxed skip length is constrained by
its inability to take advantage of the dependencies with vari-
able lengths.

Hence, by adding a dynamic skip on the recurrent con-
nections to the LSTM, our model can effectively tackle the
above problem. Both the models with dynamic skip connec-
tions outperform baseline models, and the best model is able
to improve the average test perplexity from 82.7 to 78.5, and
78.9 to 76.5, respectively. We also investigated how the hy-
perparameters λ and K affect the performance of proposed
model as shown in Figure 5. λ is a weight to balance the
utility between the newly selected State and the previous
State. K represents the size of the skip space. From both
ﬁgures we can see that, in general, the proposed model with
larger λ and K values should obtain better PPL, while pro-
ducing a larger variance because of the balance favoring the
selected State and a larger searching space.

To verify the effectiveness of dynamic skip connections,
we visualize the behavior of the agent in a situation where
it predicts a preposition based on a long-term dependency.
Some typical examples are shown in Figure 6. From the ﬁg-
ure, we can see that in the standard LSTM setting, predicting
the three prepositions in the ﬁgure is difﬁcult just based on
the previous State. By introducing the long-term and the
most relevant State using dynamic skip connections, the
proposed model is able to predict the next word with bet-
ter performance in some cases.

6486

78798081828384Attention ConnectionDynamic SkipZaremba et al., 2014PPLK234567891078798081828384Attention ConnectionDynamic SkipZaremba et al., 2014PPLλ0.10.20.30.40.50.60.70.80.91... seek  to  prevent  executive  branch  ofﬁcials  from  ...from...  who  devote  most  of  their  time  to  practicing  ...... taking  ﬂights  from  san  francisco  late  yesterday  to  ...totok=4k=4k=3(1)(2)(3)Prediction Probability: LSTM 0.03, LSTM with dynamic skip 0.21Prediction Probability: LSTM 0.04, LSTM with dynamic skip 0.31Prediction Probability: LSTM 0.33, LSTM with dynamic skip 0.91sequence length 11

Model
LSTM
LSTM with attention
LSTM with dynamic skip, λ=1, K=10
LSTM with dynamic skip, λ=0.5, K=10

sequence length 21

Model
LSTM
LSTM with attention
LSTM with dynamic skip, λ=1, K=10
LSTM with dynamic skip, λ=0.5, K=10

Dev. Test
70.4
69.6
72.5
71.3
80.5
79.6
90.5
90.4

Dev. Test
26.4
26.2
26.9
26.7
77.7
77.6
88.5
87.7

Table 5: Accuracies of different methods on number predic-
tion dataset.

Le 2017), we also investigate a new task, where the network
is given a sequence of L positive integers x0:T
1, and the
label is y = xxT −1. Here are two examples to illustrate the
idea:

−

input1: 8, 5, 1, 7, 4, 3. label: 7
input2: 2, 6, 4, 1, 3, 2. label: 4

As the examples show, xT

1 is the skipping signal that
guides the network to introduce the xT
1-th integer as the
input to predict the label. The ideal network should learn to
ignore the remaining useless numbers and learn how to skip
from the training data.

−

−

According to above rule, we generate 100,000 training,
10,000 validation, and 10,000 test examples. Each example
with a length T = 11 is formed by randomly sampling 11
0, 1, ..., 9
, and we set xx11
numbers from the integer set
}
{
as the label of each example. We use ten dimensional one-
hot vectors to represent the integers as the sequential inputs
of LSTM or Dynamic LSTM, of which the last hidden state
is used for prediction. We adopt one layer of LSTM with
200 hidden neurons. The Adam optimizer (Kingma and Ba
2014) trained with cross-entropy loss is used with 0.001 as
the default learning rate. The testing result is reported in Ta-
ble 5. It is interesting to see that even for a simple task, the
LSTM model cannot achieve a high accuracy. However, the
LSTM with dynamic skip is able to learn how to skip from
the training examples to achieve a much better performance.
Taking this one step further, we increase the difﬁculty of
the task by using two skips to ﬁnd the label, i.e., the label is
y = xx(cid:48), x(cid:48) = xxT −1. To accord with the nature of skip, we
force x(cid:48) < xT

1, Here is an example:

−

input: 8, 5, 1, 7, 1, 3, 3, 4, 7, 9, 4. label: 5

Similar to the former method, we construct a dataset
with the same size, 100,000 training, 10,000 validation, and
10,000 test examples. Each example with length T = 21
is also formed by randomly sampling 21 numbers from the
. We use the same model trained on
integer set
}
the dataset. As the Table 5 shows, the accuracy of the LSTM
with dynamic skip is vastly superior to that of LSTM. There-

0, 1, ..., 9
{

fore, the results indicate that the Dynamic LSTM is able to
learn how to skip.

Related Work
Many attempts have been made to overcome the difﬁculties
of RNNs in modeling long sequential data, such as gating
mechanism (Hochreiter and Schmidhuber 1997; Chung et al.
2014), Multi-timescale mechanism (Chung, Ahn, and Ben-
gio 2016). Recently, many works have explored the use of
skip connections across multiple time steps (Zhang et al.
2016; Chang et al. 2017). Zhang et al. (2016) introduced
the recurrent skip coefﬁcient, which captures how quickly
the information propagates over time, and found that raising
the recurrent skip coefﬁcient can mostly improve the per-
formance of models on long-term dependency tasks. Note
that previous research on skip connections all focused on a
ﬁxed skip length, which is set in advance. Different from
these methods, this work proposed a reinforcement learning
method to dynamically decide the skip length.

Other relevant works that introduce reinforcement learn-
ing to recurrent neural networks are Jump LSTM (Yu, Lee,
and Le 2017), Skip RNN (Seo et al. 2017), and Skim
RNN (Seo et al. 2017). The Jump LSTM aims to reduce the
computational cost of RNNs by skipping irrelevant informa-
tion if needed. Their model learns how many words should
be omitted, which also utilizes the REINFORCE algorithm.
Also, the Skip RNN and Skim RNN can learn to skip (part
of) state updates with a fully differentiable method. The
main differences between our method and the above meth-
ods are that Jump LSTM can not produce LSTM outputs
for the skipped tokens and the Skip (Skim) RNN would not
update (part of) hidden states. Thus three models would be
difﬁcult to be used for sequence labeling tasks. In contrast to
them, our model updated the entire hidden state at each time
step, and can be suitable for sequence labeling tasks.

Conclusions
In this work, we propose a reinforcement learning-based
LSTM model that extends the existing LSTM model with
dynamic skip connections. The proposed model can dynam-
ically choose one optimal set of hidden and cell states from
the past few states. By means of the dynamic skip connec-
tions, the model has a stronger ability to model sentences
than those with ﬁxed skip, and can tackle the dependency
problem with variable lengths in the language. In addition,
because of the shorter gradient backpropagation path, the
model can alleviate the challenges of vanishing gradient. Ex-
perimental results on a series of sequence modeling tasks
demonstrate that the proposed method can achieve much
better performance than previous methods.

Acknowledgments
The authors wish to thank the anonymous reviewers for
their helpful comments. This work was partially funded by
China National Key R&D Program (No. 2017YFB1002104,
2018YFC0831105), National Natural Science Foundation of
China (No. 61532011,61751201, 61473092, and 61472088),
and STCSM (No.16JC1420401, 17JC1420200).

6487

References

Named entity
arXiv preprint

Campos, V.; Jou, B.; Gir´o-i Nieto, X.; Torres, J.; and Chang,
S.-F. 2017. Skip rnn: Learning to skip state updates in re-
current neural networks. arXiv preprint arXiv:1708.06834.
Chang, S.; Zhang, Y.; Han, W.; Yu, M.; Guo, X.; Tan,
W.; Cui, X.; Witbrock, M.; Hasegawa-Johnson, M. A.; and
Huang, T. S. 2017. Dilated recurrent neural networks. In
Advances in Neural Information Processing Systems, 76–86.
Chen, H.; Sun, M.; Tu, C.; Lin, Y.; and Liu, Z. 2016. Neural
sentiment classiﬁcation with user and product attention. In
EMNLP 2016, 1650–1659.
Chiu, J. P., and Nichols, E.
2015.
recognition with bidirectional lstm-cnns.
arXiv:1511.08308.
2016. Hierarchi-
Chung, J.; Ahn, S.; and Bengio, Y.
cal multiscale recurrent neural networks. arXiv preprint
arXiv:1609.01704.
Chung, J.; Gulcehre, C.; Cho, K.; and Bengio, Y. 2014. Em-
pirical evaluation of gated recurrent neural networks on se-
quence modeling. arXiv preprint arXiv:1412.3555.
Dai, A. M., and Le, Q. V. 2015. Semi-supervised sequence
learning. In NIPS, 3079–3087.
Deng, Y.; Kim, Y.; Chiu, J.; Guo, D.; and Rush, A. M. 2018.
Latent alignment and variational attention. arXiv preprint
arXiv:1807.03756.
El Hihi, S., and Bengio, Y. 1996. Hierarchical recurrent
neural networks for long-term dependencies. In Advances
in neural information processing systems, 493–499.
Gal, Y., and Ghahramani, Z. 2016. A theoretically grounded
application of dropout in recurrent neural networks. In NIPS,
1019–1027.
Hochreiter, S., and Schmidhuber, J. 1997. Long short-term
memory. Neural computation 9(8):1735–1780.
Huang, Z.; Xu, W.; and Yu, K.
lstm-crf models for sequence tagging.
arXiv:1508.01991.
Kim, Y.; Jernite, Y.; Sontag, D.; and Rush, A. M. 2016.
Character-aware neural language models. In AAAI, 2741–
2749.
Kingma, D. P., and Ba, J. 2014. Adam: A method for
stochastic optimization. arXiv preprint arXiv:1412.6980.
Lample, G.; Ballesteros, M.; Subramanian, S.; Kawakami,
K.; and Dyer, C. 2016. Neural architectures for named entity
recognition. arXiv preprint arXiv:1603.01360.
Long, Y.; Qin, L.; Xiang, R.; Li, M.; and Huang, C.-R. 2017.
A cognition based attention model for sentiment analysis. In
EMNLP 2017, 462–471.
Ma, X., and Hovy, E. 2016. End-to-end sequence labeling
via bi-directional lstm-cnns-crf. In ACL, volume 1, 1064–
1074.
Maas, A. L.; Daly, R. E.; Pham, P. T.; Huang, D.; Ng, A. Y.;
and Potts, C. 2011. Learning word vectors for sentiment
analysis. In ACL, 142–150.

2015. Bidirectional
arXiv preprint

6488

Marcus, M. P.; Marcinkiewicz, M. A.; and Santorini, B.
1993. Building a large annotated corpus of english: The
penn treebank. Computational linguistics 19(2):313–330.
Merity, S.; Xiong, C.; Bradbury, J.; and Socher, R.
arXiv preprint
2016. Pointer sentinel mixture models.
arXiv:1609.07843.
Mikolov, T., and Zweig, G. 2012. Context dependent recur-
rent neural network language model. SLT 12:234–239.
Mujika, A.; Meier, F.; and Steger, A. 2017. Fast-slow recur-
rent neural networks. In NIPS, 5917–5926.
Nachum, O.; Norouzi, M.; Xu, K.; and Schuurmans, D.
2017. Bridging the gap between value and policy based re-
inforcement learning. In NIPS, 2775–2785.
Nallapati, R.; Zhou, B.; Gulcehre, C.; Xiang, B.; et al. 2016.
Abstractive text summarization using sequence-to-sequence
rnns and beyond. arXiv preprint arXiv:1602.06023.
Pascanu, R.; Gulcehre, C.; Cho, K.; and Bengio, Y. 2013.
How to construct deep recurrent neural networks. arXiv
preprint arXiv:1312.6026.
Santos, C. D., and Zadrozny, B. 2014. Learning character-
level representations for part-of-speech tagging. In ICML-
14, 1818–1826.
Seo, M.; Min, S.; Farhadi, A.; and Hajishirzi, H. 2017.
arXiv preprint
Neural speed reading via skim-rnn.
arXiv:1711.02085.
Serban, I. V.; Sordoni, A.; Bengio, Y.; Courville, A. C.; and
Pineau, J. 2016. Building end-to-end dialogue systems us-
ing generative hierarchical neural network models. In AAAI,
volume 16, 3776–3784.
Strubell, E.; Verga, P.; Belanger, D.; and McCallum, A.
2017. Fast and accurate entity recognition with iterated di-
lated convolutions. In EMNLP 2017, 2670–2680.
Sutskever, I.; Vinyals, O.; and Le, Q. V. 2014. Sequence
to sequence learning with neural networks. In NIPS, 3104–
3112.
Tjong Kim Sang, E. F., and De Meulder, F. 2003. Introduc-
tion to the conll-2003 shared task: Language-independent
named entity recognition. In HLT-NAACL 2003-Volume 4,
142–147.
Williams, R. J. 1992. Simple statistical gradient-following
algorithms for connectionist reinforcement learning. In Re-
inforcement Learning. Springer. 5–32.
Yu, A. W.; Lee, H.; and Le, Q. 2017. Learning to skim text.
In ACL (Volume 1: Long Papers), volume 1, 1880–1890.
Zaremba, W.; Sutskever, I.; and Vinyals, O. 2014. Re-
arXiv preprint
current neural network regularization.
arXiv:1409.2329.
Zhang, S.; Wu, Y.; Che, T.; Lin, Z.; Memisevic, R.;
Salakhutdinov, R. R.; and Bengio, Y. 2016. Architectural
complexity measures of recurrent neural networks. In NIPS,
1822–1830.

