Proceedings of COLING 2012: Technical Papers, pages 167–184,
COLING 2012, Mumbai, December 2012.

167

TextReuseDetectionUsingaCompositionofTextSimilarityMeasuresDanielBär1TorstenZesch1,2IrynaGurevych1,2(1)UbiquitousKnowledgeProcessingLab(UKP-TUDA)DepartmentofComputerScience,TechnischeUniversitätDarmstadt(2)UbiquitousKnowledgeProcessingLab(UKP-DIPF)GermanInstituteforEducationalResearchandEducationalInformationwww.ukp.tu-darmstadt.deABSTRACTDetectingtextreuseisafundamentalrequirementforavarietyoftasksandapplications,rangingfromjournalistictextreusetoplagiarismdetection.Textreuseistraditionallydetectedbycomputingsimilaritybetweenasourcetextandapossiblyreusedtext.However,existingtextsimilaritymeasuresexhibitamajorlimitation:Theycomputesimilarityonlyonfeatureswhichcanbederivedfromthecontentofthegiventexts,therebyinherentlyimplyingthatanyothertextcharacteristicsarenegligible.Inthispaper,weovercomethistraditionallimitationandcomputesimilarityalongthreecharacteristicdimensionsinherenttotexts:content,structure,andstyle.Weexploreanddiscusspossiblecombinationsofmeasuresalongthesedimensions,andourresultsdemonstratethatthecompositionconsistentlyoutperformspreviousapproachesonthreestandardevaluationdatasets,andthattextreusedetectiongreatlybeneﬁtsfromincorporatingadiversefeaturesetthatreﬂectsawidevarietyoftextcharacteristics.TITLEANDABSTRACTINGERMANErkennungvonTextwiederverwendungdurchKompositionvonTextähnlichkeitsmaßenDieFrage,obundinwelcherWeiseTexteinabgewandelterFormwiederverwendetwerden,isteinzentralerAspektbeieinerReihevonProblemstellungen,etwaimRahmenjournalisti-scherTätigkeitoderalsMittelzurPlagiatserkennung.TextwiederverwendungwirdtraditionellermitteltdurchBerechnenvonTextähnlichkeitzwischeneinemUrsprungstextundeinempo-tentiellwiederverwendetenText.BestehendeTextähnlichkeitsmaßehabenjedochdiestarkeEinschränkung,dasssieÄhnlichkeitnuranhandvonEigenschaftenberechnen,dievomInhaltdergegebenenTexteabgeleitetwerdenkönnen,undsomitimplizieren,dassjeglicheandereTextcharacteristikavernächlässigbarsind.IndieserArbeitberechnenwirTextähnlichkeitanhandvondreiDimensionen:Inhalt,StrukturundStil.WiruntersuchenmöglicheKombinationenvonMaßenentlangdieserDimensionen,undzeigendeutlichanhandderErgebnisseaufdreietabliertenEvaluationsdatensätzen,dassdieKompositiongenerellbessereErgebnisseliefertalsbestehendeAnsätze,unddassdieBestimmungvonTextwiederverwendungstarkvoneinembreitenSpektrumanTextcharacteristikaproﬁtiert.KEYWORDS:textsimilarity,textreuse,plagiarism,paraphrase.KEYWORDSINGERMAN:Textähnlichkeit,Textwiederverwendung,Plagiat,Paraphrase.168

1IntroductionTextreuseisacommonphenomenonandarises,forexample,ontheWebfrommirroringtextsondifferentsitesorreusingtextsinpublicblogs.Inothertextcollectionssuchascontentauthoringsystemsofcommunitiesorenterprises,textreusearisesfromkeepingmultipleversions,copiescontainingcustomizationsorreformulations,ortheuseoftemplatetexts(Broderetal.,1997).Problemswithtextreuseparticularlyariseinsettingswheresystemsareextensivelyusedinacollaborativemanner.Forexample,wikisareweb-based,collaborativecontentauthoringsys-temswhichofferfastandsimplemeansforaddingandeditingcontent(LeufandCunningham,2001).Atanytime,userscanmodifycontentalreadypresentinthewiki,augmentexistingtextswithnewfacts,ideas,orthoughts,orcreatenewtextsfromscratch.However,whenuserscontributetowikis,theyneedtoavoidcontentduplication.Thisrequirescomprehensiveknowl-edgeofwhatcontentisalreadypresentinthewiki,andwhatisnot.Aswikisaretraditionallygrowingfast,thisishardlyfeasible,though.Toremedythisissue,weaimatsupportingauthorsofcollaborativetextcollectionsbymeansofautomatictextreusedetection.Weenvisionasemi-supervisedsystemthatinformsacontentauthorofpotentiallypre-existinginstancesoftextreuse,andthenletstheauthordecidehowtoproceed,e.g.tomergebothtexts.Detectingtextreusehasbeenstudiedinavarietyoftasksandapplications,e.g.thedetectionofjournalistictextreuse(Cloughetal.,2002),theidentiﬁcationofrewritesourcesforancientliterarytexts(Lee,2007),ortheanalysisoftextreuseinblogsandwebpages(Abdel-Hamidetal.,2009).Anothercommoninstanceoftextreuseisplagiarism,withtheadditionalconstraintthatthereuseneedstobeunacknowledged.Near-duplicatedetectionisalsoabroadﬁeldofrelatedworkwherethedetectionoftextreuseiscrucial,e.g.inthecontextofwebsearchandcrawling(HoadandZobel,2003;Henzinger,2006;Mankuetal.,2007).Priorwork,however,mainlyutilizesﬁngerprintingandhashingtechniques(Charikar,2002)fortextcomparisonratherthanmethodsfromnaturallanguageprocessing.Acommonapproachtotextreusedetectionistocomputesimilaritybetweenasourcetextandapossiblyreusedtext.Amultitudeoftextsimilaritymeasureshavebeenproposedforcomputingsimilaritybasedonsurface-leveland/orsemanticfeatures(Mihalceaetal.,2006;Landaueretal.,1998;GabrilovichandMarkovitch,2007).However,existingsimilaritymeasurestypicallyexhibitamajorlimitation:Theycomputesimilarityonlyonfeatureswhichcanbederivedfromthecontentofthegiventexts.Byfollowingthisapproach,theyinherentlyimplythatthesimilaritycomputationprocessdoesnotneedtotakeanyothertextcharacteristicsintoaccount.Incontrast,weproposethattextreusedetectionindeedbeneﬁtsfromalsoassessingsimilarityalongothertextcharacteristics(dimensions,henceforth).WefollowempiricalevidencebyBäretal.(2011)andfocusonthreecharacteristicsimilaritydimensionsinherenttotexts:content,structure,andstyle.Figure1showsanexampleoftextreusetakenfromtheWikipediaRewriteCorpus(seeSection3.1)wherepartsofagivensourcetexthavebeenreusedeitherverbatimorbyusingsimilarwordsorphrases.Astheexampleillustrates,theprocessofcreatingreusedtextincludesarevisionstepinwhichtheeditorhasacertaindegreeoffreedomonhowtoreusethesourcetext.Thiskindofsimilarityisdetectablebycontent-centrictextsimilaritymeasures.However,theeditorhasfurthersplitthesourcetextintotwoindividualsentencesandchangedtheorderofthereusedparts.Fordetectingthedegreeofsimilarityofsucharevision,textsimilaritymeasuresforstructuralsimilarityarenecessary.Additionally,thegiventextsexhibitacertaindegreeofsimilaritywithrespecttostylisticfeatures,e.g.vocabularyrichness.1In1Thetype-tokenratio(Templin,1957)ofthetextsis.79and.71,respectively.169

SourceText.PageRankisalinkanalysisalgorithmusedbythe:::::Google:::::::Internet::::::search:::::enginethatassignsanumericalweightingto::::each:::::::elementofa:::::::::hyperlinked:::set:::of::::::::documents,suchastheWorldWideWeb,withthepurposeof“measuring”itsrelativeimportancewithintheset.TextReuse.ThePageRankalgorithmisusedtodesignate::::every:::::aspectofa::set:::of:::::::::hyperlinked:::::::::documentswithanumericalweighting.Itisusedbythe::::::Google::::::search:::::enginetoestimatetherelativeimportanceofawebpageaccordingtothisweighting.Figure1:ExampleoftextreusetakenfromtheWikipediaRewriteCorpus(CloughandSteven-son,2011).Variouspartsofthesourcetexthavebeenreused,eitherverbatim(underlined)orusingsimilarwordsorphrases(wavyunderlined).However,theeditorhassplitthesourcetextintotwoindividualsentencesandchangedtheorderofthereusedparts.ordertousesuchfeaturesasindicatorsoftextreuse,weproposetofurtherincludemeasuresofstylisticsimilarity.Inthispaper,wethusovercomethetraditionallimitationoftextsimilaritymeasurestocontentfeatures.Incontrast,weadoptideasofseminalstudiesbycognitivescientists(Tversky,1977;Goodman,1972;Gärdenfors,2000)anddiscusstheroleofthreesimilaritydimensionsforthetaskoftextreusedetection:content,structure,andstyle,asproposedinourpreviouswork(Bäretal.,2011).InSection2,wereportonamultitudeoftextsimilaritymeasuresfromthesedimensionsthatweusedforourexperiments.InSection3,wedemonstrateempiricallythattextreusecanbebestdetectedifmeasuresarecombinedacrossdimensions,sothatawidevarietyoftextcharacteristicsaretakenintoconsideration.Ourapproachconsistentlyoutperformspreviousworkonthreestandardevaluationdatasets,anddemonstratestheadvantageofintegratingtextcharacteristicsotherthancontentintothesimilaritycomputationprocess.2TextSimilarityMeasuresInthissection,wereportonavarietyofsimilaritymeasureswhichweusedtocomputesimilarityalongcharacteristicdimensionsinherenttotexts.2Weclassifythemintomeasuresforcontentsimilarity,structuralsimilarity,andstylisticsimilarity,asproposedbyBäretal.(2011).2.1ContentSimilarityProbablytheeasiestwaytoreusetextisverbatimcopying.Itcanbedetectedbyusingstringmeasureswhichoperateonsubstringsequences.Thelongestcommonsubstringmeasure(Gusﬁeld,1997)comparesthelengthofthelongestcontiguoussequenceofcharactersbetweentwotexts,normalizedbythetextlengths.However,theeditorialprocessinjournalistictextreuseortheattempttoobfuscatecopyinginplagiarismmayshortenthelongestcommonsubstringconsiderably,e.g.whenwordsareinsertedordeleted,orpartsofreusedtextappearinadifferentorder.Thelongestcommonsubsequencemeasure(AllisonandDix,1986)dropsthecontiguityrequirementandallowstodetecttextreuseincaseofwordinsertions/deletions.GreedyStringTiling(Wise,1996)furtherallowstodealwithreorderedpartsofreusedtextasitdeterminesasetofsharedcontiguoussubstringsbetweentwogivendocuments,eachsubstringtherebybeingamatchofmaximallength.Amultitudeofotherstringsimilaritymeasureshavebeenproposedwhichviewtextsassequencesofcharactersandcomputetheirdegreeof2Inaddition,wereleaseanopen-sourceframeworkwhichcontainsimplementationsofalldiscussedmeasuresinordertostimulatethedevelopmentofnovelmeasures:http://code.google.com/p/dkpro-similarity-asl170

distanceaccordingtoagivenmetric.Weusedthefollowingmeasuresinourexperiments:Jaro(1989),Jaro-Winkler(Winkler,1990),MongeandElkan(1997),andLevenshtein(1966).Startingfromtheobservationthatnotallwordsinadocumentareofequalimportance,wefurtheremployedasimilaritymeasurewhichweightsallwordsbyatﬁdfscheme(SaltonandMcGill,1983)andcomputestextsimilarityasthecosinebetweentwodocumentvectors.Comparingwordn-grams(Lyonetal.,2001)isapopularmeansforcomparinglexicalpatternsbetweentwotexts.Themoresimilarthepatterns,themorelikelyisitthattextreusehasoccurred.Aftercompilingtwosetsofn-grams,wecomparedthemusingtheJaccardcoefﬁcient,followingLyonetal.(2001),aswellasusingthecontainmentmeasure(Broder,1997).Wetestedn-gramsizesforn=1,2,...,15,andwillusetheoriginalsystemnameFerret(Lyonetal.,2004)torefertothevariantwithn=3usingtheJaccardcoefﬁcient,henceforth.Followingtheideaofcomparinglexicalpatterns,wealsousedameasurewhichhasnotyetbeenconsideredforassessingcontentsimilarity:charactern-gramproﬁles(Keseljetal.,2003).3WefollowtheimplementationbyBarrón-Cedeñoetal.(2010)anddiscardallcharacters(caseinsensitive)whicharenotinthealphabetΣ={a,...,z,0,...,9},thengeneratealln-gramsoncharacterlevel,weightthembyatﬁdfscheme,andﬁnallycomparethefeaturevectorsofboththerewrittenandthesourcetextusingthecosinemeasure.Whileintheoriginalimplementationonlyn=3wasused,wegeneralizethemeasureton=2,3,...,15.Incaseswheretheeditorreplacedcontentwordsbysynonyms,stringmeasurestypicallyfailduetothevocabularygap.Wethususedsimilaritymeasureswhicharecapableofmeasuringsemanticsimilaritybetweenwords.WeusedthefollowingwordsimilaritymeasureswithWordNet(Fellbaum,1998):JiangandConrath(1997),Lin(1998),andResnik(1995).Inordertoscalethesepairwisewordsimilarityscorestothedocumentlevel,wefollowtheaggregationstrategybyMihalceaetal.(2006):First,adirectionalsimilarityscoresimd(Ti,Tj)iscomputedfromatextTitoasecondtextTj(Eq.1).Therefore,foreachwordwiinTi,itsbest-matchingcounterpartinTjissought(maxSim(wi,Tj)).Thesimilarityscoresofallthesematchesaresummedupandweightedaccordingtotheirinversedocumentfrequencyidf(SpärckJones,1972),thennormalized.Theﬁnaldocument-levelsimilarityﬁgureistheaverageofapplyingthisstrategyinbothdirections,fromTitoTjandvice-versa(Eq.2).simd(Ti,Tj)=PwimaxSim(wi,Tj)·idf(wi)Pwiidf(wi)(1)sim(Ti,Tj)=12(cid:128)simd(Ti,Tj)+simd(Tj,Ti)(cid:138)(2)Wealsotestedtextexpansionmechanismswiththesemanticwordsimilaritymeasuresdescribedabove:WeusedtheMosesSMTsystem(Koehnetal.,2007),trainedonEuroparl(Koehn,2005),totranslatetheoriginalEnglishtextsviaabridgelanguage(Dutch)backtoEnglish.Thereby,theideawasthatinthetranslationprocessadditionallexemesareintroducedwhichalleviatepotentiallexicalgaps.WecomputedpairwisewordsimilaritywiththemeasuresdescribedaboveandaggregatedaccordingtoMihalceaetal.(2006).Furthermore,weusedthestatisticaltechniqueLatentSemanticAnalysis(LSA)(Landaueretal.,3Traditionally,charactern-gramproﬁleshaveratherbeenshownsuccessfulforauthorshipattribution.However,thesimilarityscoresofwordn-gramsandthoseofcharactern-gramproﬁlesarehighlycorrelated:Assuming5charactersperwordonaverageforEnglishtexts(Shannon,1951),wesetn=3forwordn-gramsandn=15forcharactern-grams,andcomputedPearson’scorrelationrbetweenthecorrespondingsimilarityscores.Weobtainedr=.93andr=.86onthedatasetsintroducedinSections3.1and3.2,respectively,andthusconcludethatthismeasurecapturescontentsimilarityratherthanstylisticsimilarity.171

1998)forcomparingtexts.Theconstructionofthesemanticspacewasdoneusingtheevaluationcorpora(seeSection3).WealsousedthevectorspacemodelExplicitSemanticAnalysis(ESA)(GabrilovichandMarkovitch,2007).BesidesWordNet,weusedtwoadditionallexical-semanticresourcesfortheconstructionoftheESAvectorspace:Wikipedia4andWiktionary5.2.2StructuralSimilarityAsdiscussedabove,wepresumethatcontentsimilarityaloneisnotareliableindicatoroftextreuse.Twoindependentlywrittentextsaboutthesametopicarelikelytomakeuseofacommonvocabularytoacertainextent.Wethusproposetoalsousemeasuresofstructuralsimilaritywhichcomputesimilaritybasedonstructuralaspectsinherenttothecomparedtexts.Stopwordn-grams(Stamatatos,2011)arebasedontheideathattextreuseoftenpreservessyntacticsimilaritieswhileexchangingcontentwords.Thus,themeasureremovesallcontentwordswhilepreservingonlystopwords.Alln-gramsofbothtextsarethencomparedusingthecontainmentmeasure(Broder,1997).Wetestedn-gramsizesforn=2,3,...,15.Forthesamereason,wealsoincludedpart-of-speechn-gramsinourfeatureset.Disregardingtheactualwordsthatappearintwogiventexts,computingn-gramsalongpart-of-speechtagsallowstodetectsyntacticsimilaritiesbetweenthesetexts.Again,wetestedn-gramsizesforn=2,3,...,15,andcomparedthetwosetsusingthecontainmentmeasure(Broder,1997).Wealsoemployedtwosimilaritymeasuresbetweenpairsofwords(Hatzivassiloglouetal.,1999).Thewordpairordermeasureassumesthatasimilarsyntacticalstructureinreusedtextsmaycausetwowordstooccurinthesameorderinbothtexts(withanynumberofwordsinbetween).Thecomplementarywordpairdistancemeasurecountsthenumberofwordswhichliebetweenthoseofagivenpair.Foreachmeasure,wecomputedfeaturevectorsforbothtextsalongallsharedwordpairsandcomparedthevectorsusingPearson’scorrelation.2.3StylisticSimilarityMeasuresofstylisticsimilarityadoptideasfromauthorshipattribution(MostellerandWallace,1964)orusestatisticalpropertiesoftextstocomputetextsimilarity.Thetype-tokenratio(TTR)(Templin,1957),forexample,comparesthevocabularyrichnessoftwotexts.However,itsuffersfromsensitivitytovariationsintextlengthandtheassumptionoftextualhomogeneity(McCarthyandJarvis,2010):Asatextgetslonger,theincreaseoftokensislinear,whiletheincreaseoftypessteadilyslowsdown.Inconsequence,lexicalrepetitioncausestheTTRvaluetovary,whileitdoesnotnecessarilyentailthatareaderperceiveschangesinthevocabularyusage.Secondly,textualhomogeneityistheassumptionoftheexistenceofasinglelexicaldiversitylevelacrossawholetext,whichmaybeviolatedbydifferentrhetoricalstrategies.SequentialTTR(McCarthyandJarvis,2010)alleviatestheseshortcomings.ItiterativelycomputesaTTRscoreforadynamicallygrowingtextsegmentuntilapointofsaturation–i.e.aﬁxedTTRscoreof.72–isreached,thenstartsanewfromthatpositioninthetextforanewsegment.Theﬁnallexicaldiversityscoreiscomputedasthenumberoftokensdividedbythenumberofsegments.InspiredbyYule(1939)whodiscussedsentencelengthasacharacteristicofstyle,wealsousedtwosimplemeasures,sentencelengthandtokenlength,inoursystem.Thesemeasurescomputetheaveragenumberoftokenspersentenceandtheaveragenumberofcharacterspertoken.4www.wikipedia.org5www.wiktionary.org172

TextSimilarityFeatureWPRewriteMETERWebisCPCAcc.¯F1Acc.¯F1Acc.¯F1MajorityClassBaseline.400.143.715.417.517.341FerretBaseline.642.517.684.535.794.789ContentSimilarityCharacter5-gramProﬁles.642.537.715.417.753.742ESA(Wikipedia).474.323.711.484.760.753GreedyStringTiling.558.457.755.645.805.800LongestCommonSubstring.621.524.719.467.743.736Resnik.632.500.715.417.666.656Word2-gramsContainment.747.683.727.692.801.797StructuralSimilarityLemmaPairDistance.611.489.715.417.775.767LemmaPairOrdering.642.494.715.417.785.780POS3-gramsContainment.642.554.731.701.787.783Stopword3-grams.632.515.715.417.778.776Stopword7-grams.653.527.652.482.753.750StylisticSimilarityFunctionWordFrequencies.453.296.715.417.727.719SequentialTTR.400.220.715.417.667.638SentenceRatio.389.268.755.625.657.653TokenRatio.432.222.755.619.778.774Type-TokenRatio.379.197.715.417.723.712Table1:PerformanceofselectedsimilaritymeasuresontheWikipediaRewriteCorpus,theMETERCorpus,andtheWebisCrowdParaphraseCorpus,groupedbysimilaritydimensionAdditionally,wecomparedtheaveragesentenceandtokenlengthsbetweenthereusedtextandtheoriginalsource.Werefertothesemeasuresassentenceratioandtokenratio,respectively.Finally,wecomparetextsbytheirfunctionwordfrequencies(DinuandPopescu,2009)whichhaveshowntobegoodstyleindicatorsinauthorshipattributionstudies.Followingtheoriginalwork,thismeasureusesasetof70functionwordsidentiﬁedbyMostellerandWallace(1964)andcomputesfeaturevectorsoftheirfrequenciesforeachpossiblyreuseddocumentandthesourcetext.ThecomparisonofthevectorsisthenperformedusingPearson’scorrelation.3Experiments&ResultsWeutilizedthreedatasetsfortheevaluationofoursystemwhichoriginateintheﬁeldsofpla-giarismdetection,journalistictextreusedetection,andparaphraserecognition:theWikipediaRewriteCorpus(CloughandStevenson,2011),theMETERCorpus(Gaizauskasetal.,2001),andtheWebisCrowdParaphraseCorpus(Burrowsetal.,2012),describedbelow.Wecarriedoutthesameevaluationprocedureforeachofthethreedatasets:First,wecomputedtextsimilarityscoresbetweenallpairsofpossiblyreusedtextsandtheiroriginalsourcesusingallthemeasuresintroducedinSection2.Wethenusedthesescoresasfeaturesfortwomachinelearningclassiﬁersinordertocombinethemacrossthethreedimensionscontent,structure,andstyle.WeexperimentedwithtwoclassiﬁersfromtheWEKAtoolkit(Halletal.,2009):aNaiveBayesclassiﬁerandaC4.5decisiontreeclassiﬁer(J48implementation).Ina10-foldcross-validationsetup,weranthreesetsofexperimentsasfollows:(i)First,wetestedonlythetextsimilarityscoresofonesinglemeasureatatimeassinglefeaturefortheclassiﬁers,inordertodeterminetheindividuallybest-performingmeasurespersimilarity173

SystemAcc.¯F1MajorityClassBaseline.400.143FerretBaseline.642.517Chongetal.(2010)6.705.641CloughandStevenson(2011)-ourre-implementation7.726.658-asreportedintheirwork.800.757OurApproach.842.811exp.class.15320113201315120037cut&pastelightrev.heavyrev.noplag.cut&pastelightrev.heavyrev.noplag.Table2:Resultsandconfusionmatrix(expectedclassvs.classiﬁcationresult)forthebestclassiﬁcationontheWikipediaRewriteCorpusfortheoriginal4-wayclassiﬁcationdimension.(ii)Wethencombinedthemeasuresperdimensionbyusingmultipletextsimilarityscoresasfeatureset,inordertodeterminetheperformanceofmultiplemeasureswithinasingledimension.(iii)Finally,wecombinedthemeasuresacrossdimensionstodeterminethebestoverallconﬁguration.Wecompareourresultswithtwobaselines:themajorityclassbaselineandthewordtrigramsimilaritymeasureFerret(Lyonetal.,2004)(seeSection2.1).Additionally,wereportthebestresultsfromtheliteratureforcomparison.Evaluationwascarriedoutintermsofaccuracyand¯F1score.Byaccuracy,werefertothenumberofcorrectlypredictedtextsdividedbythetotalnumberoftexts.Astheclassdistributionsinbothdatasetsareskewed,wereporttheoverall¯F1scoreasthearithmeticmeanacrosstheF1scoresofallclassesinordertoaccountfortheclassimbalance.3.1WikipediaRewriteCorpusDatasetThedatasetcontains100pairsofshorttexts(193wordsonaverage).Foreachof5questionsabouttopicsofcomputerscience(e.g.“Whatisdynamicprogramming?”),areferenceanswer(sourcetext,henceforth)hasbeenmanuallycreatedbycopyingportionsoftextfromasuitableWikipediaarticle.Textreusenowoccursbetweenasourcetextandananswergivenbyoneof19participants.Theparticipantswereaskedtoprovideshortanswers,eachofwhichshouldcomplytooneof4rewritelevelsandhencereusethesourcetexttoavaryingextent.Accordingtothedegreeofrewrite,thedatasetis4-wayclassiﬁedascut&paste(38texts;simplecopyoftextportionsfromtheWikipediaarticle),lightrevision(19;synonymsubstitutionsandchangesofgrammaticalstructureallowed),heavyrevision(19;rephrasingofWikipediaexcerptsusingdifferentwordsandstructure),andnoplagiarism(19;answerwrittenindependentlyfromtheWikipediaarticle).AnexampleofaheavyrevisionwasgiveninFigure1.ResultsWesummarizetheresultsonthisdatasetinTable2.8Inthebestconﬁguration,whencombiningsimilaritymeasuresacrossdimensions,oursystemachievesaperformanceof6Chongetal.(2010)report¯F1=.698intheiroriginalwork.Thisﬁgure,however,reﬂectstheweightedarithmeticmeanoverallfourclassesofthedatasetwhereoneclassistwiceasprominentaseachoftheothers.AsdicussedinSection3,wereportall¯F1scoresastheunweightedarithmeticmeaninordertoaccountfortheclassimbalance.7WhilewewereabletoreproducetheresultsoftheFerretbaselineasreportedbyChongetal.(2010),ourre-implementationofthesystembyCloughandStevenson(2011)(NaiveBayesclassiﬁer,samefeatureset)resultedinamuchloweroverallperformance.Weobservedthelargestdifferenceforthelongestcommonsubsequencemeasure,eventhoughweusedastandardimplementation(AllisonandDix,1986)andnormalizedasdescribedbyCloughandStevenson(2011).8Figuresinitalicsaretakenfromtheliterature,whilewe(re-)implementedtheremainingsystems.Thisappliestoallresulttablesinthispaper.174

TextSimilarityDimensionAcc.¯F1CombinationswithindimensionsContent.747.693Structure.716.660Style.442.398CombinationsacrossdimensionsContent+Style.800.757Content+Structure.842.811Structure+Style.632.569Content+Structure+Style.832.798Table3:Resultsofthebestcombinationsoftextsimilaritymeasureswithinandacrossdimen-sionsontheWikipediaRewriteCorpus¯F1=.811.ItoutperformsthebestreferencesystembyCloughandStevenson(2011)by5.4%pointsintermsof¯F1scorecomparedtotheirreportednumbers,andby15.3%pointscomparedtoourre-implementationofthissystem7.TheirsystemusesaNaiveBayesclassiﬁerwithonlyaverysmallfeatureset:wordn-gramcontainment(n=1,2,...,5)andlongestcommonsubsequence.Forcomparison,were-implementedtheirsystemandalsoappliedittothetwodatasetsintheremainderofthispaper.WereportourﬁndingsinSections3.2and3.3.InTable1,wefurtherreportthedetailedresultsforaselectedsetofindividualtextsimilaritymeasures,listedbysimilaritydimension.9Duetospacelimitations,weonlyreportaselectedsetofbest-performingmeasuresperdimensionandcomparethemwiththebaselines:Whilethemajorityclassbaselineperformsverypooronthisdataset(¯F1=.143),theFerretbaselineachieves¯F1=.517.Somecontentsimilaritymeasuressuchasword2-gramscontainmentshowareasonableperformance(¯F1=.683),whilestructuralmeasurescannotexceed¯F1=.554,andstylisticmeasuresperformonlyslightlybetterthanthemajorityclassbaseline(¯F1=.296).InTable3,wereportthebestresultsforthecombinationsoftextsimilaritymeasureswithinandacrossdimensions.Whenwecombinethemeasureswithintheirrespectivedimensions,contentoutperformsstructuralandstylisticsimilarity.However,allcombinationsofmeasuresacrossdimensionsinadditiontocontentsimilarityimprovetheresults.Thebestperformanceisachievedbycombiningthethreesimilaritymeasureslongestcommonsubsequence,stopword10-grams,andcharacter5-gramproﬁlesfromthetwodimensionscontentandstructure.Thissupportsourhypothesisthatthesimilaritycomputationprocessindeedproﬁtsfromdimensionsotherthancontent.Theeffectsofdimensioncombinationheldtrueregardlessoftheclassiﬁerused,eventhoughthedecisiontreeclassiﬁerperformedconsistentlybetterthanNaiveBayes.ErrorAnalysisWepresenttheconfusionmatrixforourbestconﬁgurationinTable2.Intotal,15textsoutof95havebeenclassiﬁedwiththewronglabel.Whilealltextsexceptasingleoneintheclassnoplagiarismhavebeenclassiﬁedcorrectly,67%oferrors(10texts)areduetomisclassiﬁcationsinthelightandheavyrevisionclasses.Weassumethattheseerrorsareduetoquestionablegoldstandardannotationsastheannotationguidelinesforthesetwoclassesarehighlysimilar(CloughandStevenson,2011).Forthelightrevisionclass,theannotators“couldalterthetextinsomebasicways”,thereby“alteringthegrammaticalstructure(i.e.paraphrasing).”Likewise,fortheheavyrevisionclass,theannotationmanualexpectedthe9Table1alsoliststhedetailedresultsfortheMETERCorpusandtheWebisCrowdParaphraseCorpus.WewilldiscussthenumbersinthecorrespondingSections3.2and3.3.175

SystemAcc.¯F1MajorityClassBaseline.400.190FerretBaseline.768.745CloughandStevenson(2011)13.821.788OurApproach.884.859exp.class.145033312037cut&pastepotentialnoplag.cut&pastepotentialnoplag.Table4:ResultsandconfusionmatrixontheWikipediaRewriteCorpusforthefolded3-wayclassiﬁcationSystemAcc.¯F1MajorityClassBaseline.600.375FerretBaseline.937.935CloughandStevenson(2011)-ourre-implementation.958.957-asreported.947n/aOurApproach.968.967exp.class.551237plagiarismnoplag.plagiarismnoplag.Table5:ResultsandconfusionmatrixontheWikipediaRewriteCorpusforthefoldedbinaryclassiﬁcationannotatorsto“rephrasethetexttogenerateananswerwiththesamemeaningasthesourcetext,butexpressedusingdifferentwordsandstructure.”Aseachtextofthisdatasetwaswrittenbyonlyasinglepersonforagivenrewritecategory,wedecidedtoconductanannotationstudy,inwhichweweremostlyinterestedintheinter-rateragreementofthesubjects.Weasked3participantstoratethedegreeoftextreuseandprovidedthemwiththeoriginalannotationguidelines.WeusedageneralizationofScott’s(1955)π-measureforcalculatingachance-correctedinter-rateragreementformultipleraters,whichisknownasFleiss’(1971)κandCarletta’s(1996)K.10Insummary,theresults11ofourstudysupportourhypothesisthattheannotatorsmostlydisagreeforthelightandheavyrevisionclasses,withfair12agreementsofκ=.34andκ=.28,respectively.Forthecut&pasteandnoplagiarismclasses,weobservemoderate12agreements,κ=.53andκ=.56,respectively.Basedontheseinsights,wedecidedtofoldthelightandheavyrevisionclassesintoasingleclasspotentialplagiarism.ThisapproachwasalsobrieﬂydiscussedbyCloughandStevenson(2011),thoughnotcarriedoutintheirwork.WereportthecorrespondingresultsandtheconfusionmatrixinTable4.Astheclassiﬁcationtaskgetseasierbythereductiontothreeclasses,theresultsfortheFerretbaselineimprove,from¯F1=.517to¯F1=.745.There-implementationofthesystembyCloughandStevenson(2011)achieves¯F1=.788.Oursystemagainoutperformsallothersystemswith¯F1=.859.Inourenvisionedsemi-supervisedapplicationscenario,potentiallyreusedtextsarepresentedtousersinaninformativemanner.Here,ﬁne-graineddistinctionsarenotnecessary,andwedecidedtogoevenonestepfurtherandfoldallpotentialcasesoftextreuse.Thisvariantofthedatasetresultsinabinaryclassiﬁcationofplagiarized/non-plagiarizedtexts.Wepresent10Anexhaustivediscussionofinter-rateragreementmeasuresisgivenbyArtsteinandPoesio(2008).11http://www.ukp.tu-darmstadt.de/data/text-similarity/text-reuse-annotations12StrengthofagreementforκvaluesaccordingtoLandisandKoch(1977)13Wereporttheresultsforourre-implementationofthesystembyCloughandStevenson(2011).Intheiroriginalwork,theydidnotevaluateonthisdataset.176

SystemAcc.¯F1MajorityClassBaseline.715.417FerretBaseline.684.535CloughandStevenson(2011)13.692.680Sánchez-Vegaetal.(2010).783.705OurApproach.802.768exp.class.151203052reusenoreusereusenoreuseTable6:ResultsandconfusionmatrixforthebestclassiﬁcationontheMETERCorpustheresultsandthecorrespondingconfusionmatrixinTable5.Inthissimpliﬁedsetting,eventheFerretbaselineachievesanexcellentperformanceof¯F1=.935.Ourapproachstillslightlyoutperforms(¯F1=.967)there-implementationofthesystembyCloughandStevenson(2011).Aninterestingobservationacrossallthreevariantsofthedatasetisthatthesamethreetextsalwaysconstitutesevereerrorinstanceswheree.g.acut&pastetextisfalselylabeledasnoplagiarism,whichismoreseverethanmislabelingalightrevisionasaheavyrevision.TwoofthethreecasesaccountforthetextswhichdescribethePageRankalgorithm.Oneoftheseinstanceswasfalselylabeledascut&pastewhileitisnon-plagiarized,andtheotheronevice-versa.Weattributethemisclassiﬁcationstothemodelbuiltupintheclassiﬁer’strainingphase.Intheenvisionedsemi-supervisedsetting,theremaininglesssevereerrorinstances,wheree.g.alightrevisionwasclassiﬁedasaheavyrevision,canbereviewedbyauserofthesystem.Wesupposeitisevenhardforuserstodrawastrictlinebetweenpossiblyreusedandnon-reusedtexts,asthisheavilydependsonexternaleffectssuchasuserintentionsandthetaskathand.3.2METERCorpusDatasetThedatasetcontainsnewssourcesfromtheUKPressAssociation(PA)andnewspaperarticlesfrom9BritishnewspapersthatreusedthePAsourcetextstogeneratetheirowntexts.Thecompletedatasetcontains1,716textsfromtwodomains:law&courtandshowbusiness.AllnewspaperarticleshavebeenannotatedwhethertheyarewhollyderivedfromthePAsources(i.e.thePAtexthasbeenusedexclusivelyastextreusesource),partiallyderived(thePAtexthasbeenusedinadditiontoothersources),ornon-derived(thePAtexthasnotbeenusedatall).Severalnewspapertexts,though,havemorethanasinglePAsourceintheoriginaldatasetwhereitisunclearwhich(ifnotall)ofthesourcestorieshavebeenusedtogeneratetherewrittenstory.However,fortextreusedetectionitisimportanttohavealignedpairsofreusedtextsandsourcetexts.Therefore,wefollowedSánchez-Vegaetal.(2010)andselectedasubsetoftextswhereonlyasinglesourcestoryispresentinthedataset.Thisleaves253pairsofshorttexts(205wordsonaverage).WefurtherfollowedSánchez-Vegaetal.(2010)andfoldedtheannotationstoabinaryclassiﬁcationof181reused(wholly/partiallyderived)and72non-reusedinstancesinordertocarryoutacomparableevaluationstudy.ResultsWesummarizetheresultsonthisdatasetinTable6.Inthebestconﬁguration,oursystemachievesanoverallperformanceof¯F1=.768.ItoutperformsthebestreferencesystembySánchez-Vegaetal.(2010)by6.3%pointsintermsof¯F1score.TheirsystemusesaNaiveBayesclassiﬁerwithtwocustomfeatureswhichcomparetextsbasedonthelengthandfrequencyofcommonwordsequencesandtherelevanceofindividualwords.AsinSection3.1,wefurtherreportthedetailedresultsforaselectedsetofindividualtextsimilaritymeasures177

TextSimilarityDimensionAcc.¯F1CombinationswithindimensionsContent.759.712Structure.731.701Style.755.672CombinationsacrossdimensionsContent+Style.779.733Content+Structure.739.713Structure+Style.767.739Content+Structure+Style.802.768Table7:Resultsofthebestcombinationsoftextsimilaritymeasureswithinandacrossdimen-sionsontheMETERCorpusinTable1.Fromtheseﬁgures,welearnthatmanytextsimilaritymeasurescannotexceedthesimplemajorityclassbaseline(¯F1=.417)whenappliedindividually.InTable7,weshowthattheperformanceoftextreusedetectionalwaysimprovesoverindividualmeasures(cf.Table1)whenwecombinethemeasureswithintheirrespectivedimensions.Anexceptionisthecombinationofstructuralsimilaritymeasures,whichonlyperformsonthesamelevelasthebestindividualmeasurepart-of-speech3-gramscontainment.Combinationsofcontentsimilaritymeasuresshowabetterperformancethancombinationsofstructuralorstylisticmeasures.Oursystemachievesitsbestperformanceonthisdatasetwhentextsimilaritymeasuresarecombinedacrossallthreedimensionscontent,structure,andstyle.ThebestconﬁgurationresultedfromusingaNaiveBayesclassiﬁerwiththefollowingmeasures:GreedyStringTiling,stopword12-grams,andSequentialTTR.Asforthepreviousdataset,theeffectsofdimensioncombinationheldtrueregardlessoftheclassiﬁerused.Theinﬂuenceofthestylisticsimilaritymeasuresisparticularlyinterestingtonote.IncontrasttotheWikipediaRewriteCorpus,includingthesemeasuresinthecompositionimprovestheresultsonthisdataset:Ourclassiﬁerisabletodetectsimilarityevenforreusedtextsbyexpertjournalists.Thisisduetothefactthatajournalistictextwhichreusestheoriginalpressagencysourcemostlikelyalsoshowsstylisticsimilarityintermsofe.g.vocabularyrichness.ErrorAnalysisWepresenttheconfusionmatrixforourbestconﬁgurationinTable6.Intotal,50textsoutof253havebeenclassiﬁedincorrectly:30instancesoftextreusehavenotbeenidentiﬁedbytheclassiﬁer,and20non-reusedtextshavebeenmistakenlylabeledassuch.However,theoriginalannotationshavebeencarriedoutbyonlyasingleannotator(Gaizauskasetal.,2001)whichmayhaveresultedinsubjectivejudgments.Thus,asforthepreviousdatasetinSection3.1,weconductedanannotationstudywiththreeannotatorstogainfurtherinsightsintothedata.Theresults11showthatfor61%ofalltextstheannotatorsfullyagree.Thechance-correctedFleiss’(1971)agreementκ=.47ismoderate12.Forthe30instancesoftextreusewhichhavenotbeenidentiﬁedbytheclassiﬁer,itisparticularlyinterestingtonotethatmanyerrorsareduetothefactthataloweroveralltextsimilaritybetweenthepossiblyreusedtextandtheoriginalsourcedoesnotnecessarilyentailthelabelnoreuse.ThenewspaperarticleabouttheEnglishsinger-songwriterLiamGallagher,forexample,isoriginallylabeledastextreuse.However,ourclassiﬁerfalselyassignedthelabelnoreuse.Itturnsout,though,thatthereusedtextisaboutfourtimesaslongastheoriginalpressagencysource,withlotsofnewfactsbeingintroducedthere.Consequently,onlyalowsimilarityscore178

SystemAcc.¯F1MajorityClassBaseline.517.341FerretBaseline.794.789CloughandStevenson(2011)13.798.795Burrowsetal.(2012).839.837OurApproach.853.852exp.class.3,6547594133,033paraphrasenopara.paraphrasenopara.Table8:ResultsandconfusionmatrixforthebestclassiﬁcationontheWebisCrowdParaphraseCorpuscanbecomputedbetweentheadditionalmaterialinthenewspaperarticleandtheoriginalsource,andtheoverallsimilarityscoredecreases.Weconcludethatapplicationswillbeneﬁtfromanimprovedclassiﬁerwhichbetterdealswiththesesinstances.Forexample,similarityfeaturescouldbecomputedpersection,notperdocument,whichwouldallowtoalsoidentifypotentialinstancesoftextreuseforonlypartiallymatchingtexts.Thecurrentlyachievedperformance(seeTable6)oftextreusedetection,though,issufﬁcientforourenvisionedsemi-supervisedapplicationscenariowherecontentauthorsareprovidedonlywithsuggestionsofpotentialinstancesoftextreuseandthenarefreetodecidehowtoproceed,e.g.tomergebothtexts.Theﬁnaldecisionprobablyalsodependsonexternalfactorssuchasuserintentionsandthetaskathand.3.3WebisCrowdParaphraseCorpusDatasetThedatasetwasoriginallyintroducedaspartofthePAN2010internationalplagiarismdetectioncompetition(Potthastetal.,2010).Itcontains7,859pairsoforiginaltextsalongwiththeirparaphrases(28to954wordsinlength)with4,067(52%)positiveand3,792(48%)negativesamples.TheoriginaltextsarebookexcerptsfromProjectGutenberg14,andthecorrespondingparaphraseswereacquiredinacrowdsourcingprocessusingAmazonMechanicalTurk(Callison-BurchandDredze,2010).Inthemanualﬁlteringprocess15ofallacquiredparaphrases,Burrowsetal.(2012)herebyfollowtheparaphrasedeﬁnitionbyBoonthum(2004),whereagoodparaphraseexhibitspatternssuchassynonymuse,changesbetweenactiveandpassivevoice,orchangingwordformsandpartsofspeech,andabadparaphraseisrathere.g.a(near-)duplicateoranautomatedone-for-onewordsubstitution.Thisdeﬁnitionimpliesthatamoresophisticatedinterpretationoftextsimilarityscoresneedstobelearned,wheree.g.(near-)duplicateswithveryhighsimilarityscoresareinfactnegativesamples.ResultsWesummarizetheresultsonthisdatasetinTable8.EventhoughtheFerretbaselineisastrongcompetitor(¯F1=.789),ourapproachachievesthebestresultsonthisdatasetwith¯F1=.852.TheresultsreportedbyBurrowsetal.(2012)areslightlyworse(¯F1=.837).Theirbestscorewasachievedbyusingak-nearestneighborclassiﬁerwithafeaturesetof10similaritymeasures.Theyexclusivelyusedsimilaritymeasuresthatoperateonthetexts’stringsequencesandthuscapturethecontentdimensionoftextsimilarityonly,e.g.Levenshtein(1966)distanceandawordn-gramsimilaritymeasure.Asintheprevioussections,wereportthedetailedresultsforaselectedsetofindividualtextsimilaritymeasuresinTable1.Theseﬁguresshowthat14www.gutenberg.org15Burrowsetal.(2012)donotreportanyinter-annotatoragreementsfortheﬁlteringprocess,asthetaskwassplitacrosstwoannotatorsandeachtextpairwaslabeledbyonlyasingleannotator.179

TextSimilarityDimensionAcc.¯F1CombinationswithindimensionsContent.840.839Structure.816.814Style.819.817CombinationsacrossdimensionsContent+Style.844.843Content+Structure.838.838Structure+Style.831.830Content+Structure+Style.853.852Table9:Resultsofthebestcombinationsoftextsimilaritymeasureswithinandacrossdimen-sionsontheWebisCrowdParaphraseCorpusregardlessofthesimilaritydimensionmanymeasuresachieveaveryreasonableperformancewhenappliedindividually,withthemeasuresGreedyStringTilingandword2-gramscontainmentperformingbest.Asforthepreviousdatasets,ourhypothesisholdstruethatthecombinationofsimilaritydimensionsimprovestheresults:Whenwecombinethesimilarityfeatureswithineachoftherespectivedimensions,theperformancenumbersincrease(seeTable9ascomparedtoTable1).Thecombinationofcontentsimilaritymeasuresisstrongerthanthecombinationofstructuralandstylisticsimilaritymeasures,andperformsonthesamelevelastheoriginalresultsreportedbyBurrowsetal.(2012).Thisistobeexpected,astheirsystemusesafeaturesetwhichalsoaddressesthecontentdimensionexclusively.Whenwecombinemeasuresacrossdimensions,theresultsimproveevenfurther.Anexceptionisthecombinationofcontentandstructuralmeasures,whichperformsslightlyworsethancontentmeasuresaloneduetothelowerperformanceofstructuralmeasuresonthisdataset.Thebestconﬁgurationofoursystemresultedfromcombiningallthreedimensionscontent,structure,andstyleinasingleclassiﬁcationmodelusingthedecisiontreeclassiﬁer,resultingin¯F1=.852.Theﬁnalfeaturesetcontains16textsimilarityfeatureswhicharelistedinTable10.ErrorAnalysisWepresenttheconfusionmatrixforourbestclassiﬁcationinTable8.Intotal,1,172(15%)outof7,859textpairshavebeenclassiﬁedincorrectly.Outofthese,ourclassiﬁermistakenlylabeled759instancesofnegativesamplesastrueparaphrases,while413casesoftrueparaphraseswerenotrecognized.However,inouropinionthe759falsepositivesarelesssevereerrorsinourenvisionedsemi-supervisedapplicationsetting,asuserintentionsandthecurrenttaskathandmayhighlyinﬂuenceauser’sdecisiontoconsidertextsasreusedornot.Ingeneral,weattributetheerrorstotheparticularpropertiesofthisdataset,whichdifferfromthoseoftheWikipediaRewriteCorpusandtheMETERCorpus(seeSections3.1and3.2).Forthosetwodatasets,themoresimilartwotextsare,thehighertheirdegreeoftextreuse.FortheWebisCrowdParaphraseCorpus,however,adifferentinterpretationneedstobelearnedbytheclassiﬁer:Here,(near-)duplicatesandtextswithautomatedword-by-wordsubstitutions,whichwillreceivehighsimilarityscoresbyanyofourcontentsimilaritymeasures,areinfactannotatedasbadparaphrases,i.e.negativesamples.Unrelatedtexts,emptysamples,ortextsalikealsobelongtotheclassofnegativesamples.Inconsequence,positivesamplesareonlythoseinthemediumsimilarityrange.Weassumethatthemoreelaboratedeﬁnitionofpositiveandnegativecasesmakesitmoredifﬁculttolearnapropermodelforthegivendata.180

ContentESA(WordNet,with+w/ostopwords),GreedyStringTiling,Jaro,LongestCommonSubstring,LongestCommonSubseq.(2norm.),n-gramJaccard(n={6,14,15}),Resnik(SMTwrapper)StructureLemmaPairOrdering,POS2-gramsJaccard,Stopword6-gramsStyleFunctionWordFrequencies,SequentialTTR,TokenRatioTable10:FeaturesetusedtoachievethebestresultsontheWebisCrowdParaphraseCorpus4ConclusionsandFutureWorkThemotivationforthisworkstemmedfromthehypothesisthatcontentfeaturesalonearenotareliableindicatorfortextreusedetection.AsillustratedinFigure1,areusedtextmayalsocontainmodiﬁcationssuchassplitsentences,changedorderofreusedparts,orstylisticvariance.Wethusdevisedanarchitecturewhichcomposesdiversetextsimilaritymeasuresinasupervisedclassiﬁcationmodel.Inthismodel,weovercomethetraditionallimitationoftextsimilaritymeasurestocontentfeaturesandcomputesimilarityalongthreecharacteristicdimensionsinherenttotexts:content,structure,andstyle.Weevaluatedourclassiﬁcationmodelonthreestandarddatasetswheretextreuseisprevalentandwhichoriginateintheﬁeldsofplagiarismdetection,journalistictextreusedetection,andparaphraserecognition:theWikipediaRewriteCorpus(CloughandStevenson,2011),theMETERCorpus(Gaizauskasetal.,2001),andtheWebisCrowdParaphraseCorpus(Burrowsetal.,2012).Basedontheevaluationresults,wediscussedtheinﬂuenceofeachofthesimilaritydimensions,anddemonstratedempiricallythattextreusecanbebestdetectedifmeasuresarecombinedacrossdimensions,sothatawidevarietyoftextfeaturesaretakenintoconsideration.Thecompositionconsistentlyoutperformspreviousapproachesacrossalldatasets.Asweshowed,similaritycomputationworksbestifthesimilaritydimensionsarechosenwellwithrespecttothetypeoftextreuseathand.FortheWikipediaRewriteCorpus,forexample,thestylisticsimilarityfeaturesperformonlypoorly,whichiswhythecompositionofallthreedimensionsperformsslightlyworsethanthanthecombinationofonlycontentandstructuralfeatures.Fortheothertwodatasets,however,stylisticsimilarityisastrongdimensionwithinthecomposition,andconsequentlythebestperformanceisreachedwhencombiningallthreedimensions.Basedontheseinsights,weconcludethatfornoveldatasetsitisessentialtoaddressthedimensionsexplicitlyintheannotationprocess,sothattextreusedetectionapproachescanbeevaluatedpreciselyagainstparticularcharacteristicsofdifferentkindsofdata.Forfuturework,weexpectthatconsideringadimensionalrepresentationoftextsimilarityfeatureswillalsobeneﬁtanyothertaskwheretextsimilaritycomputationisfundamentalandwhichisyetlimitedtocontentfeatures,e.g.paraphraserecognitionorautomaticessaygrading.Forthelatter,weseegreatpotentialforimprovementsbyincluding,forexample,measuresforgrammaranalysis,lexicalcomplexity,ormeasuresassessingtextorganizationwithrespecttothediscourseelements.However,eachtaskexhibitsparticularcharacteristicswhichinﬂuencethechoiceofasuitablesetofsimilaritydimensions.Asdiscussedabove,aparticulardimensionmayormaynotcontributetoanoverallimprovementbasedonthenatureofthedata.AcknowledgementsThisworkhasbeensupportedbytheVolkswagenFoundationaspartoftheLichtenberg-ProfessorshipProgramundergrantNo.I/82806,andbytheKlausTschiraFoundationunderprojectNo.00.133.2008.WethankChrisBiemannforhisinspirations,aswellasCarolinDeeg,AndriyNadolskyy,andArtemVovkfortheirparticipationintheannotationstudies.181

ReferencesAbdel-Hamid,O.,Behzadi,B.,Christoph,S.,andHenzinger,M.(2009).DetectingtheOriginofTextSegmentsEfﬁciently.InProceedingsofthe18thInternationalConferenceonWorldWideWeb,pages61–70,Madrid,Spain.Allison,L.andDix,T.I.(1986).Abit-stringlongest-common-subsequencealgorithm.Informa-tionProcessingLetters,23:305–310.Artstein,R.andPoesio,M.(2008).Inter-CoderAgreementforComputationalLinguistics.ComputationalLinguistics,34(4):555–596.Bär,D.,Zesch,T.,andGurevych,I.(2011).AReﬂectiveViewonTextSimilarity.InProceedingsoftheInternationalConferenceonRecentAdvancesinNaturalLanguageProcessing,pages515–520,Hissar,Bulgaria.Barrón-Cedeño,A.,Rosso,P.,Agirre,E.,andLabaka,G.(2010).PlagiarismDetectionacrossDistantLanguagePairs.InProceedingsofthe23rdInternationalConferenceonComputationalLinguistics,pages37–45,Beijing,China.Boonthum,C.(2004).iSTART:ParaphraseRecognition.InProceedingsofthe42ndMeetingoftheAssociationforComputationalLinguistics:StudentResearchWorkshop,pages31–36,Barcelona,Spain.Broder,A.Z.(1997).Ontheresemblanceandcontainmentofdocuments.ProceedingsofCompressionandComplexityofSequences,pages21–29.Broder,A.Z.,Glassman,S.C.,Manasse,M.S.,andZweig,G.(1997).SyntacticclusteringoftheWeb.InProceedingsofthe6thInternationalWorldWideWebConference,pages1157–1166,SantaClara,CA,USA.Burrows,S.,Potthast,M.,andStein,B.(2012).ParaphraseAcquisitionviaCrowdsourcingandMachineLearning.TransactionsonIntelligentSystemsandTechnology,V(January):1–22.Callison-Burch,C.andDredze,M.(2010).CreatingSpeechandLanguageDataWithAmazon’sMechanicalTurk.InProceedingsoftheNAACLHLTWorkshoponCreatingSpeechandLanguageDatawithAmazon’sMechanicalTurk,pages1–12,LosAngeles,CA,USA.Carletta,J.(1996).AssessingAgreementonClassiﬁcationTasks:TheKappaStatistic.Compu-tationalLinguistics,22(2):249–254.Charikar,M.S.(2002).SimilarityEstimationTechniquesfromRoundingAlgorithms.InProceedingsofthe34thAnnualSymposiumonTheoryofComputing,pages380–388,Montreal,Canada.Chong,M.,Specia,L.,andMitkov,R.(2010).UsingNaturalLanguageProcessingforAutomaticDetectionofPlagiarism.InProceedingsofthe4thInternationalPlagiarismConference,NewcastleuponTyne,UK.Clough,P.,Gaizauskas,R.,Piao,S.S.,andWilks,Y.(2002).METER:MEasuringTExtReuse.InProceedingsof40thAnnualMeetingoftheAssociationforComputationalLinguistics,pages152–159,Philadelphia,PA,USA.182

Clough,P.andStevenson,M.(2011).DevelopingaCorpusofPlagiarisedShortAnswers.Lan-guageResourcesandEvaluation:SpecialIssueonPlagiarismandAuthorshipAnalysis,45(1):5–24.Dinu,L.P.andPopescu,M.(2009).Ordinalmeasuresinauthorshipidentiﬁcation.InProceedingsofthe3rdPANWorkshop.UncoveringPlagiarism,AuthorshipandSocialSoftwareMisuse,pages62–66,SanSebastian,Spain.Fellbaum,C.(1998).WordNet:AnElectronicLexicalDatabase.MITPress.Fleiss,J.L.(1971).Measuringnominalscaleagreementamongmanyraters.PsychologicalBulletin,76(5):378–382.Gabrilovich,E.andMarkovitch,S.(2007).ComputingSemanticRelatednessusingWikipedia-basedExplicitSemanticAnalysis.InProceedingsofthe20thInternationalJointConferenceonArtiﬁcialIntelligence,pages1606–1611,Hyderabad,India.Gaizauskas,R.,Foster,J.,Wilks,Y.,Arundel,J.,Clough,P.,andPiao,S.(2001).TheMETERCorpus:Acorpusforanalysingjournalistictextreuse.InProceedingsoftheCorpusLinguistics2001Conference,pages214–223.Gärdenfors,P.(2000).ConceptualSpaces:TheGeometryofThought.MITPress.Goodman,N.(1972).Sevenstricturesonsimilarity.InGoodman,N.,editor,Problemsandprojects,pages437–446.Bobbs-Merrill.Gusﬁeld,D.(1997).AlgorithmsonStrings,TreesandSequences:ComputerScienceandComputationalBiology.CambridgeUniversityPress.Hall,M.,Frank,E.,Holmes,G.,Pfahringer,B.,Reutemann,P.,andWitten,I.H.(2009).TheWEKADataMiningSoftware:AnUpdate.SIGKDDExplorations,11(1):10–18.Hatzivassiloglou,V.,Klavans,J.L.,andEskin,E.(1999).Detectingtextsimilarityovershortpassages:Exploringlinguisticfeaturecombinationsviamachinelearning.InProceedingsoftheJointSIGDATConferenceonEmpiricalMethodsinNaturalLanguageProcessingandVeryLargeCorpora,pages203–212,CollegePark,MD,USA.Henzinger,M.(2006).FindingNear-DuplicateWebPages:ALarge-ScaleEvaluationofAlgorithms.InProceedingsofthe29thAnnualInternationalACMSIGIRConferenceonResearchandDevelopmentinInformationRetrieval,pages284–291,Seattle,WA,USA.Hoad,T.C.andZobel,J.(2003).Methodsforidentifyingversionedandplagiarizeddocuments.JournaloftheAmericanSocietyofInformationScienceandTechnology,54(3):203–215.Jaro,M.A.(1989).Advancesinrecordlinkagemethodologyasappliedtothe1985censusofTampaFlorida.JournaloftheAmericanStatisticalAssociation,84(406):414–420.Jiang,J.J.andConrath,D.W.(1997).Semanticsimilaritybasedoncorpusstatisticsandlexicaltaxonomy.InProceedingsofthe10thInternationalConferenceonResearchinComputationalLinguistics.183

Keselj,V.,Peng,F.,Cercone,N.,andThomas,C.(2003).N-gram-basedauthorproﬁlesforauthorshipattribution.InProceedingsoftheConferenceofthePaciﬁcAssociationforComputationalLinguistics,pages255–264.Koehn,P.(2005).Europarl:AParallelCorpusforStatisticalMachineTranslation.InProceedingsofthe10thMachineTranslationSummit,pages79–86,PhuketIsland,Thailand.Koehn,P.,Hoang,H.,Birch,A.,Callison-Burch,C.,Federico,M.,Bertoldi,N.,Cowan,B.,Shen,W.,Moran,C.,Zens,R.,Dyer,C.,Bojar,O.,Constantin,A.,andHerbst,E.(2007).Moses:OpenSourceToolkitforStatisticalMachineTranslation.InProceedingsofthe45thAnnualMeetingoftheAssociationforComputationalLinguisticsCompanionVolumeProceedingsoftheDemoandPosterSessions,pages177–180,Prague,CzechRepublic.Landauer,T.K.,Foltz,P.W.,andLaham,D.(1998).Anintroductiontolatentsemanticanalysis.DiscourseProcesses,25(2):259–284.Landis,J.R.andKoch,G.G.(1977).Themeasurementofobserveragreementforcategoricaldata.Biometrics,33(1):159–174.Lee,J.(2007).AComputationalModelofTextReuseinAncientLiteraryTexts.InProceedingsofthe45thAnnualMeetingoftheAssociationofComputationalLinguistics,pages472–479.Leuf,B.andCunningham,W.(2001).TheWikiWay:CollaborationandSharingontheInternet.Addison-WesleyProfessional.Levenshtein,V.I.(1966).Binarycodescapableofcorrectingdeletions,insertions,andreversals.SovietPhysicsDoklady,10(8):707–710.Lin,D.(1998).Aninformation-theoreticdeﬁnitionofsimilarity.InProceedingsofInternationalConferenceonMachineLearning,pages296–304.Lyon,C.,Barrett,R.,andMalcolm,J.(2004).Atheoreticalbasistotheautomateddetectionofcopyingbetweentexts,anditspracticalimplementationintheFerretplagiarismandcollusiondetector.InInPlagiarism:Prevention,PracticeandPoliciesConference.Lyon,C.,Malcolm,J.,andDickerson,B.(2001).Detectingshortpassagesofsimilartextinlargedocumentcollections.InProceedingsofConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages118–125.Manku,G.S.,Jain,A.,andSarma,A.D.(2007).DetectingNear-DuplicatesforWebCrawling.InProceedingsofthe16thInternationalWorldWideWebConference,pages141–149,Banff,AB,Canada.McCarthy,P.M.andJarvis,S.(2010).MTLD,vocd-D,andHD-D:Avalidationstudyofsophisticatedapproachestolexicaldiversityassessment.Behaviorresearchmethods,42(2):381–392.Mihalcea,R.,Corley,C.,andStrapparava,C.(2006).Corpus-basedandKnowledge-basedMeasuresofTextSemanticSimilarity.InProceedingsofthe21stNationalConferenceonArtiﬁcialIntelligence,pages775–780,Boston,MA,USA.184

Monge,A.andElkan,C.(1997).Anefﬁcientdomain-independentalgorithmfordetectingapproximatelyduplicatedatabaserecords.InProceedingsoftheSIGMODWorkshoponDataMiningandKnowledgeDiscovery,pages23–29,Tucson,AZ,USA.Mosteller,F.andWallace,D.L.(1964).Inferenceanddisputedauthorship:TheFederalist.Addison-Wesley.Potthast,M.,Barrón-Cedeño,A.,Eiselt,A.,Stein,B.,andRosso,P.(2010).Overviewofthe2ndInternationalCompetitiononPlagiarismDetection.InNotebookPapersofCLEF10LabsandWorkshops,Padua,Italy.Resnik,P.(1995).UsingInformationContenttoEvaluateSemanticSimilarityinaTaxonomy.InProceedingsofthe14thInternationalJointConferenceonArtiﬁcialIntelligence,pages448–453,Montreal,Canada.Salton,G.andMcGill,M.J.(1983).IntroductiontoModernInformationRetrieval.McGraw-Hill.Sánchez-Vega,F.,Villaseñor-Pineda,L.,Montes-y-Gómez,M.,andRosso,P.(2010).TowardsDocumentPlagiarismDetectionBasedontheRelevanceandFragmentationoftheReusedText.InProceedingsofthe9thMexicanInternationalConferenceonArtiﬁcialIntelligence,pages24–31,Pachuca,Mexico.Scott,W.A.(1955).Reliabilityofcontentanalysis:Thecaseofnominalscalecoding.PublicOpinionQuarterly,19(3):321–325.Shannon,C.E.(1951).PredictionandEntropyofPrintedEnglish.BellSystemTechnicalJournal,30:50–64.SpärckJones,K.(1972).Astatisticalinterpretationoftermspeciﬁcityanditsapplicationinretrieval.JournalofDocumentation,28(1):11–21.Stamatatos,E.(2011).Plagiarismdetectionusingstopwordn-grams.JournaloftheAmericanSocietyforInformationScienceandTechnology,62(12):2512–2527.Templin,M.C.(1957).Certainlanguageskillsinchildren.UniversityofMinnesotaPress.Tversky,A.(1977).FeaturesofSimilarity.InPsychologicalReview,volume84,pages327–352.Winkler,W.E.(1990).StringComparatorMetricsandEnhancedDecisionRulesintheFellegi-SunterModelofRecordLinkage.InProceedingsoftheSectiononSurveyResearchMethods,pages354–359.Wise,M.J.(1996).YAP3:Improveddetectionofsimilaritiesincomputerprogramandothertexts.InProceedingsofthe27thSIGCSEtechnicalsymposiumonComputerscienceeducation,pages130–134,Philadelphia,PA,USA.Yule,G.U.(1939).Onsentence-lengthasastatisticalcharacteristicofstyleinprose:Withapplicationtotwocasesofdisputedauthorship.Biometrika,30(3/4):363–390.